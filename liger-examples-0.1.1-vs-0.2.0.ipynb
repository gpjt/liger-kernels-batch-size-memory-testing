{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6895652e-679d-4389-a30e-50a0d1c54058",
   "metadata": {},
   "outputs": [],
   "source": [
    "v011_data = \"\"\"\n",
    "(batch-size-memory-testing) ubuntu@164-152-23-196:~/Liger-Kernel/examples/huggingface$ ./run.sh\n",
    "W0829 22:09:05.701000 140290123141120 torch/distributed/run.py:779]\n",
    "W0829 22:09:05.701000 140290123141120 torch/distributed/run.py:779] *****************************************\n",
    "W0829 22:09:05.701000 140290123141120 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
    "W0829 22:09:05.701000 140290123141120 torch/distributed/run.py:779] *****************************************\n",
    "tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 50.6k/50.6k [00:00<00:00, 142MB/s]\n",
    "tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.09M/9.09M [00:00<00:00, 46.7MB/s]\n",
    "special_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 73.0/73.0 [00:00<00:00, 687kB/s]\n",
    "Downloading readme: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.47k/7.47k [00:00<00:00, 174kB/s]\n",
    "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24.2M/24.2M [00:00<00:00, 115MB/s]\n",
    "Generating train split: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 52002/52002 [00:00<00:00, 283338.03 examples/s]\n",
    "config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 654/654 [00:00<00:00, 5.98MB/s]\n",
    "model.safetensors.index.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 23.9k/23.9k [00:00<00:00, 143MB/s]\n",
    "model-00001-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4.98G/4.98G [00:19<00:00, 250MB/s]\n",
    "model-00002-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 5.00G/5.00G [00:20<00:00, 243MB/s]\n",
    "model-00003-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4.92G/4.92G [00:20<00:00, 242MB/s]\n",
    "model-00004-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1.17G/1.17G [00:04<00:00, 242MB/s]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:05<00:00, 16.50s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:05<00:00, 16.49s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:06<00:00, 16.50s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:05<00:00, 16.50s/it]\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 10.58it/s]\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  9.43it/s]\n",
    "generation_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 177/177 [00:00<00:00, 873kB/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.57it/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.27it/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 11442.55 examples/s]\n",
    "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 12052.90 examples/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 9608.99 examples/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:05<00:00, 9212.56 examples/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:05<00:00, 8959.20 examples/s]\n",
    "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 10024.07 examples/s]\n",
    "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 10550.12 examples/s]\n",
    "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 10646.54 examples/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1558: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1558: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1564: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.\n",
    "  warnings.warn(\n",
    "  0%|                                                                                                                                             | 0/183 [00:00<?, ?it/s]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.3834, 'grad_norm': 8.760961532592773, 'learning_rate': 3.157894736842105e-07, 'epoch': 0.01, 'num_input_tokens_seen': 84992}\n",
    "  1%|▋                                                                                                                                    | 1/183 [00:09<29:07,  9.60s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.376, 'grad_norm': 9.614106178283691, 'learning_rate': 6.31578947368421e-07, 'epoch': 0.01, 'num_input_tokens_seen': 174080, 'step': 2, 'step_time_sec': 9.16, 'avg_step_time_sec': 9.16, 'time_to_completion_sec': 1657.44, 'estimated_total_time_sec': 1675.76, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 38308.48, 'step_peak_memory_reserved_MB': 58820.0, 'total_peak_memory_reserved_MB': 58820.0, 'step_tokens_per_second': 9728.79, 'avg_tokens_per_second': 9728.79}\n",
    "  1%|█▍                                                                                                                                   | 2/183 [00:18<28:16,  9.37s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.3633, 'grad_norm': 11.103222846984863, 'learning_rate': 9.473684210526316e-07, 'epoch': 0.02, 'num_input_tokens_seen': 243712, 'step': 3, 'step_time_sec': 5.58, 'avg_step_time_sec': 7.37, 'time_to_completion_sec': 1325.91, 'estimated_total_time_sec': 1348.01, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 38714.8, 'step_peak_memory_reserved_MB': 60724.0, 'total_peak_memory_reserved_MB': 60724.0, 'step_tokens_per_second': 12489.64, 'avg_tokens_per_second': 10773.58}\n",
    "  2%|██▏                                                                                                                                  | 3/183 [00:24<23:05,  7.70s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.4431, 'grad_norm': 9.42140007019043, 'learning_rate': 1.263157894736842e-06, 'epoch': 0.02, 'num_input_tokens_seen': 319488, 'step': 4, 'step_time_sec': 6.45, 'avg_step_time_sec': 7.06, 'time_to_completion_sec': 1263.73, 'estimated_total_time_sec': 1291.97, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 39871.28, 'step_peak_memory_reserved_MB': 63664.0, 'total_peak_memory_reserved_MB': 63664.0, 'step_tokens_per_second': 11752.63, 'avg_tokens_per_second': 11071.62}\n",
    "{'loss': 1.2902, 'grad_norm': 9.904911994934082, 'learning_rate': 1.5789473684210526e-06, 'epoch': 0.03, 'num_input_tokens_seen': 387072, 'step': 5, 'step_time_sec': 5.71, 'avg_step_time_sec': 6.72, 'time_to_completion_sec': 1196.52, 'estimated_total_time_sec': 1230.13, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 39871.28, 'step_peak_memory_reserved_MB': 63664.0, 'total_peak_memory_reserved_MB': 63664.0, 'step_tokens_per_second': 11839.95, 'avg_tokens_per_second': 11234.73}\n",
    "  3%|███▋                                                                                                                                 | 5/183 [00:37<20:00,  6.74s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2678, 'grad_norm': 7.6250691413879395, 'learning_rate': 1.8947368421052632e-06, 'epoch': 0.03, 'num_input_tokens_seen': 472064, 'step': 6, 'step_time_sec': 9.14, 'avg_step_time_sec': 7.21, 'time_to_completion_sec': 1275.43, 'estimated_total_time_sec': 1318.67, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 39871.28, 'step_peak_memory_reserved_MB': 63664.0, 'total_peak_memory_reserved_MB': 63664.0, 'step_tokens_per_second': 9297.83, 'avg_tokens_per_second': 10743.31}\n",
    "  3%|████▎                                                                                                                                | 6/183 [00:46<22:25,  7.60s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2352, 'grad_norm': 8.224749565124512, 'learning_rate': 2.2105263157894738e-06, 'epoch': 0.04, 'num_input_tokens_seen': 556032, 'step': 7, 'step_time_sec': 7.89, 'avg_step_time_sec': 7.32, 'time_to_completion_sec': 1288.41, 'estimated_total_time_sec': 1339.65, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 40161.53, 'step_peak_memory_reserved_MB': 66744.0, 'total_peak_memory_reserved_MB': 66744.0, 'step_tokens_per_second': 10636.98, 'avg_tokens_per_second': 10724.2}\n",
    "{'loss': 1.3102, 'grad_norm': 7.415462493896484, 'learning_rate': 2.526315789473684e-06, 'epoch': 0.04, 'num_input_tokens_seen': 626688, 'step': 8, 'step_time_sec': 6.05, 'avg_step_time_sec': 7.14, 'time_to_completion_sec': 1249.35, 'estimated_total_time_sec': 1306.47, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 40161.53, 'step_peak_memory_reserved_MB': 66744.0, 'total_peak_memory_reserved_MB': 66744.0, 'step_tokens_per_second': 11676.55, 'avg_tokens_per_second': 10839.52}\n",
    "{'loss': 1.3134, 'grad_norm': 3.8079965114593506, 'learning_rate': 2.8421052631578946e-06, 'epoch': 0.05, 'num_input_tokens_seen': 698368, 'step': 9, 'step_time_sec': 5.75, 'avg_step_time_sec': 6.97, 'time_to_completion_sec': 1212.09, 'estimated_total_time_sec': 1274.79, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 40161.53, 'step_peak_memory_reserved_MB': 66744.0, 'total_peak_memory_reserved_MB': 66744.0, 'step_tokens_per_second': 12457.07, 'avg_tokens_per_second': 11006.54}\n",
    "  5%|██████▌                                                                                                                              | 9/183 [01:06<19:46,  6.82s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2369, 'grad_norm': 3.0823919773101807, 'learning_rate': 3.157894736842105e-06, 'epoch': 0.05, 'num_input_tokens_seen': 789504, 'step': 10, 'step_time_sec': 8.75, 'avg_step_time_sec': 7.16, 'time_to_completion_sec': 1239.35, 'estimated_total_time_sec': 1310.99, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 40161.53, 'step_peak_memory_reserved_MB': 66744.0, 'total_peak_memory_reserved_MB': 66744.0, 'step_tokens_per_second': 10419.8, 'avg_tokens_per_second': 10926.94}\n",
    "  5%|███████▏                                                                                                                            | 10/183 [01:15<21:29,  7.45s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2928, 'grad_norm': 3.3591697216033936, 'learning_rate': 3.473684210526316e-06, 'epoch': 0.06, 'num_input_tokens_seen': 869376, 'step': 11, 'step_time_sec': 8.35, 'avg_step_time_sec': 7.28, 'time_to_completion_sec': 1252.62, 'estimated_total_time_sec': 1332.73, 'step_peak_memory_allocated_MB': 42364.27, 'total_peak_memory_allocated_MB': 42364.27, 'step_peak_memory_reserved_MB': 71668.0, 'total_peak_memory_reserved_MB': 71668.0, 'step_tokens_per_second': 9563.4, 'avg_tokens_per_second': 10770.57}\n",
    "  6%|███████▉                                                                                                                            | 11/183 [01:23<22:15,  7.77s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2798, 'grad_norm': 4.481235980987549, 'learning_rate': 3.7894736842105264e-06, 'epoch': 0.07, 'num_input_tokens_seen': 954368, 'step': 12, 'step_time_sec': 7.39, 'avg_step_time_sec': 7.29, 'time_to_completion_sec': 1246.95, 'estimated_total_time_sec': 1334.45, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 42364.27, 'step_peak_memory_reserved_MB': 71668.0, 'total_peak_memory_reserved_MB': 71668.0, 'step_tokens_per_second': 11506.72, 'avg_tokens_per_second': 10838.36}\n",
    "{'loss': 1.2321, 'grad_norm': 3.491896629333496, 'learning_rate': 4.105263157894737e-06, 'epoch': 0.07, 'num_input_tokens_seen': 1076224, 'step': 13, 'step_time_sec': 9.26, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 1267.52, 'estimated_total_time_sec': 1364.45, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 13160.77, 'avg_tokens_per_second': 11078.69}\n",
    "  7%|█████████▍                                                                                                                          | 13/183 [01:40<23:14,  8.20s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2296, 'grad_norm': 4.087116718292236, 'learning_rate': 4.4210526315789476e-06, 'epoch': 0.08, 'num_input_tokens_seen': 1144832, 'step': 14, 'step_time_sec': 6.43, 'avg_step_time_sec': 7.38, 'time_to_completion_sec': 1246.77, 'estimated_total_time_sec': 1350.05, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10664.42, 'avg_tokens_per_second': 11050.9}\n",
    "  8%|██████████                                                                                                                          | 14/183 [01:47<21:42,  7.71s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2421, 'grad_norm': 3.176999568939209, 'learning_rate': 4.736842105263158e-06, 'epoch': 0.08, 'num_input_tokens_seen': 1206272, 'step': 15, 'step_time_sec': 6.24, 'avg_step_time_sec': 7.3, 'time_to_completion_sec': 1225.75, 'estimated_total_time_sec': 1335.19, 'step_peak_memory_allocated_MB': 38308.41, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 9845.88, 'avg_tokens_per_second': 10977.29}\n",
    "{'loss': 1.2097, 'grad_norm': 3.000127077102661, 'learning_rate': 5.052631578947368e-06, 'epoch': 0.09, 'num_input_tokens_seen': 1283072, 'step': 16, 'step_time_sec': 7.31, 'avg_step_time_sec': 7.3, 'time_to_completion_sec': 1218.59, 'estimated_total_time_sec': 1335.34, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10507.87, 'avg_tokens_per_second': 10945.94}\n",
    "{'loss': 1.2253, 'grad_norm': 3.7658963203430176, 'learning_rate': 5.368421052631579e-06, 'epoch': 0.09, 'num_input_tokens_seen': 1366016, 'step': 17, 'step_time_sec': 8.23, 'avg_step_time_sec': 7.36, 'time_to_completion_sec': 1220.98, 'estimated_total_time_sec': 1346.02, 'step_peak_memory_allocated_MB': 42364.27, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10077.77, 'avg_tokens_per_second': 10885.22}\n",
    "{'loss': 1.1924, 'grad_norm': 2.960622787475586, 'learning_rate': 5.684210526315789e-06, 'epoch': 0.1, 'num_input_tokens_seen': 1430528, 'step': 18, 'step_time_sec': 6.32, 'avg_step_time_sec': 7.29, 'time_to_completion_sec': 1203.62, 'estimated_total_time_sec': 1334.92, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10200.27, 'avg_tokens_per_second': 10850.29}\n",
    "{'loss': 1.2247, 'grad_norm': 2.945671796798706, 'learning_rate': 6e-06, 'epoch': 0.1, 'num_input_tokens_seen': 1504256, 'step': 19, 'step_time_sec': 6.07, 'avg_step_time_sec': 7.23, 'time_to_completion_sec': 1185.15, 'estimated_total_time_sec': 1322.45, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 12149.83, 'avg_tokens_per_second': 10910.92}\n",
    " 10%|█████████████▋                                                                                                                      | 19/183 [02:22<19:01,  6.96s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2378, 'grad_norm': 2.935847759246826, 'learning_rate': 5.9994495852953836e-06, 'epoch': 0.11, 'num_input_tokens_seen': 1603584, 'step': 20, 'step_time_sec': 9.22, 'avg_step_time_sec': 7.33, 'time_to_completion_sec': 1195.06, 'estimated_total_time_sec': 1341.69, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10768.28, 'avg_tokens_per_second': 10901.47}\n",
    "{'loss': 1.2597, 'grad_norm': 2.9193015098571777, 'learning_rate': 5.997798543152429e-06, 'epoch': 0.11, 'num_input_tokens_seen': 1676288, 'step': 21, 'step_time_sec': 6.85, 'avg_step_time_sec': 7.31, 'time_to_completion_sec': 1183.8, 'estimated_total_time_sec': 1337.25, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10619.18, 'avg_tokens_per_second': 10888.25}\n",
    "{'loss': 1.1876, 'grad_norm': 3.008368730545044, 'learning_rate': 5.9950474794097236e-06, 'epoch': 0.12, 'num_input_tokens_seen': 1745920, 'step': 22, 'step_time_sec': 5.82, 'avg_step_time_sec': 7.24, 'time_to_completion_sec': 1165.1, 'estimated_total_time_sec': 1324.3, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11962.42, 'avg_tokens_per_second': 10929.39}\n",
    "{'loss': 1.1969, 'grad_norm': 3.0055980682373047, 'learning_rate': 5.9911974035512214e-06, 'epoch': 0.13, 'num_input_tokens_seen': 1844224, 'step': 23, 'step_time_sec': 9.13, 'avg_step_time_sec': 7.32, 'time_to_completion_sec': 1171.63, 'estimated_total_time_sec': 1340.05, 'step_peak_memory_allocated_MB': 41031.35, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10767.08, 'avg_tokens_per_second': 10920.19}\n",
    "{'loss': 1.1826, 'grad_norm': 3.0077781677246094, 'learning_rate': 5.9862497283358345e-06, 'epoch': 0.13, 'num_input_tokens_seen': 1933312, 'step': 24, 'step_time_sec': 8.64, 'avg_step_time_sec': 7.38, 'time_to_completion_sec': 1173.39, 'estimated_total_time_sec': 1350.51, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10314.88, 'avg_tokens_per_second': 10889.39}\n",
    "{'loss': 1.1903, 'grad_norm': 2.85009503364563, 'learning_rate': 5.980206269279025e-06, 'epoch': 0.14, 'num_input_tokens_seen': 2014208, 'step': 25, 'step_time_sec': 6.96, 'avg_step_time_sec': 7.36, 'time_to_completion_sec': 1163.27, 'estimated_total_time_sec': 1347.34, 'step_peak_memory_allocated_MB': 40740.84, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11616.43, 'avg_tokens_per_second': 10918.05}\n",
    "{'loss': 1.1333, 'grad_norm': 3.1574299335479736, 'learning_rate': 5.973069243986614e-06, 'epoch': 0.14, 'num_input_tokens_seen': 2097152, 'step': 26, 'step_time_sec': 9.16, 'avg_step_time_sec': 7.43, 'time_to_completion_sec': 1167.18, 'estimated_total_time_sec': 1360.48, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 9057.33, 'avg_tokens_per_second': 10826.36}\n",
    "{'loss': 1.1566, 'grad_norm': 2.857090711593628, 'learning_rate': 5.964841271341046e-06, 'epoch': 0.15, 'num_input_tokens_seen': 2179072, 'step': 27, 'step_time_sec': 7.31, 'avg_step_time_sec': 7.43, 'time_to_completion_sec': 1159.01, 'estimated_total_time_sec': 1359.6, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11206.08, 'avg_tokens_per_second': 10840.73}\n",
    " 15%|███████████████████▍                                                                                                                | 27/183 [03:26<20:43,  7.97s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2174, 'grad_norm': 2.7847626209259033, 'learning_rate': 5.95552537054041e-06, 'epoch': 0.15, 'num_input_tokens_seen': 2274304, 'step': 28, 'step_time_sec': 9.29, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 1162.25, 'estimated_total_time_sec': 1372.2, 'step_peak_memory_allocated_MB': 41320.04, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10252.8, 'avg_tokens_per_second': 10813.76}\n",
    "{'loss': 1.2154, 'grad_norm': 2.697991132736206, 'learning_rate': 5.945124959990565e-06, 'epoch': 0.16, 'num_input_tokens_seen': 2341888, 'step': 29, 'step_time_sec': 5.62, 'avg_step_time_sec': 7.43, 'time_to_completion_sec': 1144.42, 'estimated_total_time_sec': 1359.92, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 12026.2, 'avg_tokens_per_second': 10846.51}\n",
    "{'loss': 1.1943, 'grad_norm': 2.7648305892944336, 'learning_rate': 5.933643856050778e-06, 'epoch': 0.16, 'num_input_tokens_seen': 2426880, 'step': 30, 'step_time_sec': 7.57, 'avg_step_time_sec': 7.44, 'time_to_completion_sec': 1137.73, 'estimated_total_time_sec': 1360.82, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11223.1, 'avg_tokens_per_second': 10859.73}\n",
    "{'loss': 1.1928, 'grad_norm': 2.6044135093688965, 'learning_rate': 5.921086271633337e-06, 'epoch': 0.17, 'num_input_tokens_seen': 2501632, 'step': 31, 'step_time_sec': 6.64, 'avg_step_time_sec': 7.41, 'time_to_completion_sec': 1126.28, 'estimated_total_time_sec': 1355.99, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11251.18, 'avg_tokens_per_second': 10871.43}\n",
    "{'loss': 1.2351, 'grad_norm': 2.7094781398773193, 'learning_rate': 5.907456814657656e-06, 'epoch': 0.17, 'num_input_tokens_seen': 2583552, 'step': 32, 'step_time_sec': 7.76, 'avg_step_time_sec': 7.42, 'time_to_completion_sec': 1120.57, 'estimated_total_time_sec': 1358.04, 'step_peak_memory_allocated_MB': 41320.04, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10559.92, 'avg_tokens_per_second': 10860.93}\n",
    "{'loss': 1.1925, 'grad_norm': 2.7369489669799805, 'learning_rate': 5.892760486359423e-06, 'epoch': 0.18, 'num_input_tokens_seen': 2683904, 'step': 33, 'step_time_sec': 9.31, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 1122.02, 'estimated_total_time_sec': 1368.86, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10775.46, 'avg_tokens_per_second': 10857.6}\n",
    "{'loss': 1.1667, 'grad_norm': 2.588451862335205, 'learning_rate': 5.877002679455439e-06, 'epoch': 0.19, 'num_input_tokens_seen': 2772992, 'step': 34, 'step_time_sec': 7.49, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 1114.56, 'estimated_total_time_sec': 1368.89, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11901.67, 'avg_tokens_per_second': 10889.26}\n",
    " 19%|████████████████████████▌                                                                                                           | 34/183 [04:20<19:45,  7.96s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/utils.py:187: UserWarning: Could not find response key `[14711, 6075, 512]` in the following instance: <|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Come up with an appropriate title for the following document.\n",
    "\n",
    "### Input:\n",
    "WASHINGTON (CNN) -- A wide-open presidential race and a willingness by candidates, interest groups, unions and corporations to buy TV time will lead to historic spending for political and issue-advocacy advertising in the 2008 election cycle, an analysis shows. Former Massachusetts Gov. Mitt Romney has spent the most on TV advertising so far among presidential contenders. The cost to try to influence the 2008 election could exceed $3 billion, according to TNS Media Intelligence/Campaign Media Analysis Group, CNN's consultant on political television advertising. This is nearly twice as much than what was spent in 2004 when political and issue-advocacy television advertising rang in at $1.7 billion. In 2006, $2.3 billion was spent on political and issue-advocacy TV commercials. Just about every candidate running for an office from dogcatcher to president is spending the money, said Evan Tracey, CMAG's chief operating officer. The costs to produce a TV commercial are no longer prohibitive for local and state candidates, who are turning more and more to the airwaves to reach voters. See how spending breaks down for this year ». And interest groups have spent $6.2 million on TV ads so far this year for state and local ballot measures. On the national level, the cost of issue-advocacy television ad spending was $270 million in the first nine months of this year. Subjects ranged from the Iraq war to telecommunications reform. Television ads on health care alone total $60 million. CMAG estimates more than $3 million of the $270 million spent to air issue-advocacy ads this year has gone for commercials in states and districts that are likely to have competitive House and Senate races in 2008. Tracey said he thinks this is just the beginning of interest groups \"pivoting from legislative advocacy mode to political mode.\" \"What we expect to see between now and the end of the primaries, and through the general election, is groups will take a more aggressive stance on their advertising and actually target candidates,\" he said. With 17 Democratic and Republican candidates running for president, CMAG predicts that more than $800 million will be spent on TV ads in the battle for the White House. Up to now, the political commercials have been largely This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
    "  warnings.warn(\n",
    "{'loss': 1.2217, 'grad_norm': 2.6150856018066406, 'learning_rate': 5.860189176164791e-06, 'epoch': 0.19, 'num_input_tokens_seen': 2843648, 'step': 35, 'step_time_sec': 6.1, 'avg_step_time_sec': 7.44, 'time_to_completion_sec': 1101.08, 'estimated_total_time_sec': 1361.47, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11579.42, 'avg_tokens_per_second': 10905.91}\n",
    "{'loss': 1.1497, 'grad_norm': 2.7921183109283447, 'learning_rate': 5.842326146087113e-06, 'epoch': 0.2, 'num_input_tokens_seen': 2951168, 'step': 36, 'step_time_sec': 9.28, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 1101.37, 'estimated_total_time_sec': 1371.09, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11587.14, 'avg_tokens_per_second': 10930.01}\n",
    " 20%|█████████████████████████▉                                                                                                          | 36/183 [04:36<19:40,  8.03s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.1584, 'grad_norm': 2.5424840450286865, 'learning_rate': 5.823420143938684e-06, 'epoch': 0.2, 'num_input_tokens_seen': 3045376, 'step': 37, 'step_time_sec': 9.11, 'avg_step_time_sec': 7.54, 'time_to_completion_sec': 1100.44, 'estimated_total_time_sec': 1379.31, 'step_peak_memory_allocated_MB': 40740.84, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10340.78, 'avg_tokens_per_second': 10910.23}\n",
    " 20%|██████████████████████████▋                                                                                                         | 37/183 [04:45<20:25,  8.39s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.1486, 'grad_norm': 2.5124969482421875, 'learning_rate': 5.803478107147233e-06, 'epoch': 0.21, 'num_input_tokens_seen': 3111936, 'step': 38, 'step_time_sec': 6.63, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 1089.33, 'estimated_total_time_sec': 1374.81, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10042.96, 'avg_tokens_per_second': 10889.55}\n",
    "{'loss': 1.1903, 'grad_norm': 2.7244441509246826, 'learning_rate': 5.7825073533062846e-06, 'epoch': 0.21, 'num_input_tokens_seen': 3181568, 'step': 39, 'step_time_sec': 6.1, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 1076.45, 'estimated_total_time_sec': 1367.99, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11422.85, 'avg_tokens_per_second': 10901.0}\n",
    "{'loss': 1.2776, 'grad_norm': 2.753725290298462, 'learning_rate': 5.760515577490025e-06, 'epoch': 0.22, 'num_input_tokens_seen': 3258368, 'step': 40, 'step_time_sec': 7.93, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 1070.64, 'estimated_total_time_sec': 1370.12, 'step_peak_memory_allocated_MB': 41841.51, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 9686.81, 'avg_tokens_per_second': 10868.03}\n",
    "{'loss': 1.1462, 'grad_norm': 2.595022678375244, 'learning_rate': 5.737510849429649e-06, 'epoch': 0.22, 'num_input_tokens_seen': 3337216, 'step': 41, 'step_time_sec': 7.32, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 1062.54, 'estimated_total_time_sec': 1369.33, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10777.19, 'avg_tokens_per_second': 10865.81}\n",
    "{'loss': 1.2367, 'grad_norm': 2.838466167449951, 'learning_rate': 5.713501610552225e-06, 'epoch': 0.23, 'num_input_tokens_seen': 3398656, 'step': 42, 'step_time_sec': 5.1, 'avg_step_time_sec': 7.42, 'time_to_completion_sec': 1046.85, 'estimated_total_time_sec': 1358.68, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 12056.67, 'avg_tokens_per_second': 10885.74}\n",
    "{'loss': 1.268, 'grad_norm': 2.614915370941162, 'learning_rate': 5.688496670883167e-06, 'epoch': 0.23, 'num_input_tokens_seen': 3492864, 'step': 43, 'step_time_sec': 9.12, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 1045.07, 'estimated_total_time_sec': 1366.06, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10333.17, 'avg_tokens_per_second': 10869.68}\n",
    "{'loss': 1.1786, 'grad_norm': 2.4994304180145264, 'learning_rate': 5.662505205813464e-06, 'epoch': 0.24, 'num_input_tokens_seen': 3589120, 'step': 44, 'step_time_sec': 9.21, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 1043.23, 'estimated_total_time_sec': 1373.47, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10456.11, 'avg_tokens_per_second': 10857.88}\n",
    "{'loss': 1.2114, 'grad_norm': 2.4186995029449463, 'learning_rate': 5.6355367527328275e-06, 'epoch': 0.25, 'num_input_tokens_seen': 3688448, 'step': 45, 'step_time_sec': 9.22, 'avg_step_time_sec': 7.54, 'time_to_completion_sec': 1041.09, 'estimated_total_time_sec': 1380.58, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10778.11, 'avg_tokens_per_second': 10855.66}\n",
    "{'loss': 1.1626, 'grad_norm': 2.5915255546569824, 'learning_rate': 5.607601207530016e-06, 'epoch': 0.25, 'num_input_tokens_seen': 3803136, 'step': 46, 'step_time_sec': 9.28, 'avg_step_time_sec': 7.58, 'time_to_completion_sec': 1038.84, 'estimated_total_time_sec': 1387.65, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 12353.84, 'avg_tokens_per_second': 10896.42}\n",
    "{'loss': 1.1711, 'grad_norm': 2.531416893005371, 'learning_rate': 5.578708820961603e-06, 'epoch': 0.26, 'num_input_tokens_seen': 3875840, 'step': 47, 'step_time_sec': 5.63, 'avg_step_time_sec': 7.54, 'time_to_completion_sec': 1025.48, 'estimated_total_time_sec': 1379.88, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 12917.88, 'avg_tokens_per_second': 10929.23}\n",
    "{'loss': 1.1206, 'grad_norm': 2.619826555252075, 'learning_rate': 5.548870194890537e-06, 'epoch': 0.26, 'num_input_tokens_seen': 3982336, 'step': 48, 'step_time_sec': 9.21, 'avg_step_time_sec': 7.58, 'time_to_completion_sec': 1022.74, 'estimated_total_time_sec': 1386.38, 'step_peak_memory_allocated_MB': 41841.51, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11562.41, 'avg_tokens_per_second': 10945.6}\n",
    "{'loss': 1.115, 'grad_norm': 2.314028739929199, 'learning_rate': 5.518096278395851e-06, 'epoch': 0.27, 'num_input_tokens_seen': 4060160, 'step': 49, 'step_time_sec': 6.59, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 1012.41, 'estimated_total_time_sec': 1382.62, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11808.47, 'avg_tokens_per_second': 10961.28}\n",
    "{'loss': 1.2217, 'grad_norm': 2.5960428714752197, 'learning_rate': 5.486398363754984e-06, 'epoch': 0.27, 'num_input_tokens_seen': 4151296, 'step': 50, 'step_time_sec': 9.21, 'avg_step_time_sec': 7.59, 'time_to_completion_sec': 1009.35, 'estimated_total_time_sec': 1388.81, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 9893.27, 'avg_tokens_per_second': 10934.83}\n",
    "{'loss': 1.1417, 'grad_norm': 2.43572735786438, 'learning_rate': 5.453788082300154e-06, 'epoch': 0.28, 'num_input_tokens_seen': 4244480, 'step': 51, 'step_time_sec': 9.28, 'avg_step_time_sec': 7.62, 'time_to_completion_sec': 1006.24, 'estimated_total_time_sec': 1395.02, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10036.14, 'avg_tokens_per_second': 10912.94}\n",
    "{'loss': 1.1122, 'grad_norm': 2.4454195499420166, 'learning_rate': 5.420277400150314e-06, 'epoch': 0.28, 'num_input_tokens_seen': 4321280, 'step': 52, 'step_time_sec': 6.73, 'avg_step_time_sec': 7.61, 'time_to_completion_sec': 996.31, 'estimated_total_time_sec': 1391.8, 'step_peak_memory_allocated_MB': 40451.33, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11418.18, 'avg_tokens_per_second': 10921.7}\n",
    "{'loss': 1.1791, 'grad_norm': 2.5632412433624268, 'learning_rate': 5.38587861382028e-06, 'epoch': 0.29, 'num_input_tokens_seen': 4398080, 'step': 53, 'step_time_sec': 7.67, 'avg_step_time_sec': 7.61, 'time_to_completion_sec': 988.87, 'estimated_total_time_sec': 1392.03, 'step_peak_memory_allocated_MB': 41320.04, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10010.83, 'avg_tokens_per_second': 10904.03}\n",
    "{'loss': 1.2337, 'grad_norm': 2.682112693786621, 'learning_rate': 5.350604345708593e-06, 'epoch': 0.3, 'num_input_tokens_seen': 4483072, 'step': 54, 'step_time_sec': 8.09, 'avg_step_time_sec': 7.62, 'time_to_completion_sec': 982.44, 'estimated_total_time_sec': 1393.69, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 10510.14, 'avg_tokens_per_second': 10896.14}\n",
    "{'loss': 1.1103, 'grad_norm': 2.4975364208221436, 'learning_rate': 5.314467539465829e-06, 'epoch': 0.3, 'num_input_tokens_seen': 4545536, 'step': 55, 'step_time_sec': 5.53, 'avg_step_time_sec': 7.58, 'time_to_completion_sec': 969.88, 'estimated_total_time_sec': 1386.62, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 75252.0, 'total_peak_memory_reserved_MB': 75252.0, 'step_tokens_per_second': 11295.03, 'avg_tokens_per_second': 10901.53}\n",
    "{'loss': 1.2175, 'grad_norm': 2.548203468322754, 'learning_rate': 5.277481455245011e-06, 'epoch': 0.31, 'num_input_tokens_seen': 4640768, 'step': 56, 'step_time_sec': 8.79, 'avg_step_time_sec': 7.6, 'time_to_completion_sec': 965.1, 'estimated_total_time_sec': 1390.65, 'step_peak_memory_allocated_MB': 43406.97, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10834.81, 'avg_tokens_per_second': 10900.13}\n",
    "{'loss': 1.1288, 'grad_norm': 2.40271258354187, 'learning_rate': 5.239659664835888e-06, 'epoch': 0.31, 'num_input_tokens_seen': 4742144, 'step': 57, 'step_time_sec': 8.82, 'avg_step_time_sec': 7.62, 'time_to_completion_sec': 960.25, 'estimated_total_time_sec': 1394.65, 'step_peak_memory_allocated_MB': 43406.97, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11490.8, 'avg_tokens_per_second': 10912.34}\n",
    "{'loss': 1.2106, 'grad_norm': 2.424638032913208, 'learning_rate': 5.201016046684856e-06, 'epoch': 0.32, 'num_input_tokens_seen': 4828160, 'step': 58, 'step_time_sec': 6.72, 'avg_step_time_sec': 7.61, 'time_to_completion_sec': 950.66, 'estimated_total_time_sec': 1391.77, 'step_peak_memory_allocated_MB': 40451.33, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12794.47, 'avg_tokens_per_second': 10941.53}\n",
    "{'loss': 1.1751, 'grad_norm': 2.6372854709625244, 'learning_rate': 5.161564780802361e-06, 'epoch': 0.32, 'num_input_tokens_seen': 4898816, 'step': 59, 'step_time_sec': 6.63, 'avg_step_time_sec': 7.59, 'time_to_completion_sec': 940.97, 'estimated_total_time_sec': 1388.69, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10656.29, 'avg_tokens_per_second': 10937.23}\n",
    "{'loss': 1.1745, 'grad_norm': 2.4762110710144043, 'learning_rate': 5.1213203435596425e-06, 'epoch': 0.33, 'num_input_tokens_seen': 4972544, 'step': 60, 'step_time_sec': 6.09, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 930.26, 'estimated_total_time_sec': 1384.05, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12101.94, 'avg_tokens_per_second': 10953.13}\n",
    "{'loss': 1.1713, 'grad_norm': 2.5256528854370117, 'learning_rate': 5.0802975023767254e-06, 'epoch': 0.33, 'num_input_tokens_seen': 5059584, 'step': 61, 'step_time_sec': 7.91, 'avg_step_time_sec': 7.57, 'time_to_completion_sec': 923.42, 'estimated_total_time_sec': 1385.12, 'step_peak_memory_allocated_MB': 41841.51, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10996.99, 'avg_tokens_per_second': 10953.9}\n",
    "{'loss': 1.1336, 'grad_norm': 2.537781000137329, 'learning_rate': 5.038511310303617e-06, 'epoch': 0.34, 'num_input_tokens_seen': 5129216, 'step': 62, 'step_time_sec': 5.54, 'avg_step_time_sec': 7.54, 'time_to_completion_sec': 911.82, 'estimated_total_time_sec': 1379.03, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12573.85, 'avg_tokens_per_second': 10973.41}\n",
    "{'loss': 1.1168, 'grad_norm': 2.4782538414001465, 'learning_rate': 4.9959771004966955e-06, 'epoch': 0.34, 'num_input_tokens_seen': 5207040, 'step': 63, 'step_time_sec': 7.77, 'avg_step_time_sec': 7.54, 'time_to_completion_sec': 904.74, 'estimated_total_time_sec': 1379.73, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10013.25, 'avg_tokens_per_second': 10957.45}\n",
    "{'loss': 1.1971, 'grad_norm': 2.5280652046203613, 'learning_rate': 4.952710480592314e-06, 'epoch': 0.35, 'num_input_tokens_seen': 5297152, 'step': 64, 'step_time_sec': 6.9, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 895.99, 'estimated_total_time_sec': 1377.86, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 13066.77, 'avg_tokens_per_second': 10988.11}\n",
    "{'loss': 1.233, 'grad_norm': 2.6135919094085693, 'learning_rate': 4.9087273269796795e-06, 'epoch': 0.36, 'num_input_tokens_seen': 5369856, 'step': 65, 'step_time_sec': 9.2, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 891.53, 'estimated_total_time_sec': 1382.63, 'step_peak_memory_allocated_MB': 38308.41, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 7904.86, 'avg_tokens_per_second': 10929.47}\n",
    "{'loss': 1.1402, 'grad_norm': 2.3268215656280518, 'learning_rate': 4.8640437789751294e-06, 'epoch': 0.36, 'num_input_tokens_seen': 5449728, 'step': 66, 'step_time_sec': 7.3, 'avg_step_time_sec': 7.55, 'time_to_completion_sec': 883.52, 'estimated_total_time_sec': 1381.92, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10937.49, 'avg_tokens_per_second': 10929.59}\n",
    "{'loss': 1.1544, 'grad_norm': 2.4166319370269775, 'learning_rate': 4.818676232899914e-06, 'epoch': 0.37, 'num_input_tokens_seen': 5526528, 'step': 67, 'step_time_sec': 6.2, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 873.6, 'estimated_total_time_sec': 1378.18, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12378.93, 'avg_tokens_per_second': 10947.68}\n",
    "{'loss': 1.1294, 'grad_norm': 2.7068777084350586, 'learning_rate': 4.772641336063682e-06, 'epoch': 0.37, 'num_input_tokens_seen': 5587968, 'step': 68, 'step_time_sec': 5.03, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 861.79, 'estimated_total_time_sec': 1371.36, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12203.96, 'avg_tokens_per_second': 10960.28}\n",
    "{'loss': 1.1873, 'grad_norm': 2.461376190185547, 'learning_rate': 4.725955980655862e-06, 'epoch': 0.38, 'num_input_tokens_seen': 5673984, 'step': 69, 'step_time_sec': 8.44, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 855.87, 'estimated_total_time_sec': 1373.9, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10196.46, 'avg_tokens_per_second': 10947.65}\n",
    "{'loss': 1.1045, 'grad_norm': 2.7105162143707275, 'learning_rate': 4.678637297547192e-06, 'epoch': 0.38, 'num_input_tokens_seen': 5749760, 'step': 70, 'step_time_sec': 6.11, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 846.07, 'estimated_total_time_sec': 1370.18, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12407.63, 'avg_tokens_per_second': 10964.91}\n",
    "{'loss': 1.1667, 'grad_norm': 2.85365891456604, 'learning_rate': 4.630702650003664e-06, 'epoch': 0.39, 'num_input_tokens_seen': 5826560, 'step': 71, 'step_time_sec': 6.89, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 837.62, 'estimated_total_time_sec': 1368.61, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11153.68, 'avg_tokens_per_second': 10967.4}\n",
    "{'loss': 1.216, 'grad_norm': 2.7384016513824463, 'learning_rate': 4.582169627315188e-06, 'epoch': 0.39, 'num_input_tokens_seen': 5902336, 'step': 72, 'step_time_sec': 7.51, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 830.2, 'estimated_total_time_sec': 1368.7, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10085.35, 'avg_tokens_per_second': 10954.92}\n",
    "{'loss': 1.1291, 'grad_norm': 2.699951410293579, 'learning_rate': 4.533056038341331e-06, 'epoch': 0.4, 'num_input_tokens_seen': 5980160, 'step': 73, 'step_time_sec': 7.66, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 823.0, 'estimated_total_time_sec': 1369.17, 'step_peak_memory_allocated_MB': 41320.04, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10155.22, 'avg_tokens_per_second': 10943.54}\n",
    "{'loss': 1.1145, 'grad_norm': 2.591937780380249, 'learning_rate': 4.483379904976471e-06, 'epoch': 0.4, 'num_input_tokens_seen': 6045696, 'step': 74, 'step_time_sec': 5.57, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 812.65, 'estimated_total_time_sec': 1364.36, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11775.37, 'avg_tokens_per_second': 10952.05}\n",
    "{'loss': 1.1886, 'grad_norm': 2.678478956222534, 'learning_rate': 4.433159455536789e-06, 'epoch': 0.41, 'num_input_tokens_seen': 6122496, 'step': 75, 'step_time_sec': 7.49, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 805.25, 'estimated_total_time_sec': 1364.45, 'step_peak_memory_allocated_MB': 38308.41, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10254.58, 'avg_tokens_per_second': 10942.58}\n",
    "{'loss': 1.138, 'grad_norm': 2.5981054306030273, 'learning_rate': 4.382413118071515e-06, 'epoch': 0.42, 'num_input_tokens_seen': 6224896, 'step': 76, 'step_time_sec': 8.68, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 799.54, 'estimated_total_time_sec': 1367.44, 'step_peak_memory_allocated_MB': 42885.09, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11791.92, 'avg_tokens_per_second': 10955.74}\n",
    "{'loss': 1.2204, 'grad_norm': 2.8073389530181885, 'learning_rate': 4.331159513600879e-06, 'epoch': 0.42, 'num_input_tokens_seen': 6292480, 'step': 77, 'step_time_sec': 6.62, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 790.88, 'estimated_total_time_sec': 1365.39, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10210.88, 'avg_tokens_per_second': 10947.04}\n",
    "{'loss': 1.1218, 'grad_norm': 2.4742441177368164, 'learning_rate': 4.27941744928326e-06, 'epoch': 0.43, 'num_input_tokens_seen': 6379520, 'step': 78, 'step_time_sec': 9.12, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 785.68, 'estimated_total_time_sec': 1369.33, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9546.73, 'avg_tokens_per_second': 10924.89}\n",
    "{'loss': 1.1164, 'grad_norm': 2.6291658878326416, 'learning_rate': 4.22720591151402e-06, 'epoch': 0.43, 'num_input_tokens_seen': 6477824, 'step': 79, 'step_time_sec': 9.3, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 780.62, 'estimated_total_time_sec': 1373.59, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10569.57, 'avg_tokens_per_second': 10919.24}\n",
    "{'loss': 1.084, 'grad_norm': 2.5035040378570557, 'learning_rate': 4.174544058958587e-06, 'epoch': 0.44, 'num_input_tokens_seen': 6562816, 'step': 80, 'step_time_sec': 8.43, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 774.32, 'estimated_total_time_sec': 1375.73, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10081.63, 'avg_tokens_per_second': 10907.35}\n",
    "{'loss': 1.1694, 'grad_norm': 2.5900659561157227, 'learning_rate': 4.121451215522306e-06, 'epoch': 0.44, 'num_input_tokens_seen': 6645760, 'step': 81, 'step_time_sec': 8.4, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 767.93, 'estimated_total_time_sec': 1377.75, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9874.22, 'avg_tokens_per_second': 10892.94}\n",
    "{'loss': 1.1341, 'grad_norm': 2.4784469604492188, 'learning_rate': 4.06794686325967e-06, 'epoch': 0.45, 'num_input_tokens_seen': 6730752, 'step': 82, 'step_time_sec': 6.64, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 759.29, 'estimated_total_time_sec': 1375.74, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12801.79, 'avg_tokens_per_second': 10913.75}\n",
    "{'loss': 1.0767, 'grad_norm': 2.460381269454956, 'learning_rate': 4.014050635225508e-06, 'epoch': 0.45, 'num_input_tokens_seen': 6831104, 'step': 83, 'step_time_sec': 8.43, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 752.88, 'estimated_total_time_sec': 1377.77, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11910.57, 'avg_tokens_per_second': 10927.36}\n",
    "{'loss': 1.0895, 'grad_norm': 2.7328310012817383, 'learning_rate': 3.9597823082707765e-06, 'epoch': 0.46, 'num_input_tokens_seen': 6902784, 'step': 84, 'step_time_sec': 5.59, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 743.03, 'estimated_total_time_sec': 1373.48, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12832.83, 'avg_tokens_per_second': 10944.44}\n",
    "{'loss': 1.1598, 'grad_norm': 2.6660971641540527, 'learning_rate': 3.905161795785577e-06, 'epoch': 0.46, 'num_input_tokens_seen': 7004160, 'step': 85, 'step_time_sec': 9.19, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 737.49, 'estimated_total_time_sec': 1377.14, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11035.3, 'avg_tokens_per_second': 10945.76}\n",
    "{'loss': 1.1455, 'grad_norm': 2.5535359382629395, 'learning_rate': 3.850209140392072e-06, 'epoch': 0.47, 'num_input_tokens_seen': 7077888, 'step': 86, 'step_time_sec': 6.36, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 728.64, 'estimated_total_time_sec': 1374.64, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11585.36, 'avg_tokens_per_second': 10952.14}\n",
    "{'loss': 1.0707, 'grad_norm': 2.6375479698181152, 'learning_rate': 3.7949445065899857e-06, 'epoch': 0.48, 'num_input_tokens_seen': 7165952, 'step': 87, 'step_time_sec': 8.11, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 721.79, 'estimated_total_time_sec': 1375.91, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10863.55, 'avg_tokens_per_second': 10951.03}\n",
    "{'loss': 1.0906, 'grad_norm': 2.4420998096466064, 'learning_rate': 3.739388173357378e-06, 'epoch': 0.48, 'num_input_tokens_seen': 7242752, 'step': 88, 'step_time_sec': 8.11, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 714.92, 'estimated_total_time_sec': 1377.16, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9465.72, 'avg_tokens_per_second': 10932.62}\n",
    "{'loss': 1.1063, 'grad_norm': 2.743145227432251, 'learning_rate': 3.6835605267094133e-06, 'epoch': 0.49, 'num_input_tokens_seen': 7317504, 'step': 89, 'step_time_sec': 6.1, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 705.87, 'estimated_total_time_sec': 1374.19, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12260.68, 'avg_tokens_per_second': 10944.87}\n",
    "{'loss': 1.1182, 'grad_norm': 2.576791763305664, 'learning_rate': 3.6274820522178506e-06, 'epoch': 0.49, 'num_input_tokens_seen': 7406592, 'step': 90, 'step_time_sec': 9.31, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 700.24, 'estimated_total_time_sec': 1377.9, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9567.13, 'avg_tokens_per_second': 10925.73}\n",
    "{'loss': 1.151, 'grad_norm': 2.5563783645629883, 'learning_rate': 3.5711733274940054e-06, 'epoch': 0.5, 'num_input_tokens_seen': 7490560, 'step': 91, 'step_time_sec': 6.89, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 692.06, 'estimated_total_time_sec': 1376.61, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12178.59, 'avg_tokens_per_second': 10938.49}\n",
    "{'loss': 1.0929, 'grad_norm': 2.51374888420105, 'learning_rate': 3.5146550146379353e-06, 'epoch': 0.5, 'num_input_tokens_seen': 7583744, 'step': 92, 'step_time_sec': 7.78, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 684.8, 'estimated_total_time_sec': 1377.13, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11973.6, 'avg_tokens_per_second': 10950.25}\n",
    "{'loss': 1.0877, 'grad_norm': 2.8339293003082275, 'learning_rate': 3.4579478526566237e-06, 'epoch': 0.51, 'num_input_tokens_seen': 7659520, 'step': 93, 'step_time_sec': 5.79, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 675.58, 'estimated_total_time_sec': 1373.68, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 13079.08, 'avg_tokens_per_second': 10968.11}\n",
    "{'loss': 1.1348, 'grad_norm': 2.4670252799987793, 'learning_rate': 3.4010726498539453e-06, 'epoch': 0.51, 'num_input_tokens_seen': 7747584, 'step': 94, 'step_time_sec': 9.13, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 669.63, 'estimated_total_time_sec': 1376.88, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9645.57, 'avg_tokens_per_second': 10950.86}\n",
    "{'loss': 1.1428, 'grad_norm': 2.453486919403076, 'learning_rate': 3.344050276195202e-06, 'epoch': 0.52, 'num_input_tokens_seen': 7855104, 'step': 95, 'step_time_sec': 9.14, 'avg_step_time_sec': 7.54, 'time_to_completion_sec': 663.62, 'estimated_total_time_sec': 1380.03, 'step_peak_memory_allocated_MB': 41841.51, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11759.85, 'avg_tokens_per_second': 10961.29}\n",
    "{'loss': 1.1566, 'grad_norm': 2.6072633266448975, 'learning_rate': 3.286901655649027e-06, 'epoch': 0.52, 'num_input_tokens_seen': 7945216, 'step': 96, 'step_time_sec': 9.29, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 657.68, 'estimated_total_time_sec': 1383.4, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9699.23, 'avg_tokens_per_second': 10944.96}\n",
    "{'loss': 1.1617, 'grad_norm': 2.4179818630218506, 'learning_rate': 3.229647758509488e-06, 'epoch': 0.53, 'num_input_tokens_seen': 8022016, 'step': 97, 'step_time_sec': 8.63, 'avg_step_time_sec': 7.57, 'time_to_completion_sec': 651.08, 'estimated_total_time_sec': 1385.44, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 8897.99, 'avg_tokens_per_second': 10920.65}\n",
    "{'loss': 1.1589, 'grad_norm': 2.5483219623565674, 'learning_rate': 3.1723095937011706e-06, 'epoch': 0.54, 'num_input_tokens_seen': 8097792, 'step': 98, 'step_time_sec': 8.55, 'avg_step_time_sec': 7.58, 'time_to_completion_sec': 644.37, 'estimated_total_time_sec': 1387.28, 'step_peak_memory_allocated_MB': 42885.09, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 8866.22, 'avg_tokens_per_second': 10896.78}\n",
    "{'loss': 1.139, 'grad_norm': 2.776958703994751, 'learning_rate': 3.1149082010701064e-06, 'epoch': 0.54, 'num_input_tokens_seen': 8176640, 'step': 99, 'step_time_sec': 6.98, 'avg_step_time_sec': 7.57, 'time_to_completion_sec': 636.27, 'estimated_total_time_sec': 1386.16, 'step_peak_memory_allocated_MB': 40740.84, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11297.0, 'avg_tokens_per_second': 10900.54}\n",
    "{'loss': 1.2104, 'grad_norm': 2.541374921798706, 'learning_rate': 3.0574646436633425e-06, 'epoch': 0.55, 'num_input_tokens_seen': 8251392, 'step': 100, 'step_time_sec': 6.16, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 627.51, 'estimated_total_time_sec': 1383.55, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12128.14, 'avg_tokens_per_second': 10910.65}\n",
    "{'loss': 1.1968, 'grad_norm': 2.4191529750823975, 'learning_rate': 3e-06, 'epoch': 0.55, 'num_input_tokens_seen': 8340480, 'step': 101, 'step_time_sec': 7.8, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 620.15, 'estimated_total_time_sec': 1383.98, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11428.15, 'avg_tokens_per_second': 10915.98}\n",
    "{'loss': 1.1057, 'grad_norm': 2.357393264770508, 'learning_rate': 2.9425353563366576e-06, 'epoch': 0.56, 'num_input_tokens_seen': 8425472, 'step': 102, 'step_time_sec': 7.94, 'avg_step_time_sec': 7.57, 'time_to_completion_sec': 612.89, 'estimated_total_time_sec': 1384.67, 'step_peak_memory_allocated_MB': 41841.51, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10702.62, 'avg_tokens_per_second': 10913.77}\n",
    "{'loss': 1.1354, 'grad_norm': 2.4089536666870117, 'learning_rate': 2.885091798929894e-06, 'epoch': 0.56, 'num_input_tokens_seen': 8506368, 'step': 103, 'step_time_sec': 7.41, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 605.2, 'estimated_total_time_sec': 1384.39, 'step_peak_memory_allocated_MB': 41031.35, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10912.66, 'avg_tokens_per_second': 10913.75}\n",
    "{'loss': 1.1015, 'grad_norm': 2.66099214553833, 'learning_rate': 2.8276904062988304e-06, 'epoch': 0.57, 'num_input_tokens_seen': 8586240, 'step': 104, 'step_time_sec': 8.68, 'avg_step_time_sec': 7.58, 'time_to_completion_sec': 598.49, 'estimated_total_time_sec': 1386.38, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9201.59, 'avg_tokens_per_second': 10894.71}\n",
    "{'loss': 1.0959, 'grad_norm': 2.3865387439727783, 'learning_rate': 2.770352241490513e-06, 'epoch': 0.57, 'num_input_tokens_seen': 8655872, 'step': 105, 'step_time_sec': 6.08, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 589.79, 'estimated_total_time_sec': 1383.75, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11448.74, 'avg_tokens_per_second': 10898.99}\n",
    "{'loss': 1.0872, 'grad_norm': 2.7860469818115234, 'learning_rate': 2.7130983443509734e-06, 'epoch': 0.58, 'num_input_tokens_seen': 8749056, 'step': 106, 'step_time_sec': 7.59, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 582.25, 'estimated_total_time_sec': 1383.8, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12275.84, 'avg_tokens_per_second': 10912.16}\n",
    "{'loss': 1.1175, 'grad_norm': 2.577706813812256, 'learning_rate': 2.655949723804799e-06, 'epoch': 0.58, 'num_input_tokens_seen': 8835072, 'step': 107, 'step_time_sec': 9.13, 'avg_step_time_sec': 7.58, 'time_to_completion_sec': 575.82, 'estimated_total_time_sec': 1386.51, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9419.59, 'avg_tokens_per_second': 10895.19}\n",
    "{'loss': 1.1321, 'grad_norm': 2.7383525371551514, 'learning_rate': 2.5989273501460544e-06, 'epoch': 0.59, 'num_input_tokens_seen': 8906752, 'step': 108, 'step_time_sec': 6.16, 'avg_step_time_sec': 7.56, 'time_to_completion_sec': 567.25, 'estimated_total_time_sec': 1384.08, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11639.6, 'avg_tokens_per_second': 10900.85}\n",
    "{'loss': 1.1107, 'grad_norm': 2.6210103034973145, 'learning_rate': 2.5420521473433765e-06, 'epoch': 0.6, 'num_input_tokens_seen': 8986624, 'step': 109, 'step_time_sec': 6.38, 'avg_step_time_sec': 7.55, 'time_to_completion_sec': 558.88, 'estimated_total_time_sec': 1382.09, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12510.46, 'avg_tokens_per_second': 10913.45}\n",
    "{'loss': 1.1322, 'grad_norm': 2.3475868701934814, 'learning_rate': 2.485344985362065e-06, 'epoch': 0.6, 'num_input_tokens_seen': 9068544, 'step': 110, 'step_time_sec': 6.4, 'avg_step_time_sec': 7.54, 'time_to_completion_sec': 550.55, 'estimated_total_time_sec': 1380.15, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12805.61, 'avg_tokens_per_second': 10928.17}\n",
    "{'loss': 1.1151, 'grad_norm': 2.3852245807647705, 'learning_rate': 2.4288266725059947e-06, 'epoch': 0.61, 'num_input_tokens_seen': 9144320, 'step': 111, 'step_time_sec': 6.09, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 542.05, 'estimated_total_time_sec': 1377.72, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12452.62, 'avg_tokens_per_second': 10939.38}\n",
    "{'loss': 1.0306, 'grad_norm': 2.5751078128814697, 'learning_rate': 2.372517947782151e-06, 'epoch': 0.61, 'num_input_tokens_seen': 9236480, 'step': 112, 'step_time_sec': 9.19, 'avg_step_time_sec': 7.54, 'time_to_completion_sec': 535.59, 'estimated_total_time_sec': 1380.46, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10029.74, 'avg_tokens_per_second': 10929.39}\n",
    "{'loss': 1.0725, 'grad_norm': 2.501106023788452, 'learning_rate': 2.316439473290588e-06, 'epoch': 0.62, 'num_input_tokens_seen': 9296896, 'step': 113, 'step_time_sec': 4.59, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 526.2, 'estimated_total_time_sec': 1375.63, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 13162.53, 'avg_tokens_per_second': 10941.57}\n",
    "{'loss': 1.1429, 'grad_norm': 2.3226068019866943, 'learning_rate': 2.260611826642623e-06, 'epoch': 0.62, 'num_input_tokens_seen': 9391104, 'step': 114, 'step_time_sec': 9.22, 'avg_step_time_sec': 7.53, 'time_to_completion_sec': 519.72, 'estimated_total_time_sec': 1378.38, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10222.81, 'avg_tokens_per_second': 10933.79}\n",
    "{'loss': 1.1509, 'grad_norm': 2.5047190189361572, 'learning_rate': 2.2050554934100157e-06, 'epoch': 0.63, 'num_input_tokens_seen': 9465856, 'step': 115, 'step_time_sec': 5.88, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 511.2, 'estimated_total_time_sec': 1375.73, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12721.62, 'avg_tokens_per_second': 10946.04}\n",
    "{'loss': 1.0915, 'grad_norm': 2.583066701889038, 'learning_rate': 2.149790859607929e-06, 'epoch': 0.63, 'num_input_tokens_seen': 9532416, 'step': 116, 'step_time_sec': 5.61, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 502.57, 'estimated_total_time_sec': 1372.69, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11871.07, 'avg_tokens_per_second': 10952.06}\n",
    "{'loss': 1.1446, 'grad_norm': 2.6494877338409424, 'learning_rate': 2.0948382042144234e-06, 'epoch': 0.64, 'num_input_tokens_seen': 9600000, 'step': 117, 'step_time_sec': 6.42, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 494.45, 'estimated_total_time_sec': 1370.97, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10534.14, 'avg_tokens_per_second': 10948.97}\n",
    "{'loss': 1.0731, 'grad_norm': 2.4706413745880127, 'learning_rate': 2.0402176917292237e-06, 'epoch': 0.64, 'num_input_tokens_seen': 9672704, 'step': 118, 'step_time_sec': 6.07, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 486.17, 'estimated_total_time_sec': 1368.75, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11976.65, 'avg_tokens_per_second': 10956.1}\n",
    "{'loss': 1.1462, 'grad_norm': 2.372274398803711, 'learning_rate': 1.9859493647744925e-06, 'epoch': 0.65, 'num_input_tokens_seen': 9756672, 'step': 119, 'step_time_sec': 6.41, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 478.11, 'estimated_total_time_sec': 1367.09, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 13105.04, 'avg_tokens_per_second': 10971.72}\n",
    "{'loss': 1.0266, 'grad_norm': 2.444197416305542, 'learning_rate': 1.9320531367403304e-06, 'epoch': 0.66, 'num_input_tokens_seen': 9847808, 'step': 120, 'step_time_sec': 9.2, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 471.55, 'estimated_total_time_sec': 1369.74, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9907.66, 'avg_tokens_per_second': 10960.73}\n",
    "{'loss': 1.1324, 'grad_norm': 2.5069875717163086, 'learning_rate': 1.8785487844776938e-06, 'epoch': 0.66, 'num_input_tokens_seen': 9929728, 'step': 121, 'step_time_sec': 6.75, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 463.69, 'estimated_total_time_sec': 1368.63, 'step_peak_memory_allocated_MB': 40451.33, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12129.38, 'avg_tokens_per_second': 10969.53}\n",
    "{'loss': 1.091, 'grad_norm': 2.567671775817871, 'learning_rate': 1.8254559410414134e-06, 'epoch': 0.67, 'num_input_tokens_seen': 10004480, 'step': 122, 'step_time_sec': 5.82, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 455.37, 'estimated_total_time_sec': 1366.12, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12841.37, 'avg_tokens_per_second': 10981.59}\n",
    "{'loss': 1.171, 'grad_norm': 2.566594362258911, 'learning_rate': 1.7727940884859804e-06, 'epoch': 0.67, 'num_input_tokens_seen': 10086400, 'step': 123, 'step_time_sec': 7.86, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 448.1, 'estimated_total_time_sec': 1366.71, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10424.5, 'avg_tokens_per_second': 10976.78}\n",
    "{'loss': 1.064, 'grad_norm': 2.5213539600372314, 'learning_rate': 1.7205825507167408e-06, 'epoch': 0.68, 'num_input_tokens_seen': 10168320, 'step': 124, 'step_time_sec': 8.18, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 440.97, 'estimated_total_time_sec': 1367.77, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10017.94, 'avg_tokens_per_second': 10968.26}\n",
    "{'loss': 1.0747, 'grad_norm': 2.4884233474731445, 'learning_rate': 1.6688404863991208e-06, 'epoch': 0.68, 'num_input_tokens_seen': 10247168, 'step': 125, 'step_time_sec': 6.95, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 433.26, 'estimated_total_time_sec': 1367.0, 'step_peak_memory_allocated_MB': 40740.84, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11338.5, 'avg_tokens_per_second': 10971.03}\n",
    "{'loss': 1.0619, 'grad_norm': 2.507038116455078, 'learning_rate': 1.6175868819284853e-06, 'epoch': 0.69, 'num_input_tokens_seen': 10338304, 'step': 126, 'step_time_sec': 8.18, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 426.11, 'estimated_total_time_sec': 1368.04, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11140.65, 'avg_tokens_per_second': 10972.52}\n",
    "{'loss': 1.077, 'grad_norm': 2.4728050231933594, 'learning_rate': 1.5668405444632109e-06, 'epoch': 0.69, 'num_input_tokens_seen': 10424320, 'step': 127, 'step_time_sec': 9.29, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 419.44, 'estimated_total_time_sec': 1370.67, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9260.22, 'avg_tokens_per_second': 10955.67}\n",
    "{'loss': 1.0431, 'grad_norm': 2.6263201236724854, 'learning_rate': 1.5166200950235286e-06, 'epoch': 0.7, 'num_input_tokens_seen': 10506240, 'step': 128, 'step_time_sec': 8.41, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 412.35, 'estimated_total_time_sec': 1372.0, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9739.33, 'avg_tokens_per_second': 10944.92}\n",
    "{'loss': 1.0291, 'grad_norm': 2.4672482013702393, 'learning_rate': 1.4669439616586685e-06, 'epoch': 0.7, 'num_input_tokens_seen': 10572800, 'step': 129, 'step_time_sec': 5.75, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 404.12, 'estimated_total_time_sec': 1369.51, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11568.85, 'avg_tokens_per_second': 10948.67}\n",
    "{'loss': 1.1456, 'grad_norm': 2.436051368713379, 'learning_rate': 1.4178303726848122e-06, 'epoch': 0.71, 'num_input_tokens_seen': 10653696, 'step': 130, 'step_time_sec': 6.72, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 396.32, 'estimated_total_time_sec': 1368.43, 'step_peak_memory_allocated_MB': 40451.33, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12034.83, 'avg_tokens_per_second': 10956.24}\n",
    "{'loss': 1.0425, 'grad_norm': 2.6713452339172363, 'learning_rate': 1.3692973499963369e-06, 'epoch': 0.72, 'num_input_tokens_seen': 10747904, 'step': 131, 'step_time_sec': 9.2, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 389.53, 'estimated_total_time_sec': 1370.85, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10244.3, 'avg_tokens_per_second': 10949.51}\n",
    "{'loss': 0.9619, 'grad_norm': 2.421201467514038, 'learning_rate': 1.321362702452808e-06, 'epoch': 0.72, 'num_input_tokens_seen': 10843136, 'step': 132, 'step_time_sec': 9.2, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 382.71, 'estimated_total_time_sec': 1373.24, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10348.81, 'avg_tokens_per_second': 10943.89}\n",
    "{'loss': 1.0674, 'grad_norm': 3.4261064529418945, 'learning_rate': 1.2740440193441384e-06, 'epoch': 0.73, 'num_input_tokens_seen': 10920960, 'step': 133, 'step_time_sec': 7.27, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 375.11, 'estimated_total_time_sec': 1372.91, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10707.76, 'avg_tokens_per_second': 10942.16}\n",
    "{'loss': 1.1251, 'grad_norm': 2.798006057739258, 'learning_rate': 1.2273586639363195e-06, 'epoch': 0.73, 'num_input_tokens_seen': 11003904, 'step': 134, 'step_time_sec': 9.12, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 368.2, 'estimated_total_time_sec': 1375.13, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9097.37, 'avg_tokens_per_second': 10925.33}\n",
    "{'loss': 1.0453, 'grad_norm': 2.493957281112671, 'learning_rate': 1.1813237671000868e-06, 'epoch': 0.74, 'num_input_tokens_seen': 11094016, 'step': 135, 'step_time_sec': 8.27, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 360.96, 'estimated_total_time_sec': 1376.17, 'step_peak_memory_allocated_MB': 42364.27, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10890.09, 'avg_tokens_per_second': 10925.04}\n",
    "{'loss': 1.1178, 'grad_norm': 2.547833204269409, 'learning_rate': 1.1359562210248713e-06, 'epoch': 0.74, 'num_input_tokens_seen': 11180032, 'step': 136, 'step_time_sec': 6.99, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 353.26, 'estimated_total_time_sec': 1375.45, 'step_peak_memory_allocated_MB': 40740.84, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12312.48, 'avg_tokens_per_second': 10934.59}\n",
    "{'loss': 1.1181, 'grad_norm': 2.5407068729400635, 'learning_rate': 1.0912726730203213e-06, 'epoch': 0.75, 'num_input_tokens_seen': 11264000, 'step': 137, 'step_time_sec': 7.93, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 345.88, 'estimated_total_time_sec': 1376.0, 'step_peak_memory_allocated_MB': 41841.51, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10594.81, 'avg_tokens_per_second': 10931.96}\n",
    "{'loss': 1.0575, 'grad_norm': 2.367995262145996, 'learning_rate': 1.0472895194076868e-06, 'epoch': 0.75, 'num_input_tokens_seen': 11332608, 'step': 138, 'step_time_sec': 5.3, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 337.63, 'estimated_total_time_sec': 1373.03, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12942.33, 'avg_tokens_per_second': 10942.33}\n",
    "{'loss': 1.1314, 'grad_norm': 2.3791825771331787, 'learning_rate': 1.0040228995033042e-06, 'epoch': 0.76, 'num_input_tokens_seen': 11422720, 'step': 139, 'step_time_sec': 8.57, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 330.47, 'estimated_total_time_sec': 1374.45, 'step_peak_memory_allocated_MB': 42885.09, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10517.3, 'avg_tokens_per_second': 10938.81}\n",
    "{'loss': 1.1172, 'grad_norm': 2.559088945388794, 'learning_rate': 9.614886896963835e-07, 'epoch': 0.77, 'num_input_tokens_seen': 11492352, 'step': 140, 'step_time_sec': 6.35, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 322.6, 'estimated_total_time_sec': 1372.92, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10959.34, 'avg_tokens_per_second': 10938.94}\n",
    "{'loss': 1.0661, 'grad_norm': 2.3878214359283447, 'learning_rate': 9.197024976232752e-07, 'epoch': 0.77, 'num_input_tokens_seen': 11575296, 'step': 141, 'step_time_sec': 7.77, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 315.18, 'estimated_total_time_sec': 1373.28, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10668.42, 'avg_tokens_per_second': 10936.94}\n",
    "{'loss': 1.1311, 'grad_norm': 2.4701602458953857, 'learning_rate': 8.786796564403577e-07, 'epoch': 0.78, 'num_input_tokens_seen': 11664384, 'step': 142, 'step_time_sec': 7.92, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 307.8, 'estimated_total_time_sec': 1373.82, 'step_peak_memory_allocated_MB': 41841.51, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11250.07, 'avg_tokens_per_second': 10939.28}\n",
    "{'loss': 1.0822, 'grad_norm': 2.376356363296509, 'learning_rate': 8.384352191976392e-07, 'epoch': 0.78, 'num_input_tokens_seen': 11745280, 'step': 143, 'step_time_sec': 8.16, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 300.47, 'estimated_total_time_sec': 1374.65, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9917.73, 'avg_tokens_per_second': 10931.47}\n",
    "{'loss': 1.0613, 'grad_norm': 2.41853928565979, 'learning_rate': 7.989839533151444e-07, 'epoch': 0.79, 'num_input_tokens_seen': 11842560, 'step': 144, 'step_time_sec': 8.28, 'avg_step_time_sec': 7.52, 'time_to_completion_sec': 293.17, 'estimated_total_time_sec': 1375.63, 'step_peak_memory_allocated_MB': 42364.27, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11754.7, 'avg_tokens_per_second': 10937.8}\n",
    "{'loss': 1.0419, 'grad_norm': 2.442612886428833, 'learning_rate': 7.603403351641119e-07, 'epoch': 0.79, 'num_input_tokens_seen': 11919360, 'step': 145, 'step_time_sec': 6.72, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 285.44, 'estimated_total_time_sec': 1374.61, 'step_peak_memory_allocated_MB': 40451.33, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11434.99, 'avg_tokens_per_second': 10940.89}\n",
    "{'loss': 1.1004, 'grad_norm': 2.3376307487487793, 'learning_rate': 7.225185447549883e-07, 'epoch': 0.8, 'num_input_tokens_seen': 11984896, 'step': 146, 'step_time_sec': 5.74, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 277.47, 'estimated_total_time_sec': 1372.38, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11422.88, 'avg_tokens_per_second': 10943.43}\n",
    "{'loss': 1.0371, 'grad_norm': 2.3493547439575195, 'learning_rate': 6.855324605341711e-07, 'epoch': 0.8, 'num_input_tokens_seen': 12085248, 'step': 147, 'step_time_sec': 9.12, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 270.38, 'estimated_total_time_sec': 1374.41, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11003.83, 'avg_tokens_per_second': 10943.94}\n",
    "{'loss': 0.9934, 'grad_norm': 2.631024122238159, 'learning_rate': 6.493956542914075e-07, 'epoch': 0.81, 'num_input_tokens_seen': 12153856, 'step': 148, 'step_time_sec': 5.8, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 262.46, 'estimated_total_time_sec': 1372.27, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11832.64, 'avg_tokens_per_second': 10948.61}\n",
    "{'loss': 1.0674, 'grad_norm': 2.478576183319092, 'learning_rate': 6.141213861797204e-07, 'epoch': 0.81, 'num_input_tokens_seen': 12234752, 'step': 149, 'step_time_sec': 7.34, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 254.92, 'estimated_total_time_sec': 1372.07, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11027.43, 'avg_tokens_per_second': 10949.13}\n",
    "{'loss': 1.0946, 'grad_norm': 2.732083559036255, 'learning_rate': 5.797225998496851e-07, 'epoch': 0.82, 'num_input_tokens_seen': 12311552, 'step': 150, 'step_time_sec': 7.33, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 247.39, 'estimated_total_time_sec': 1371.86, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10483.1, 'avg_tokens_per_second': 10946.08}\n",
    "{'loss': 1.0725, 'grad_norm': 2.326475143432617, 'learning_rate': 5.462119176998471e-07, 'epoch': 0.83, 'num_input_tokens_seen': 12406784, 'step': 151, 'step_time_sec': 8.16, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 240.03, 'estimated_total_time_sec': 1372.67, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11676.05, 'avg_tokens_per_second': 10951.37}\n",
    "{'loss': 1.0518, 'grad_norm': 2.6012845039367676, 'learning_rate': 5.136016362450165e-07, 'epoch': 0.83, 'num_input_tokens_seen': 12479488, 'step': 152, 'step_time_sec': 6.45, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 232.31, 'estimated_total_time_sec': 1371.39, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11276.06, 'avg_tokens_per_second': 10953.22}\n",
    "{'loss': 1.1034, 'grad_norm': 2.375689744949341, 'learning_rate': 4.819037216041501e-07, 'epoch': 0.84, 'num_input_tokens_seen': 12571648, 'step': 153, 'step_time_sec': 9.29, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 225.17, 'estimated_total_time_sec': 1373.55, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9920.56, 'avg_tokens_per_second': 10944.81}\n",
    "{'loss': 1.086, 'grad_norm': 2.5424656867980957, 'learning_rate': 4.511298051094641e-07, 'epoch': 0.84, 'num_input_tokens_seen': 12642304, 'step': 154, 'step_time_sec': 5.75, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 217.33, 'estimated_total_time_sec': 1371.45, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12284.76, 'avg_tokens_per_second': 10951.53}\n",
    "{'loss': 1.0271, 'grad_norm': 2.3602185249328613, 'learning_rate': 4.212911790383971e-07, 'epoch': 0.85, 'num_input_tokens_seen': 12731392, 'step': 155, 'step_time_sec': 9.29, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 210.17, 'estimated_total_time_sec': 1373.59, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9588.61, 'avg_tokens_per_second': 10940.58}\n",
    "{'loss': 1.1073, 'grad_norm': 2.5697944164276123, 'learning_rate': 3.9239879246998476e-07, 'epoch': 0.85, 'num_input_tokens_seen': 12809216, 'step': 156, 'step_time_sec': 8.15, 'avg_step_time_sec': 7.51, 'time_to_completion_sec': 202.77, 'estimated_total_time_sec': 1374.35, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9550.6, 'avg_tokens_per_second': 10930.85}\n",
    "{'loss': 1.1038, 'grad_norm': 2.5351736545562744, 'learning_rate': 3.644632472671734e-07, 'epoch': 0.86, 'num_input_tokens_seen': 12874752, 'step': 157, 'step_time_sec': 5.34, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 194.9, 'estimated_total_time_sec': 1371.8, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12271.71, 'avg_tokens_per_second': 10936.97}\n",
    "{'loss': 0.9982, 'grad_norm': 2.4083731174468994, 'learning_rate': 3.3749479418653716e-07, 'epoch': 0.86, 'num_input_tokens_seen': 12938240, 'step': 158, 'step_time_sec': 5.11, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 187.02, 'estimated_total_time_sec': 1369.02, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12435.82, 'avg_tokens_per_second': 10943.48}\n",
    "{'loss': 1.0198, 'grad_norm': 2.444545030593872, 'learning_rate': 3.1150332911683354e-07, 'epoch': 0.87, 'num_input_tokens_seen': 13028352, 'step': 159, 'step_time_sec': 8.16, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 179.65, 'estimated_total_time_sec': 1369.8, 'step_peak_memory_allocated_MB': 39293.13, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11045.9, 'avg_tokens_per_second': 10944.19}\n",
    "{'loss': 1.0704, 'grad_norm': 2.52502179145813, 'learning_rate': 2.864983894477752e-07, 'epoch': 0.87, 'num_input_tokens_seen': 13103104, 'step': 160, 'step_time_sec': 5.81, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 171.92, 'estimated_total_time_sec': 1367.88, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12860.78, 'avg_tokens_per_second': 10953.56}\n",
    "{'loss': 1.0468, 'grad_norm': 2.5194032192230225, 'learning_rate': 2.6248915057035006e-07, 'epoch': 0.88, 'num_input_tokens_seen': 13184000, 'step': 161, 'step_time_sec': 9.08, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 164.66, 'estimated_total_time_sec': 1369.71, 'step_peak_memory_allocated_MB': 43928.95, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 8913.82, 'avg_tokens_per_second': 10938.11}\n",
    "{'loss': 1.074, 'grad_norm': 2.353602886199951, 'learning_rate': 2.394844225099747e-07, 'epoch': 0.89, 'num_input_tokens_seen': 13264896, 'step': 162, 'step_time_sec': 6.59, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 157.06, 'estimated_total_time_sec': 1368.69, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12276.29, 'avg_tokens_per_second': 10945.43}\n",
    "{'loss': 1.0438, 'grad_norm': 2.413208246231079, 'learning_rate': 2.1749264669371616e-07, 'epoch': 0.89, 'num_input_tokens_seen': 13351936, 'step': 163, 'step_time_sec': 9.3, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 149.81, 'estimated_total_time_sec': 1370.74, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9361.24, 'avg_tokens_per_second': 10933.29}\n",
    "{'loss': 1.1109, 'grad_norm': 2.470350503921509, 'learning_rate': 1.96521892852767e-07, 'epoch': 0.9, 'num_input_tokens_seen': 13422592, 'step': 164, 'step_time_sec': 8.27, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 142.41, 'estimated_total_time_sec': 1371.61, 'step_peak_memory_allocated_MB': 42364.27, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 8548.6, 'avg_tokens_per_second': 10917.16}\n",
    "{'loss': 0.9841, 'grad_norm': 2.50467848777771, 'learning_rate': 1.7657985606131544e-07, 'epoch': 0.9, 'num_input_tokens_seen': 13504512, 'step': 165, 'step_time_sec': 8.27, 'avg_step_time_sec': 7.5, 'time_to_completion_sec': 135.0, 'estimated_total_time_sec': 1372.47, 'step_peak_memory_allocated_MB': 42364.27, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9911.11, 'avg_tokens_per_second': 10910.4}\n",
    "{'loss': 1.0556, 'grad_norm': 2.4573974609375, 'learning_rate': 1.5767385391288725e-07, 'epoch': 0.91, 'num_input_tokens_seen': 13577216, 'step': 166, 'step_time_sec': 6.35, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 127.38, 'estimated_total_time_sec': 1371.2, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11449.55, 'avg_tokens_per_second': 10913.17}\n",
    "{'loss': 1.0489, 'grad_norm': 2.452732801437378, 'learning_rate': 1.3981082383520837e-07, 'epoch': 0.91, 'num_input_tokens_seen': 13632512, 'step': 167, 'step_time_sec': 4.36, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 119.58, 'estimated_total_time_sec': 1367.75, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12676.27, 'avg_tokens_per_second': 10919.37}\n",
    "{'loss': 1.0673, 'grad_norm': 2.584343910217285, 'learning_rate': 1.2299732054456092e-07, 'epoch': 0.92, 'num_input_tokens_seen': 13705216, 'step': 168, 'step_time_sec': 6.13, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 111.99, 'estimated_total_time_sec': 1366.27, 'step_peak_memory_allocated_MB': 38308.46, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11863.23, 'avg_tokens_per_second': 10924.0}\n",
    "{'loss': 1.0786, 'grad_norm': 2.413900375366211, 'learning_rate': 1.0723951364057705e-07, 'epoch': 0.92, 'num_input_tokens_seen': 13786112, 'step': 169, 'step_time_sec': 6.41, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 104.44, 'estimated_total_time_sec': 1365.12, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12614.61, 'avg_tokens_per_second': 10932.66}\n",
    "{'loss': 1.0848, 'grad_norm': 2.5445902347564697, 'learning_rate': 9.25431853423443e-08, 'epoch': 0.93, 'num_input_tokens_seen': 13872128, 'step': 170, 'step_time_sec': 9.2, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 97.11, 'estimated_total_time_sec': 1367.01, 'step_peak_memory_allocated_MB': 38308.48, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9348.87, 'avg_tokens_per_second': 10921.11}\n",
    "{'loss': 1.1052, 'grad_norm': 2.301790237426758, 'learning_rate': 7.891372836666311e-08, 'epoch': 0.93, 'num_input_tokens_seen': 13957120, 'step': 171, 'step_time_sec': 7.51, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 89.64, 'estimated_total_time_sec': 1367.06, 'step_peak_memory_allocated_MB': 39003.01, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11310.78, 'avg_tokens_per_second': 10923.42}\n",
    "{'loss': 1.0402, 'grad_norm': 2.4266223907470703, 'learning_rate': 6.635614394922274e-08, 'epoch': 0.94, 'num_input_tokens_seen': 14035968, 'step': 172, 'step_time_sec': 8.26, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 82.22, 'estimated_total_time_sec': 1367.9, 'step_peak_memory_allocated_MB': 42364.27, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9547.91, 'avg_tokens_per_second': 10914.53}\n",
    "{'loss': 1.0714, 'grad_norm': 2.4250941276550293, 'learning_rate': 5.487504000943522e-08, 'epoch': 0.95, 'num_input_tokens_seen': 14115840, 'step': 173, 'step_time_sec': 6.84, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 74.71, 'estimated_total_time_sec': 1367.22, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11682.06, 'avg_tokens_per_second': 10918.62}\n",
    "{'loss': 1.0155, 'grad_norm': 2.409923791885376, 'learning_rate': 4.447462945959024e-08, 'epoch': 0.95, 'num_input_tokens_seen': 14201856, 'step': 174, 'step_time_sec': 7.84, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 67.26, 'estimated_total_time_sec': 1367.61, 'step_peak_memory_allocated_MB': 40740.84, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10972.44, 'avg_tokens_per_second': 10918.94}\n",
    "{'loss': 1.0005, 'grad_norm': 2.456784248352051, 'learning_rate': 3.515872865895475e-08, 'epoch': 0.96, 'num_input_tokens_seen': 14269440, 'step': 175, 'step_time_sec': 5.79, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 59.71, 'estimated_total_time_sec': 1365.84, 'step_peak_memory_allocated_MB': 38308.44, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11677.54, 'avg_tokens_per_second': 10922.32}\n",
    "{'loss': 1.1243, 'grad_norm': 2.431488275527954, 'learning_rate': 2.693075601338646e-08, 'epoch': 0.96, 'num_input_tokens_seen': 14337024, 'step': 176, 'step_time_sec': 6.16, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 52.19, 'estimated_total_time_sec': 1364.47, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10972.35, 'avg_tokens_per_second': 10922.56}\n",
    "{'loss': 1.0873, 'grad_norm': 2.33998703956604, 'learning_rate': 1.9793730720974902e-08, 'epoch': 0.97, 'num_input_tokens_seen': 14414848, 'step': 177, 'step_time_sec': 6.83, 'avg_step_time_sec': 7.45, 'time_to_completion_sec': 44.72, 'estimated_total_time_sec': 1363.83, 'step_peak_memory_allocated_MB': 39871.28, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11390.07, 'avg_tokens_per_second': 10924.99}\n",
    "{'loss': 1.0859, 'grad_norm': 2.5222296714782715, 'learning_rate': 1.3750271664165315e-08, 'epoch': 0.97, 'num_input_tokens_seen': 14509056, 'step': 178, 'step_time_sec': 9.11, 'avg_step_time_sec': 7.46, 'time_to_completion_sec': 37.31, 'estimated_total_time_sec': 1365.54, 'step_peak_memory_allocated_MB': 40161.53, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10345.09, 'avg_tokens_per_second': 10921.0}\n",
    "{'loss': 1.1219, 'grad_norm': 2.6023123264312744, 'learning_rate': 8.802596448778677e-09, 'epoch': 0.98, 'num_input_tokens_seen': 14620672, 'step': 179, 'step_time_sec': 9.3, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 29.89, 'estimated_total_time_sec': 1367.43, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11999.17, 'avg_tokens_per_second': 10928.54}\n",
    "{'loss': 1.0906, 'grad_norm': 2.523496389389038, 'learning_rate': 4.952520590276621e-09, 'epoch': 0.98, 'num_input_tokens_seen': 14706688, 'step': 180, 'step_time_sec': 7.29, 'avg_step_time_sec': 7.47, 'time_to_completion_sec': 22.41, 'estimated_total_time_sec': 1367.24, 'step_peak_memory_allocated_MB': 39582.71, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 11805.69, 'avg_tokens_per_second': 10933.31}\n",
    "{'loss': 1.0803, 'grad_norm': 2.334371566772461, 'learning_rate': 2.201456847570005e-09, 'epoch': 0.99, 'num_input_tokens_seen': 14794752, 'step': 181, 'step_time_sec': 9.11, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 14.96, 'estimated_total_time_sec': 1368.91, 'step_peak_memory_allocated_MB': 38424.56, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 9665.04, 'avg_tokens_per_second': 10924.73}\n",
    "{'loss': 1.0846, 'grad_norm': 2.439408540725708, 'learning_rate': 5.504147046169195e-10, 'epoch': 0.99, 'num_input_tokens_seen': 14891008, 'step': 182, 'step_time_sec': 9.28, 'avg_step_time_sec': 7.49, 'time_to_completion_sec': 7.49, 'estimated_total_time_sec': 1370.73, 'step_peak_memory_allocated_MB': 44450.96, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 10369.47, 'avg_tokens_per_second': 10920.93}\n",
    "{'loss': 1.0233, 'grad_norm': 2.4924302101135254, 'learning_rate': 0.0, 'epoch': 1.0, 'num_input_tokens_seen': 14966784, 'step': 183, 'step_time_sec': 6.06, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 0.0, 'estimated_total_time_sec': 1369.29, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12502.43, 'avg_tokens_per_second': 10927.97}\n",
    "{'train_runtime': 1394.6588, 'train_samples_per_second': 33.557, 'train_steps_per_second': 0.131, 'train_loss': 1.1385395650655195, 'epoch': 1.0, 'num_input_tokens_seen': 14966784, 'step': 183, 'step_time_sec': 6.06, 'avg_step_time_sec': 7.48, 'time_to_completion_sec': 0.0, 'estimated_total_time_sec': 1369.29, 'step_peak_memory_allocated_MB': 38714.8, 'total_peak_memory_allocated_MB': 44450.96, 'step_peak_memory_reserved_MB': 76254.0, 'total_peak_memory_reserved_MB': 76254.0, 'step_tokens_per_second': 12502.43, 'avg_tokens_per_second': 10927.97}\n",
    "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 183/183 [23:14<00:00,  7.62s/it]\n",
    "(\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c55b95-5b10-4f32-b946-c208bb14e2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>num_input_tokens_seen</th>\n",
       "      <th>step</th>\n",
       "      <th>step_time_sec</th>\n",
       "      <th>avg_step_time_sec</th>\n",
       "      <th>time_to_completion_sec</th>\n",
       "      <th>estimated_total_time_sec</th>\n",
       "      <th>step_peak_memory_allocated_MB</th>\n",
       "      <th>total_peak_memory_allocated_MB</th>\n",
       "      <th>step_peak_memory_reserved_MB</th>\n",
       "      <th>total_peak_memory_reserved_MB</th>\n",
       "      <th>step_tokens_per_second</th>\n",
       "      <th>avg_tokens_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3760</td>\n",
       "      <td>9.614106</td>\n",
       "      <td>6.315789e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>174080</td>\n",
       "      <td>2</td>\n",
       "      <td>9.16</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1657.44</td>\n",
       "      <td>1675.76</td>\n",
       "      <td>38308.48</td>\n",
       "      <td>38308.48</td>\n",
       "      <td>58820.0</td>\n",
       "      <td>58820.0</td>\n",
       "      <td>9728.79</td>\n",
       "      <td>9728.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3633</td>\n",
       "      <td>11.103223</td>\n",
       "      <td>9.473684e-07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>243712</td>\n",
       "      <td>3</td>\n",
       "      <td>5.58</td>\n",
       "      <td>7.37</td>\n",
       "      <td>1325.91</td>\n",
       "      <td>1348.01</td>\n",
       "      <td>38714.80</td>\n",
       "      <td>38714.80</td>\n",
       "      <td>60724.0</td>\n",
       "      <td>60724.0</td>\n",
       "      <td>12489.64</td>\n",
       "      <td>10773.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4431</td>\n",
       "      <td>9.421400</td>\n",
       "      <td>1.263158e-06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>319488</td>\n",
       "      <td>4</td>\n",
       "      <td>6.45</td>\n",
       "      <td>7.06</td>\n",
       "      <td>1263.73</td>\n",
       "      <td>1291.97</td>\n",
       "      <td>39871.28</td>\n",
       "      <td>39871.28</td>\n",
       "      <td>63664.0</td>\n",
       "      <td>63664.0</td>\n",
       "      <td>11752.63</td>\n",
       "      <td>11071.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2902</td>\n",
       "      <td>9.904912</td>\n",
       "      <td>1.578947e-06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>387072</td>\n",
       "      <td>5</td>\n",
       "      <td>5.71</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1196.52</td>\n",
       "      <td>1230.13</td>\n",
       "      <td>38308.48</td>\n",
       "      <td>39871.28</td>\n",
       "      <td>63664.0</td>\n",
       "      <td>63664.0</td>\n",
       "      <td>11839.95</td>\n",
       "      <td>11234.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2678</td>\n",
       "      <td>7.625069</td>\n",
       "      <td>1.894737e-06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>472064</td>\n",
       "      <td>6</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.21</td>\n",
       "      <td>1275.43</td>\n",
       "      <td>1318.67</td>\n",
       "      <td>39003.01</td>\n",
       "      <td>39871.28</td>\n",
       "      <td>63664.0</td>\n",
       "      <td>63664.0</td>\n",
       "      <td>9297.83</td>\n",
       "      <td>10743.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.0906</td>\n",
       "      <td>2.523496</td>\n",
       "      <td>4.952521e-09</td>\n",
       "      <td>0.98</td>\n",
       "      <td>14706688</td>\n",
       "      <td>180</td>\n",
       "      <td>7.29</td>\n",
       "      <td>7.47</td>\n",
       "      <td>22.41</td>\n",
       "      <td>1367.24</td>\n",
       "      <td>39582.71</td>\n",
       "      <td>44450.96</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>11805.69</td>\n",
       "      <td>10933.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.0803</td>\n",
       "      <td>2.334372</td>\n",
       "      <td>2.201457e-09</td>\n",
       "      <td>0.99</td>\n",
       "      <td>14794752</td>\n",
       "      <td>181</td>\n",
       "      <td>9.11</td>\n",
       "      <td>7.48</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1368.91</td>\n",
       "      <td>38424.56</td>\n",
       "      <td>44450.96</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>9665.04</td>\n",
       "      <td>10924.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.0846</td>\n",
       "      <td>2.439409</td>\n",
       "      <td>5.504147e-10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>14891008</td>\n",
       "      <td>182</td>\n",
       "      <td>9.28</td>\n",
       "      <td>7.49</td>\n",
       "      <td>7.49</td>\n",
       "      <td>1370.73</td>\n",
       "      <td>44450.96</td>\n",
       "      <td>44450.96</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>10369.47</td>\n",
       "      <td>10920.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.0233</td>\n",
       "      <td>2.492430</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14966784</td>\n",
       "      <td>183</td>\n",
       "      <td>6.06</td>\n",
       "      <td>7.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1369.29</td>\n",
       "      <td>38714.80</td>\n",
       "      <td>44450.96</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>12502.43</td>\n",
       "      <td>10927.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14966784</td>\n",
       "      <td>183</td>\n",
       "      <td>6.06</td>\n",
       "      <td>7.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1369.29</td>\n",
       "      <td>38714.80</td>\n",
       "      <td>44450.96</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>76254.0</td>\n",
       "      <td>12502.43</td>\n",
       "      <td>10927.97</td>\n",
       "      <td>1394.6588</td>\n",
       "      <td>33.557</td>\n",
       "      <td>0.131</td>\n",
       "      <td>1.13854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  grad_norm  learning_rate  epoch  num_input_tokens_seen  step  \\\n",
       "0    1.3760   9.614106   6.315789e-07   0.01                 174080     2   \n",
       "1    1.3633  11.103223   9.473684e-07   0.02                 243712     3   \n",
       "2    1.4431   9.421400   1.263158e-06   0.02                 319488     4   \n",
       "3    1.2902   9.904912   1.578947e-06   0.03                 387072     5   \n",
       "4    1.2678   7.625069   1.894737e-06   0.03                 472064     6   \n",
       "..      ...        ...            ...    ...                    ...   ...   \n",
       "178  1.0906   2.523496   4.952521e-09   0.98               14706688   180   \n",
       "179  1.0803   2.334372   2.201457e-09   0.99               14794752   181   \n",
       "180  1.0846   2.439409   5.504147e-10   0.99               14891008   182   \n",
       "181  1.0233   2.492430   0.000000e+00   1.00               14966784   183   \n",
       "182     NaN        NaN            NaN   1.00               14966784   183   \n",
       "\n",
       "     step_time_sec  avg_step_time_sec  time_to_completion_sec  \\\n",
       "0             9.16               9.16                 1657.44   \n",
       "1             5.58               7.37                 1325.91   \n",
       "2             6.45               7.06                 1263.73   \n",
       "3             5.71               6.72                 1196.52   \n",
       "4             9.14               7.21                 1275.43   \n",
       "..             ...                ...                     ...   \n",
       "178           7.29               7.47                   22.41   \n",
       "179           9.11               7.48                   14.96   \n",
       "180           9.28               7.49                    7.49   \n",
       "181           6.06               7.48                    0.00   \n",
       "182           6.06               7.48                    0.00   \n",
       "\n",
       "     estimated_total_time_sec  step_peak_memory_allocated_MB  \\\n",
       "0                     1675.76                       38308.48   \n",
       "1                     1348.01                       38714.80   \n",
       "2                     1291.97                       39871.28   \n",
       "3                     1230.13                       38308.48   \n",
       "4                     1318.67                       39003.01   \n",
       "..                        ...                            ...   \n",
       "178                   1367.24                       39582.71   \n",
       "179                   1368.91                       38424.56   \n",
       "180                   1370.73                       44450.96   \n",
       "181                   1369.29                       38714.80   \n",
       "182                   1369.29                       38714.80   \n",
       "\n",
       "     total_peak_memory_allocated_MB  step_peak_memory_reserved_MB  \\\n",
       "0                          38308.48                       58820.0   \n",
       "1                          38714.80                       60724.0   \n",
       "2                          39871.28                       63664.0   \n",
       "3                          39871.28                       63664.0   \n",
       "4                          39871.28                       63664.0   \n",
       "..                              ...                           ...   \n",
       "178                        44450.96                       76254.0   \n",
       "179                        44450.96                       76254.0   \n",
       "180                        44450.96                       76254.0   \n",
       "181                        44450.96                       76254.0   \n",
       "182                        44450.96                       76254.0   \n",
       "\n",
       "     total_peak_memory_reserved_MB  step_tokens_per_second  \\\n",
       "0                          58820.0                 9728.79   \n",
       "1                          60724.0                12489.64   \n",
       "2                          63664.0                11752.63   \n",
       "3                          63664.0                11839.95   \n",
       "4                          63664.0                 9297.83   \n",
       "..                             ...                     ...   \n",
       "178                        76254.0                11805.69   \n",
       "179                        76254.0                 9665.04   \n",
       "180                        76254.0                10369.47   \n",
       "181                        76254.0                12502.43   \n",
       "182                        76254.0                12502.43   \n",
       "\n",
       "     avg_tokens_per_second  train_runtime  train_samples_per_second  \\\n",
       "0                  9728.79            NaN                       NaN   \n",
       "1                 10773.58            NaN                       NaN   \n",
       "2                 11071.62            NaN                       NaN   \n",
       "3                 11234.73            NaN                       NaN   \n",
       "4                 10743.31            NaN                       NaN   \n",
       "..                     ...            ...                       ...   \n",
       "178               10933.31            NaN                       NaN   \n",
       "179               10924.73            NaN                       NaN   \n",
       "180               10920.93            NaN                       NaN   \n",
       "181               10927.97            NaN                       NaN   \n",
       "182               10927.97      1394.6588                    33.557   \n",
       "\n",
       "     train_steps_per_second  train_loss  \n",
       "0                       NaN         NaN  \n",
       "1                       NaN         NaN  \n",
       "2                       NaN         NaN  \n",
       "3                       NaN         NaN  \n",
       "4                       NaN         NaN  \n",
       "..                      ...         ...  \n",
       "178                     NaN         NaN  \n",
       "179                     NaN         NaN  \n",
       "180                     NaN         NaN  \n",
       "181                     NaN         NaN  \n",
       "182                   0.131     1.13854  \n",
       "\n",
       "[183 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "def extract_dicts_from_log(log_content):\n",
    "    # Regular expression to match dictionary-like strings\n",
    "    dict_pattern = r'\\{[^}]+\\}'\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(dict_pattern, log_content)\n",
    "    \n",
    "    # Convert string representations to actual dictionaries\n",
    "    dicts = []\n",
    "    for match in matches:\n",
    "        try:\n",
    "            d = literal_eval(match)\n",
    "            if isinstance(d, dict):\n",
    "                if \"step\" in d:\n",
    "                    dicts.append(d)\n",
    "        except:\n",
    "            pass  # Ignore any errors in parsing\n",
    "    \n",
    "    return dicts\n",
    "\n",
    "# Assuming the log content is stored in a variable called 'log_content'\n",
    "dicts = extract_dicts_from_log(v011_data)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "v011 = pd.DataFrame(dicts)\n",
    "\n",
    "# Display the DataFrame\n",
    "v011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16cc1ea-74ce-4f6e-a820-86231a8c6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v020_data = \"\"\"\n",
    "W0829 21:24:09.631000 140308402159616 torch/distributed/run.py:779] *****************************************\n",
    "W0829 21:24:09.631000 140308402159616 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
    "W0829 21:24:09.631000 140308402159616 torch/distributed/run.py:779] *****************************************\n",
    "2024-08-29 21:24:12.238257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "2024-08-29 21:24:12.255873: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "2024-08-29 21:24:12.261299: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "2024-08-29 21:24:12.275852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-08-29 21:24:12.343254: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "2024-08-29 21:24:12.360576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "2024-08-29 21:24:12.366124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "2024-08-29 21:24:12.379872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-08-29 21:24:12.402419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "2024-08-29 21:24:12.402419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "2024-08-29 21:24:12.420301: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "2024-08-29 21:24:12.420395: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "2024-08-29 21:24:12.425982: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "2024-08-29 21:24:12.426204: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "2024-08-29 21:24:12.440822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-08-29 21:24:12.440822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-08-29 21:24:13.278759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "2024-08-29 21:24:13.441046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "2024-08-29 21:24:13.553690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "2024-08-29 21:24:13.563188: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50.6k/50.6k [00:00<00:00, 2.42MB/s]\n",
    "tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.09M/9.09M [00:00<00:00, 25.7MB/s]\n",
    "special_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 73.0/73.0 [00:00<00:00, 427kB/s]\n",
    "Downloading readme: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.47k/7.47k [00:00<00:00, 180kB/s]\n",
    "Downloading data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24.2M/24.2M [00:00<00:00, 132MB/s]\n",
    "Generating train split: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 52002/52002 [00:00<00:00, 291672.61 examples/s]\n",
    "config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 654/654 [00:00<00:00, 6.55MB/s]\n",
    "model.safetensors.index.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 23.9k/23.9k [00:00<00:00, 73.3MB/s]\n",
    "model-00001-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4.98G/4.98G [00:19<00:00, 258MB/s]\n",
    "model-00002-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 5.00G/5.00G [00:20<00:00, 247MB/s]\n",
    "model-00003-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4.92G/4.92G [00:19<00:00, 253MB/s]\n",
    "model-00004-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1.17G/1.17G [00:04<00:00, 249MB/s]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:03<00:00, 15.97s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:03<00:00, 15.97s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:03<00:00, 15.97s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:03<00:00, 15.96s/it]\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  5.36it/s]\n",
    "generation_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 177/177 [00:00<00:00, 1.77MB/s]\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.52it/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.74it/s]\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.64it/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 11651.33 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 6550.78 examples/s]\n",
    "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 10193.94 examples/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 9931.86 examples/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 9576.04 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 6148.96 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 6761.19 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 6861.25 examples/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1558: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1558: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1564: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.\n",
    "  warnings.warn(\n",
    "  0%|                                                                                                                                             | 0/183 [00:00<?, ?it/s]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2967, 'grad_norm': 9.784804344177246, 'learning_rate': 3.157894736842105e-07, 'epoch': 0.01, 'num_input_tokens_seen': 75776}\n",
    "{'loss': 1.2993, 'grad_norm': 9.791666984558105, 'learning_rate': 6.31578947368421e-07, 'epoch': 0.01, 'num_input_tokens_seen': 167936, 'step': 2, 'step_time_sec': 10.33, 'avg_step_time_sec': 10.33, 'time_to_completion_sec': 1869.28, 'estimated_total_time_sec': 1889.94, 'step_peak_memory_allocated_MB': 62354.05, 'step_peak_memory_reserved_MB': 79408.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79408.0, 'step_tokens_per_second': 8923.72, 'avg_tokens_per_second': 8923.72}\n",
    "{'loss': 1.4052, 'grad_norm': 9.73194694519043, 'learning_rate': 9.473684210526316e-07, 'epoch': 0.02, 'num_input_tokens_seen': 250880, 'step': 3, 'step_time_sec': 9.15, 'avg_step_time_sec': 9.74, 'time_to_completion_sec': 1752.71, 'estimated_total_time_sec': 1781.92, 'step_peak_memory_allocated_MB': 41948.18, 'step_peak_memory_reserved_MB': 70586.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79408.0, 'step_tokens_per_second': 9067.88, 'avg_tokens_per_second': 8991.43}\n",
    "  2%|██▏                                                                                                                                  | 3/183 [00:29<28:54,  9.64s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.3677, 'grad_norm': 9.1876859664917, 'learning_rate': 1.263157894736842e-06, 'epoch': 0.02, 'num_input_tokens_seen': 329728, 'step': 4, 'step_time_sec': 7.11, 'avg_step_time_sec': 8.86, 'time_to_completion_sec': 1586.12, 'estimated_total_time_sec': 1621.57, 'step_peak_memory_allocated_MB': 55974.59, 'step_peak_memory_reserved_MB': 79410.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11092.03, 'avg_tokens_per_second': 9553.14}\n",
    "{'loss': 1.4013, 'grad_norm': 9.777603149414062, 'learning_rate': 1.5789473684210526e-06, 'epoch': 0.03, 'num_input_tokens_seen': 406528, 'step': 5, 'step_time_sec': 6.52, 'avg_step_time_sec': 8.28, 'time_to_completion_sec': 1473.21, 'estimated_total_time_sec': 1514.59, 'step_peak_memory_allocated_MB': 45772.31, 'step_peak_memory_reserved_MB': 67092.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11774.07, 'avg_tokens_per_second': 9990.73}\n",
    "{'loss': 1.3633, 'grad_norm': 8.155755043029785, 'learning_rate': 1.8947368421052632e-06, 'epoch': 0.03, 'num_input_tokens_seen': 478208, 'step': 6, 'step_time_sec': 6.07, 'avg_step_time_sec': 7.84, 'time_to_completion_sec': 1386.98, 'estimated_total_time_sec': 1434.0, 'step_peak_memory_allocated_MB': 52149.36, 'step_peak_memory_reserved_MB': 77582.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11800.2, 'avg_tokens_per_second': 10271.27}\n",
    "{'loss': 1.3005, 'grad_norm': 7.554805278778076, 'learning_rate': 2.2105263157894738e-06, 'epoch': 0.04, 'num_input_tokens_seen': 565248, 'step': 7, 'step_time_sec': 8.4, 'avg_step_time_sec': 7.93, 'time_to_completion_sec': 1395.68, 'estimated_total_time_sec': 1451.19, 'step_peak_memory_allocated_MB': 57251.16, 'step_peak_memory_reserved_MB': 71738.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 10362.18, 'avg_tokens_per_second': 10287.32}\n",
    "{'loss': 1.3302, 'grad_norm': 7.372071266174316, 'learning_rate': 2.526315789473684e-06, 'epoch': 0.04, 'num_input_tokens_seen': 657408, 'step': 8, 'step_time_sec': 10.07, 'avg_step_time_sec': 8.24, 'time_to_completion_sec': 1441.23, 'estimated_total_time_sec': 1507.11, 'step_peak_memory_allocated_MB': 45772.31, 'step_peak_memory_reserved_MB': 72240.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9152.91, 'avg_tokens_per_second': 10089.18}\n",
    "{'loss': 1.2764, 'grad_norm': 3.7853829860687256, 'learning_rate': 2.8421052631578946e-06, 'epoch': 0.05, 'num_input_tokens_seen': 740352, 'step': 9, 'step_time_sec': 8.49, 'avg_step_time_sec': 8.27, 'time_to_completion_sec': 1438.57, 'estimated_total_time_sec': 1512.98, 'step_peak_memory_allocated_MB': 59802.48, 'step_peak_memory_reserved_MB': 73742.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9766.99, 'avg_tokens_per_second': 10047.81}\n",
    "{'loss': 1.1972, 'grad_norm': 3.170466899871826, 'learning_rate': 3.157894736842105e-06, 'epoch': 0.05, 'num_input_tokens_seen': 830464, 'step': 10, 'step_time_sec': 10.68, 'avg_step_time_sec': 8.54, 'time_to_completion_sec': 1476.75, 'estimated_total_time_sec': 1562.11, 'step_peak_memory_allocated_MB': 44497.3, 'step_peak_memory_reserved_MB': 74244.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 8434.48, 'avg_tokens_per_second': 9823.46}\n",
    "{'loss': 1.2912, 'grad_norm': 3.5955066680908203, 'learning_rate': 3.473684210526316e-06, 'epoch': 0.06, 'num_input_tokens_seen': 894976, 'step': 11, 'step_time_sec': 6.67, 'avg_step_time_sec': 8.35, 'time_to_completion_sec': 1436.17, 'estimated_total_time_sec': 1528.02, 'step_peak_memory_allocated_MB': 40672.67, 'step_peak_memory_reserved_MB': 74244.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9667.09, 'avg_tokens_per_second': 9810.96}\n",
    "{'loss': 1.2455, 'grad_norm': 4.807107448577881, 'learning_rate': 3.7894736842105264e-06, 'epoch': 0.07, 'num_input_tokens_seen': 974848, 'step': 12, 'step_time_sec': 6.72, 'avg_step_time_sec': 8.2, 'time_to_completion_sec': 1402.44, 'estimated_total_time_sec': 1500.86, 'step_peak_memory_allocated_MB': 54699.08, 'step_peak_memory_reserved_MB': 74244.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11890.82, 'avg_tokens_per_second': 9965.82}\n",
    "{'loss': 1.2009, 'grad_norm': 4.261688232421875, 'learning_rate': 4.105263157894737e-06, 'epoch': 0.07, 'num_input_tokens_seen': 1056768, 'step': 13, 'step_time_sec': 8.75, 'avg_step_time_sec': 8.25, 'time_to_completion_sec': 1401.97, 'estimated_total_time_sec': 1509.18, 'step_peak_memory_allocated_MB': 53424.51, 'step_peak_memory_reserved_MB': 74244.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9365.45, 'avg_tokens_per_second': 9912.75}\n",
    "{'loss': 1.1938, 'grad_norm': 3.9962756633758545, 'learning_rate': 4.4210526315789476e-06, 'epoch': 0.08, 'num_input_tokens_seen': 1153024, 'step': 14, 'step_time_sec': 9.47, 'avg_step_time_sec': 8.34, 'time_to_completion_sec': 1409.62, 'estimated_total_time_sec': 1526.39, 'step_peak_memory_allocated_MB': 54699.08, 'step_peak_memory_reserved_MB': 74244.0, 'total_peak_memory_allocated_MB': 62354.05, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 10165.02, 'avg_tokens_per_second': 9934.78}\n",
    "{'loss': 1.1849, 'grad_norm': 3.5185294151306152, 'learning_rate': 4.736842105263158e-06, 'epoch': 0.08, 'num_input_tokens_seen': 1258496, 'step': 15, 'step_time_sec': 10.87, 'avg_step_time_sec': 8.52, 'time_to_completion_sec': 1431.61, 'estimated_total_time_sec': 1559.43, 'step_peak_memory_allocated_MB': 63628.93, 'step_peak_memory_reserved_MB': 79308.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9704.37, 'avg_tokens_per_second': 9913.79}\n",
    "{'loss': 1.2264, 'grad_norm': 3.1267378330230713, 'learning_rate': 5.052631578947368e-06, 'epoch': 0.09, 'num_input_tokens_seen': 1346560, 'step': 16, 'step_time_sec': 8.43, 'avg_step_time_sec': 8.52, 'time_to_completion_sec': 1422.06, 'estimated_total_time_sec': 1558.3, 'step_peak_memory_allocated_MB': 44498.3, 'step_peak_memory_reserved_MB': 75610.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 10447.21, 'avg_tokens_per_second': 9948.99}\n",
    "{'loss': 1.2555, 'grad_norm': 2.899998426437378, 'learning_rate': 5.368421052631579e-06, 'epoch': 0.09, 'num_input_tokens_seen': 1434624, 'step': 17, 'step_time_sec': 7.8, 'avg_step_time_sec': 8.47, 'time_to_completion_sec': 1406.09, 'estimated_total_time_sec': 1550.08, 'step_peak_memory_allocated_MB': 52149.36, 'step_peak_memory_reserved_MB': 79316.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11295.12, 'avg_tokens_per_second': 10026.43}\n",
    "{'loss': 1.2189, 'grad_norm': 3.608665943145752, 'learning_rate': 5.684210526315789e-06, 'epoch': 0.1, 'num_input_tokens_seen': 1518592, 'step': 18, 'step_time_sec': 7.4, 'avg_step_time_sec': 8.41, 'time_to_completion_sec': 1387.23, 'estimated_total_time_sec': 1538.56, 'step_peak_memory_allocated_MB': 54700.08, 'step_peak_memory_reserved_MB': 77580.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11346.65, 'avg_tokens_per_second': 10094.79}\n",
    "{'loss': 1.2315, 'grad_norm': 3.074618339538574, 'learning_rate': 6e-06, 'epoch': 0.1, 'num_input_tokens_seen': 1591296, 'step': 19, 'step_time_sec': 5.49, 'avg_step_time_sec': 8.25, 'time_to_completion_sec': 1352.27, 'estimated_total_time_sec': 1508.94, 'step_peak_memory_allocated_MB': 52148.36, 'step_peak_memory_reserved_MB': 77718.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 13234.42, 'avg_tokens_per_second': 10211.0}\n",
    "{'loss': 1.2461, 'grad_norm': 3.1047000885009766, 'learning_rate': 5.9994495852953836e-06, 'epoch': 0.11, 'num_input_tokens_seen': 1654784, 'step': 20, 'step_time_sec': 5.2, 'avg_step_time_sec': 8.09, 'time_to_completion_sec': 1317.91, 'estimated_total_time_sec': 1479.61, 'step_peak_memory_allocated_MB': 47048.31, 'step_peak_memory_reserved_MB': 77718.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 12207.85, 'avg_tokens_per_second': 10278.6}\n",
    "{'loss': 1.19, 'grad_norm': 2.8782384395599365, 'learning_rate': 5.997798543152429e-06, 'epoch': 0.11, 'num_input_tokens_seen': 1731584, 'step': 21, 'step_time_sec': 6.83, 'avg_step_time_sec': 8.02, 'time_to_completion_sec': 1299.63, 'estimated_total_time_sec': 1468.09, 'step_peak_memory_allocated_MB': 47048.31, 'step_peak_memory_reserved_MB': 77718.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11250.1, 'avg_tokens_per_second': 10319.93}\n",
    "{'loss': 1.2061, 'grad_norm': 2.380156993865967, 'learning_rate': 5.9950474794097236e-06, 'epoch': 0.12, 'num_input_tokens_seen': 1815552, 'step': 22, 'step_time_sec': 8.44, 'avg_step_time_sec': 8.04, 'time_to_completion_sec': 1294.83, 'estimated_total_time_sec': 1471.77, 'step_peak_memory_allocated_MB': 58525.78, 'step_peak_memory_reserved_MB': 79218.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9944.17, 'avg_tokens_per_second': 10301.15}\n",
    "{'loss': 1.1583, 'grad_norm': 2.7259037494659424, 'learning_rate': 5.9911974035512214e-06, 'epoch': 0.13, 'num_input_tokens_seen': 1898496, 'step': 23, 'step_time_sec': 8.88, 'avg_step_time_sec': 8.08, 'time_to_completion_sec': 1292.92, 'estimated_total_time_sec': 1478.77, 'step_peak_memory_allocated_MB': 63628.93, 'step_peak_memory_reserved_MB': 79102.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9335.98, 'avg_tokens_per_second': 10252.91}\n",
    "{'loss': 1.2232, 'grad_norm': 2.965057373046875, 'learning_rate': 5.9862497283358345e-06, 'epoch': 0.13, 'num_input_tokens_seen': 1982464, 'step': 24, 'step_time_sec': 7.12, 'avg_step_time_sec': 8.04, 'time_to_completion_sec': 1278.2, 'estimated_total_time_sec': 1471.13, 'step_peak_memory_allocated_MB': 48322.5, 'step_peak_memory_reserved_MB': 79300.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11792.66, 'avg_tokens_per_second': 10312.21}\n",
    "{'loss': 1.2454, 'grad_norm': 3.0411436557769775, 'learning_rate': 5.980206269279025e-06, 'epoch': 0.14, 'num_input_tokens_seen': 2046976, 'step': 25, 'step_time_sec': 5.24, 'avg_step_time_sec': 7.92, 'time_to_completion_sec': 1251.71, 'estimated_total_time_sec': 1449.77, 'step_peak_memory_allocated_MB': 40672.67, 'step_peak_memory_reserved_MB': 79300.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 12317.43, 'avg_tokens_per_second': 10367.44}\n",
    "{'loss': 1.2446, 'grad_norm': 2.780355930328369, 'learning_rate': 5.973069243986614e-06, 'epoch': 0.14, 'num_input_tokens_seen': 2113536, 'step': 26, 'step_time_sec': 5.91, 'avg_step_time_sec': 7.84, 'time_to_completion_sec': 1231.14, 'estimated_total_time_sec': 1435.02, 'step_peak_memory_allocated_MB': 47048.31, 'step_peak_memory_reserved_MB': 79300.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 11266.5, 'avg_tokens_per_second': 10394.54}\n",
    "{'loss': 1.2374, 'grad_norm': 2.7066614627838135, 'learning_rate': 5.964841271341046e-06, 'epoch': 0.15, 'num_input_tokens_seen': 2199552, 'step': 27, 'step_time_sec': 9.5, 'avg_step_time_sec': 7.91, 'time_to_completion_sec': 1233.24, 'estimated_total_time_sec': 1446.69, 'step_peak_memory_allocated_MB': 44497.3, 'step_peak_memory_reserved_MB': 79300.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9055.53, 'avg_tokens_per_second': 10332.66}\n",
    "{'loss': 1.1912, 'grad_norm': 2.8191580772399902, 'learning_rate': 5.95552537054041e-06, 'epoch': 0.15, 'num_input_tokens_seen': 2296832, 'step': 28, 'step_time_sec': 10.4, 'avg_step_time_sec': 8.0, 'time_to_completion_sec': 1239.68, 'estimated_total_time_sec': 1463.63, 'step_peak_memory_allocated_MB': 45772.31, 'step_peak_memory_reserved_MB': 79300.0, 'total_peak_memory_allocated_MB': 63628.93, 'total_peak_memory_reserved_MB': 79410.0, 'step_tokens_per_second': 9349.46, 'avg_tokens_per_second': 10285.28}\n",
    "{'loss': 1.1317, 'grad_norm': 2.5820600986480713, 'learning_rate': 5.945124959990565e-06, 'epoch': 0.16, 'num_input_tokens_seen': 2394112, 'step': 29, 'step_time_sec': 10.03, 'avg_step_time_sec': 8.07, 'time_to_completion_sec': 1242.85, 'estimated_total_time_sec': 1476.9, 'step_peak_memory_allocated_MB': 66180.87, 'step_peak_memory_reserved_MB': 79470.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79470.0, 'step_tokens_per_second': 9700.56, 'avg_tokens_per_second': 10259.34}\n",
    "{'loss': 1.1578, 'grad_norm': 2.661432981491089, 'learning_rate': 5.933643856050778e-06, 'epoch': 0.16, 'num_input_tokens_seen': 2491392, 'step': 30, 'step_time_sec': 9.63, 'avg_step_time_sec': 8.12, 'time_to_completion_sec': 1243.01, 'estimated_total_time_sec': 1486.73, 'step_peak_memory_allocated_MB': 47049.31, 'step_peak_memory_reserved_MB': 76986.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79470.0, 'step_tokens_per_second': 10102.75, 'avg_tokens_per_second': 10252.94}\n",
    "{'loss': 1.2359, 'grad_norm': 2.7071778774261475, 'learning_rate': 5.921086271633337e-06, 'epoch': 0.17, 'num_input_tokens_seen': 2565120, 'step': 31, 'step_time_sec': 5.97, 'avg_step_time_sec': 8.05, 'time_to_completion_sec': 1223.98, 'estimated_total_time_sec': 1473.61, 'step_peak_memory_allocated_MB': 48322.5, 'step_peak_memory_reserved_MB': 77968.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79470.0, 'step_tokens_per_second': 12344.42, 'avg_tokens_per_second': 10304.64}\n",
    "{'loss': 1.2672, 'grad_norm': 3.4068548679351807, 'learning_rate': 5.907456814657656e-06, 'epoch': 0.17, 'num_input_tokens_seen': 2660352, 'step': 32, 'step_time_sec': 10.22, 'avg_step_time_sec': 8.12, 'time_to_completion_sec': 1226.47, 'estimated_total_time_sec': 1486.39, 'step_peak_memory_allocated_MB': 52149.36, 'step_peak_memory_reserved_MB': 79072.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79470.0, 'step_tokens_per_second': 9320.56, 'avg_tokens_per_second': 10264.71}\n",
    "{'loss': 1.2436, 'grad_norm': 2.6726064682006836, 'learning_rate': 5.892760486359423e-06, 'epoch': 0.18, 'num_input_tokens_seen': 2754560, 'step': 33, 'step_time_sec': 7.94, 'avg_step_time_sec': 8.12, 'time_to_completion_sec': 1217.52, 'estimated_total_time_sec': 1485.37, 'step_peak_memory_allocated_MB': 59802.48, 'step_peak_memory_reserved_MB': 79274.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79470.0, 'step_tokens_per_second': 11858.13, 'avg_tokens_per_second': 10313.45}\n",
    "{'loss': 1.1975, 'grad_norm': 2.6058826446533203, 'learning_rate': 5.877002679455439e-06, 'epoch': 0.19, 'num_input_tokens_seen': 2832384, 'step': 34, 'step_time_sec': 6.15, 'avg_step_time_sec': 8.06, 'time_to_completion_sec': 1200.54, 'estimated_total_time_sec': 1474.49, 'step_peak_memory_allocated_MB': 49599.38, 'step_peak_memory_reserved_MB': 74326.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79470.0, 'step_tokens_per_second': 12646.18, 'avg_tokens_per_second': 10367.44}\n",
    "{'loss': 1.173, 'grad_norm': 2.5237417221069336, 'learning_rate': 5.860189176164791e-06, 'epoch': 0.19, 'num_input_tokens_seen': 2914304, 'step': 35, 'step_time_sec': 10.04, 'avg_step_time_sec': 8.12, 'time_to_completion_sec': 1201.11, 'estimated_total_time_sec': 1485.15, 'step_peak_memory_allocated_MB': 44497.3, 'step_peak_memory_reserved_MB': 74462.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79470.0, 'step_tokens_per_second': 8159.84, 'avg_tokens_per_second': 10287.12}\n",
    "{'loss': 1.2357, 'grad_norm': 2.678485870361328, 'learning_rate': 5.842326146087113e-06, 'epoch': 0.2, 'num_input_tokens_seen': 2999296, 'step': 36, 'step_time_sec': 8.27, 'avg_step_time_sec': 8.12, 'time_to_completion_sec': 1193.62, 'estimated_total_time_sec': 1485.94, 'step_peak_memory_allocated_MB': 58525.78, 'step_peak_memory_reserved_MB': 79498.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10283.24, 'avg_tokens_per_second': 10287.01}\n",
    "{'loss': 1.2296, 'grad_norm': 2.5203726291656494, 'learning_rate': 5.823420143938684e-06, 'epoch': 0.2, 'num_input_tokens_seen': 3066880, 'step': 37, 'step_time_sec': 5.04, 'avg_step_time_sec': 8.03, 'time_to_completion_sec': 1173.02, 'estimated_total_time_sec': 1470.29, 'step_peak_memory_allocated_MB': 48322.5, 'step_peak_memory_reserved_MB': 70804.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13404.47, 'avg_tokens_per_second': 10341.35}\n",
    "{'loss': 1.1506, 'grad_norm': 2.419691324234009, 'learning_rate': 5.803478107147233e-06, 'epoch': 0.21, 'num_input_tokens_seen': 3156992, 'step': 38, 'step_time_sec': 10.05, 'avg_step_time_sec': 8.09, 'time_to_completion_sec': 1172.9, 'estimated_total_time_sec': 1480.28, 'step_peak_memory_allocated_MB': 49599.38, 'step_peak_memory_reserved_MB': 77522.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8962.74, 'avg_tokens_per_second': 10295.04}\n",
    "{'loss': 1.2229, 'grad_norm': 2.599046230316162, 'learning_rate': 5.7825073533062846e-06, 'epoch': 0.21, 'num_input_tokens_seen': 3248128, 'step': 39, 'step_time_sec': 9.5, 'avg_step_time_sec': 8.13, 'time_to_completion_sec': 1170.15, 'estimated_total_time_sec': 1487.06, 'step_peak_memory_allocated_MB': 44497.3, 'step_peak_memory_reserved_MB': 59876.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9595.74, 'avg_tokens_per_second': 10273.53}\n",
    "{'loss': 1.1495, 'grad_norm': 2.617234706878662, 'learning_rate': 5.760515577490025e-06, 'epoch': 0.22, 'num_input_tokens_seen': 3313664, 'step': 40, 'step_time_sec': 5.28, 'avg_step_time_sec': 8.05, 'time_to_completion_sec': 1151.6, 'estimated_total_time_sec': 1473.73, 'step_peak_memory_allocated_MB': 48322.5, 'step_peak_memory_reserved_MB': 77882.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 12402.83, 'avg_tokens_per_second': 10309.35}\n",
    "{'loss': 1.1389, 'grad_norm': 2.589113473892212, 'learning_rate': 5.737510849429649e-06, 'epoch': 0.22, 'num_input_tokens_seen': 3402752, 'step': 41, 'step_time_sec': 9.49, 'avg_step_time_sec': 8.09, 'time_to_completion_sec': 1148.65, 'estimated_total_time_sec': 1480.31, 'step_peak_memory_allocated_MB': 45772.31, 'step_peak_memory_reserved_MB': 76998.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9386.32, 'avg_tokens_per_second': 10282.28}\n",
    "{'loss': 1.2082, 'grad_norm': 2.8709161281585693, 'learning_rate': 5.713501610552225e-06, 'epoch': 0.23, 'num_input_tokens_seen': 3487744, 'step': 42, 'step_time_sec': 10.41, 'avg_step_time_sec': 8.15, 'time_to_completion_sec': 1148.54, 'estimated_total_time_sec': 1490.66, 'step_peak_memory_allocated_MB': 49599.38, 'step_peak_memory_reserved_MB': 79382.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8165.33, 'avg_tokens_per_second': 10216.3}\n",
    "{'loss': 1.1449, 'grad_norm': 2.547075033187866, 'learning_rate': 5.688496670883167e-06, 'epoch': 0.23, 'num_input_tokens_seen': 3573760, 'step': 43, 'step_time_sec': 7.86, 'avg_step_time_sec': 8.14, 'time_to_completion_sec': 1139.44, 'estimated_total_time_sec': 1489.41, 'step_peak_memory_allocated_MB': 49599.38, 'step_peak_memory_reserved_MB': 77864.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10943.91, 'avg_tokens_per_second': 10233.03}\n",
    "{'loss': 1.1928, 'grad_norm': 2.746863842010498, 'learning_rate': 5.662505205813464e-06, 'epoch': 0.24, 'num_input_tokens_seen': 3642368, 'step': 44, 'step_time_sec': 6.96, 'avg_step_time_sec': 8.11, 'time_to_completion_sec': 1127.48, 'estimated_total_time_sec': 1484.38, 'step_peak_memory_allocated_MB': 52149.36, 'step_peak_memory_reserved_MB': 79448.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9862.27, 'avg_tokens_per_second': 10225.63}\n",
    "{'loss': 1.1502, 'grad_norm': 2.6729724407196045, 'learning_rate': 5.6355367527328275e-06, 'epoch': 0.25, 'num_input_tokens_seen': 3710976, 'step': 45, 'step_time_sec': 5.01, 'avg_step_time_sec': 8.04, 'time_to_completion_sec': 1109.66, 'estimated_total_time_sec': 1471.5, 'step_peak_memory_allocated_MB': 41948.18, 'step_peak_memory_reserved_MB': 58856.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13682.18, 'avg_tokens_per_second': 10274.62}\n",
    "{'loss': 1.2168, 'grad_norm': 2.54723858833313, 'learning_rate': 5.607601207530016e-06, 'epoch': 0.25, 'num_input_tokens_seen': 3786752, 'step': 46, 'step_time_sec': 7.02, 'avg_step_time_sec': 8.02, 'time_to_completion_sec': 1098.52, 'estimated_total_time_sec': 1467.36, 'step_peak_memory_allocated_MB': 48322.5, 'step_peak_memory_reserved_MB': 76862.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10789.01, 'avg_tokens_per_second': 10284.63}\n",
    "{'loss': 1.1421, 'grad_norm': 2.8255085945129395, 'learning_rate': 5.578708820961603e-06, 'epoch': 0.26, 'num_input_tokens_seen': 3855360, 'step': 47, 'step_time_sec': 5.17, 'avg_step_time_sec': 7.96, 'time_to_completion_sec': 1082.06, 'estimated_total_time_sec': 1456.01, 'step_peak_memory_allocated_MB': 44498.3, 'step_peak_memory_reserved_MB': 76998.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13282.58, 'avg_tokens_per_second': 10326.94}\n",
    "{'loss': 1.1447, 'grad_norm': 2.513897180557251, 'learning_rate': 5.548870194890537e-06, 'epoch': 0.26, 'num_input_tokens_seen': 3966976, 'step': 48, 'step_time_sec': 10.47, 'avg_step_time_sec': 8.01, 'time_to_completion_sec': 1081.33, 'estimated_total_time_sec': 1465.8, 'step_peak_memory_allocated_MB': 63628.93, 'step_peak_memory_reserved_MB': 79338.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10660.15, 'avg_tokens_per_second': 10336.21}\n",
    "{'loss': 1.1234, 'grad_norm': 2.580101728439331, 'learning_rate': 5.518096278395851e-06, 'epoch': 0.27, 'num_input_tokens_seen': 4057088, 'step': 49, 'step_time_sec': 9.87, 'avg_step_time_sec': 8.05, 'time_to_completion_sec': 1078.52, 'estimated_total_time_sec': 1472.9, 'step_peak_memory_allocated_MB': 54700.08, 'step_peak_memory_reserved_MB': 77998.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9128.69, 'avg_tokens_per_second': 10305.36}\n",
    "{'loss': 1.1878, 'grad_norm': 2.5282530784606934, 'learning_rate': 5.486398363754984e-06, 'epoch': 0.27, 'num_input_tokens_seen': 4169728, 'step': 50, 'step_time_sec': 10.5, 'avg_step_time_sec': 8.1, 'time_to_completion_sec': 1077.11, 'estimated_total_time_sec': 1482.04, 'step_peak_memory_allocated_MB': 54700.08, 'step_peak_memory_reserved_MB': 77292.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10732.48, 'avg_tokens_per_second': 10316.65}\n",
    "{'loss': 1.1883, 'grad_norm': 2.476102113723755, 'learning_rate': 5.453788082300154e-06, 'epoch': 0.28, 'num_input_tokens_seen': 4243456, 'step': 51, 'step_time_sec': 6.13, 'avg_step_time_sec': 8.06, 'time_to_completion_sec': 1063.8, 'estimated_total_time_sec': 1474.82, 'step_peak_memory_allocated_MB': 49598.38, 'step_peak_memory_reserved_MB': 74828.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 12034.14, 'avg_tokens_per_second': 10342.77}\n",
    "{'loss': 1.1782, 'grad_norm': 2.736722469329834, 'learning_rate': 5.420277400150314e-06, 'epoch': 0.28, 'num_input_tokens_seen': 4334592, 'step': 52, 'step_time_sec': 8.7, 'avg_step_time_sec': 8.07, 'time_to_completion_sec': 1057.39, 'estimated_total_time_sec': 1477.11, 'step_peak_memory_allocated_MB': 50872.95, 'step_peak_memory_reserved_MB': 74828.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10477.81, 'avg_tokens_per_second': 10345.62}\n",
    "{'loss': 1.1755, 'grad_norm': 2.5431602001190186, 'learning_rate': 5.38587861382028e-06, 'epoch': 0.29, 'num_input_tokens_seen': 4411392, 'step': 53, 'step_time_sec': 9.17, 'avg_step_time_sec': 8.09, 'time_to_completion_sec': 1052.07, 'estimated_total_time_sec': 1480.99, 'step_peak_memory_allocated_MB': 43222.36, 'step_peak_memory_reserved_MB': 74828.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8371.09, 'avg_tokens_per_second': 10302.57}\n",
    "{'loss': 1.1362, 'grad_norm': 2.5131020545959473, 'learning_rate': 5.350604345708593e-06, 'epoch': 0.3, 'num_input_tokens_seen': 4490240, 'step': 54, 'step_time_sec': 6.24, 'avg_step_time_sec': 8.06, 'time_to_completion_sec': 1039.46, 'estimated_total_time_sec': 1474.59, 'step_peak_memory_allocated_MB': 53424.51, 'step_peak_memory_reserved_MB': 74828.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 12640.01, 'avg_tokens_per_second': 10336.72}\n",
    "{'loss': 1.1587, 'grad_norm': 2.383772850036621, 'learning_rate': 5.314467539465829e-06, 'epoch': 0.3, 'num_input_tokens_seen': 4579328, 'step': 55, 'step_time_sec': 9.97, 'avg_step_time_sec': 8.09, 'time_to_completion_sec': 1035.95, 'estimated_total_time_sec': 1481.08, 'step_peak_memory_allocated_MB': 57251.16, 'step_peak_memory_reserved_MB': 75998.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8932.04, 'avg_tokens_per_second': 10304.66}\n",
    "{'loss': 1.1549, 'grad_norm': 2.673962116241455, 'learning_rate': 5.277481455245011e-06, 'epoch': 0.31, 'num_input_tokens_seen': 4635648, 'step': 56, 'step_time_sec': 3.93, 'avg_step_time_sec': 8.02, 'time_to_completion_sec': 1018.23, 'estimated_total_time_sec': 1467.22, 'step_peak_memory_allocated_MB': 43222.36, 'step_peak_memory_reserved_MB': 76500.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 14343.1, 'avg_tokens_per_second': 10340.62}\n",
    "{'loss': 1.1401, 'grad_norm': 2.4842827320098877, 'learning_rate': 5.239659664835888e-06, 'epoch': 0.31, 'num_input_tokens_seen': 4703232, 'step': 57, 'step_time_sec': 5.01, 'avg_step_time_sec': 7.96, 'time_to_completion_sec': 1003.45, 'estimated_total_time_sec': 1457.39, 'step_peak_memory_allocated_MB': 49598.38, 'step_peak_memory_reserved_MB': 76500.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13492.81, 'avg_tokens_per_second': 10376.02}\n",
    "{'loss': 1.1247, 'grad_norm': 2.4941444396972656, 'learning_rate': 5.201016046684856e-06, 'epoch': 0.32, 'num_input_tokens_seen': 4804608, 'step': 58, 'step_time_sec': 11.67, 'avg_step_time_sec': 8.03, 'time_to_completion_sec': 1003.61, 'estimated_total_time_sec': 1469.29, 'step_peak_memory_allocated_MB': 55974.59, 'step_peak_memory_reserved_MB': 76500.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8686.32, 'avg_tokens_per_second': 10332.93}\n",
    "{'loss': 1.1192, 'grad_norm': 2.590303897857666, 'learning_rate': 5.161564780802361e-06, 'epoch': 0.32, 'num_input_tokens_seen': 4872192, 'step': 59, 'step_time_sec': 4.75, 'avg_step_time_sec': 7.97, 'time_to_completion_sec': 988.58, 'estimated_total_time_sec': 1458.95, 'step_peak_memory_allocated_MB': 44497.3, 'step_peak_memory_reserved_MB': 76500.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 14220.46, 'avg_tokens_per_second': 10372.89}\n",
    "{'loss': 1.1448, 'grad_norm': 2.869765520095825, 'learning_rate': 5.1213203435596425e-06, 'epoch': 0.33, 'num_input_tokens_seen': 4943872, 'step': 60, 'step_time_sec': 5.23, 'avg_step_time_sec': 7.93, 'time_to_completion_sec': 974.88, 'estimated_total_time_sec': 1450.44, 'step_peak_memory_allocated_MB': 50872.95, 'step_peak_memory_reserved_MB': 76500.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13711.65, 'avg_tokens_per_second': 10410.21}\n",
    "{'loss': 1.1804, 'grad_norm': 2.620133399963379, 'learning_rate': 5.0802975023767254e-06, 'epoch': 0.33, 'num_input_tokens_seen': 5036032, 'step': 61, 'step_time_sec': 9.56, 'avg_step_time_sec': 7.95, 'time_to_completion_sec': 970.28, 'estimated_total_time_sec': 1455.41, 'step_peak_memory_allocated_MB': 41948.18, 'step_peak_memory_reserved_MB': 76500.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9642.47, 'avg_tokens_per_second': 10394.84}\n",
    "{'loss': 1.1911, 'grad_norm': 2.489651918411255, 'learning_rate': 5.038511310303617e-06, 'epoch': 0.34, 'num_input_tokens_seen': 5109760, 'step': 62, 'step_time_sec': 6.36, 'avg_step_time_sec': 7.93, 'time_to_completion_sec': 959.17, 'estimated_total_time_sec': 1450.64, 'step_peak_memory_allocated_MB': 53424.51, 'step_peak_memory_reserved_MB': 76500.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11588.04, 'avg_tokens_per_second': 10410.54}\n",
    "{'loss': 1.2552, 'grad_norm': 2.477651834487915, 'learning_rate': 4.9959771004966955e-06, 'epoch': 0.34, 'num_input_tokens_seen': 5180416, 'step': 63, 'step_time_sec': 7.49, 'avg_step_time_sec': 7.92, 'time_to_completion_sec': 950.4, 'estimated_total_time_sec': 1449.36, 'step_peak_memory_allocated_MB': 44497.3, 'step_peak_memory_reserved_MB': 76500.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9430.78, 'avg_tokens_per_second': 10395.59}\n",
    "{'loss': 1.1734, 'grad_norm': 2.509531259536743, 'learning_rate': 4.952710480592314e-06, 'epoch': 0.35, 'num_input_tokens_seen': 5273600, 'step': 64, 'step_time_sec': 9.99, 'avg_step_time_sec': 7.95, 'time_to_completion_sec': 946.38, 'estimated_total_time_sec': 1455.36, 'step_peak_memory_allocated_MB': 66180.87, 'step_peak_memory_reserved_MB': 79498.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9329.98, 'avg_tokens_per_second': 10374.35}\n",
    "{'loss': 1.1456, 'grad_norm': 2.4363083839416504, 'learning_rate': 4.9087273269796795e-06, 'epoch': 0.36, 'num_input_tokens_seen': 5355520, 'step': 65, 'step_time_sec': 6.87, 'avg_step_time_sec': 7.94, 'time_to_completion_sec': 936.43, 'estimated_total_time_sec': 1452.26, 'step_peak_memory_allocated_MB': 49599.38, 'step_peak_memory_reserved_MB': 78378.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11931.09, 'avg_tokens_per_second': 10395.39}\n",
    "{'loss': 1.2333, 'grad_norm': 2.627732276916504, 'learning_rate': 4.8640437789751294e-06, 'epoch': 0.36, 'num_input_tokens_seen': 5456896, 'step': 66, 'step_time_sec': 11.13, 'avg_step_time_sec': 7.98, 'time_to_completion_sec': 934.24, 'estimated_total_time_sec': 1461.25, 'step_peak_memory_allocated_MB': 53424.51, 'step_peak_memory_reserved_MB': 72072.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9107.54, 'avg_tokens_per_second': 10367.77}\n",
    "{'loss': 1.1398, 'grad_norm': 2.2554678916931152, 'learning_rate': 4.818676232899914e-06, 'epoch': 0.37, 'num_input_tokens_seen': 5550080, 'step': 67, 'step_time_sec': 9.8, 'avg_step_time_sec': 8.01, 'time_to_completion_sec': 929.45, 'estimated_total_time_sec': 1466.28, 'step_peak_memory_allocated_MB': 66180.87, 'step_peak_memory_reserved_MB': 79434.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9509.18, 'avg_tokens_per_second': 10351.86}\n",
    "{'loss': 1.1205, 'grad_norm': 2.3539042472839355, 'learning_rate': 4.772641336063682e-06, 'epoch': 0.37, 'num_input_tokens_seen': 5638144, 'step': 68, 'step_time_sec': 8.31, 'avg_step_time_sec': 8.02, 'time_to_completion_sec': 921.94, 'estimated_total_time_sec': 1467.08, 'step_peak_memory_allocated_MB': 45772.31, 'step_peak_memory_reserved_MB': 66120.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10603.38, 'avg_tokens_per_second': 10355.75}\n",
    "{'loss': 1.1555, 'grad_norm': 2.493100881576538, 'learning_rate': 4.725955980655862e-06, 'epoch': 0.38, 'num_input_tokens_seen': 5725184, 'step': 69, 'step_time_sec': 9.57, 'avg_step_time_sec': 8.04, 'time_to_completion_sec': 916.53, 'estimated_total_time_sec': 1471.27, 'step_peak_memory_allocated_MB': 47049.31, 'step_peak_memory_reserved_MB': 74606.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9091.47, 'avg_tokens_per_second': 10333.61}\n",
    "{'loss': 1.2307, 'grad_norm': 2.699173927307129, 'learning_rate': 4.678637297547192e-06, 'epoch': 0.38, 'num_input_tokens_seen': 5797888, 'step': 70, 'step_time_sec': 6.45, 'avg_step_time_sec': 8.02, 'time_to_completion_sec': 905.89, 'estimated_total_time_sec': 1467.05, 'step_peak_memory_allocated_MB': 49599.38, 'step_peak_memory_reserved_MB': 76214.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11272.74, 'avg_tokens_per_second': 10344.56}\n",
    "{'loss': 1.1837, 'grad_norm': 2.528790235519409, 'learning_rate': 4.630702650003664e-06, 'epoch': 0.39, 'num_input_tokens_seen': 5888000, 'step': 71, 'step_time_sec': 7.13, 'avg_step_time_sec': 8.0, 'time_to_completion_sec': 896.46, 'estimated_total_time_sec': 1464.75, 'step_peak_memory_allocated_MB': 50872.95, 'step_peak_memory_reserved_MB': 77718.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 12632.43, 'avg_tokens_per_second': 10373.69}\n",
    "{'loss': 1.1065, 'grad_norm': 2.5090878009796143, 'learning_rate': 4.582169627315188e-06, 'epoch': 0.39, 'num_input_tokens_seen': 5962752, 'step': 72, 'step_time_sec': 5.75, 'avg_step_time_sec': 7.97, 'time_to_completion_sec': 884.93, 'estimated_total_time_sec': 1458.94, 'step_peak_memory_allocated_MB': 49598.38, 'step_peak_memory_reserved_MB': 68228.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13000.61, 'avg_tokens_per_second': 10400.37}\n",
    "{'loss': 1.1381, 'grad_norm': 2.433800458908081, 'learning_rate': 4.533056038341331e-06, 'epoch': 0.4, 'num_input_tokens_seen': 6044672, 'step': 73, 'step_time_sec': 7.18, 'avg_step_time_sec': 7.96, 'time_to_completion_sec': 875.75, 'estimated_total_time_sec': 1456.92, 'step_peak_memory_allocated_MB': 44497.3, 'step_peak_memory_reserved_MB': 68228.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11407.94, 'avg_tokens_per_second': 10413.0}\n",
    "{'loss': 1.1586, 'grad_norm': 2.5714025497436523, 'learning_rate': 4.483379904976471e-06, 'epoch': 0.4, 'num_input_tokens_seen': 6149120, 'step': 74, 'step_time_sec': 10.15, 'avg_step_time_sec': 7.99, 'time_to_completion_sec': 871.05, 'estimated_total_time_sec': 1462.4, 'step_peak_memory_allocated_MB': 53424.51, 'step_peak_memory_reserved_MB': 79220.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10293.72, 'avg_tokens_per_second': 10410.92}\n",
    "{'loss': 1.178, 'grad_norm': 2.6912381649017334, 'learning_rate': 4.433159455536789e-06, 'epoch': 0.41, 'num_input_tokens_seen': 6235136, 'step': 75, 'step_time_sec': 9.43, 'avg_step_time_sec': 8.01, 'time_to_completion_sec': 865.16, 'estimated_total_time_sec': 1465.96, 'step_peak_memory_allocated_MB': 52148.36, 'step_peak_memory_reserved_MB': 69230.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9122.34, 'avg_tokens_per_second': 10390.42}\n",
    " 41%|██████████████████████████████████████████████████████                                                                              | 75/183 [10:13<15:37,  8.68s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/utils.py:155: UserWarning: Could not find response key `[14711, 6075, 512]` in the following instance: <|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Come up with an appropriate title for the following document.\n",
    "\n",
    "### Input:\n",
    "WASHINGTON (CNN) -- A wide-open presidential race and a willingness by candidates, interest groups, unions and corporations to buy TV time will lead to historic spending for political and issue-advocacy advertising in the 2008 election cycle, an analysis shows. Former Massachusetts Gov. Mitt Romney has spent the most on TV advertising so far among presidential contenders. The cost to try to influence the 2008 election could exceed $3 billion, according to TNS Media Intelligence/Campaign Media Analysis Group, CNN's consultant on political television advertising. This is nearly twice as much than what was spent in 2004 when political and issue-advocacy television advertising rang in at $1.7 billion. In 2006, $2.3 billion was spent on political and issue-advocacy TV commercials. Just about every candidate running for an office from dogcatcher to president is spending the money, said Evan Tracey, CMAG's chief operating officer. The costs to produce a TV commercial are no longer prohibitive for local and state candidates, who are turning more and more to the airwaves to reach voters. See how spending breaks down for this year ». And interest groups have spent $6.2 million on TV ads so far this year for state and local ballot measures. On the national level, the cost of issue-advocacy television ad spending was $270 million in the first nine months of this year. Subjects ranged from the Iraq war to telecommunications reform. Television ads on health care alone total $60 million. CMAG estimates more than $3 million of the $270 million spent to air issue-advocacy ads this year has gone for commercials in states and districts that are likely to have competitive House and Senate races in 2008. Tracey said he thinks this is just the beginning of interest groups \"pivoting from legislative advocacy mode to political mode.\" \"What we expect to see between now and the end of the primaries, and through the general election, is groups will take a more aggressive stance on their advertising and actually target candidates,\" he said. With 17 Democratic and Republican candidates running for president, CMAG predicts that more than $800 million will be spent on TV ads in the battle for the White House. Up to now, the political commercials have been largely This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
    "  warnings.warn(\n",
    "{'loss': 1.1471, 'grad_norm': 2.422825813293457, 'learning_rate': 4.382413118071515e-06, 'epoch': 0.42, 'num_input_tokens_seen': 6309888, 'step': 76, 'step_time_sec': 6.93, 'avg_step_time_sec': 8.0, 'time_to_completion_sec': 855.6, 'estimated_total_time_sec': 1463.32, 'step_peak_memory_allocated_MB': 40672.67, 'step_peak_memory_reserved_MB': 69230.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10786.25, 'avg_tokens_per_second': 10395.0}\n",
    "{'loss': 1.1542, 'grad_norm': 2.490349531173706, 'learning_rate': 4.331159513600879e-06, 'epoch': 0.42, 'num_input_tokens_seen': 6392832, 'step': 77, 'step_time_sec': 9.72, 'avg_step_time_sec': 8.02, 'time_to_completion_sec': 850.01, 'estimated_total_time_sec': 1467.48, 'step_peak_memory_allocated_MB': 50872.95, 'step_peak_memory_reserved_MB': 69230.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8531.9, 'avg_tokens_per_second': 10365.28}\n",
    "{'loss': 1.1856, 'grad_norm': 2.5667724609375, 'learning_rate': 4.27941744928326e-06, 'epoch': 0.43, 'num_input_tokens_seen': 6462464, 'step': 78, 'step_time_sec': 5.77, 'avg_step_time_sec': 7.99, 'time_to_completion_sec': 838.93, 'estimated_total_time_sec': 1462.13, 'step_peak_memory_allocated_MB': 40672.67, 'step_peak_memory_reserved_MB': 69230.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 12072.15, 'avg_tokens_per_second': 10381.28}\n",
    "{'loss': 1.1534, 'grad_norm': 2.40911865234375, 'learning_rate': 4.22720591151402e-06, 'epoch': 0.43, 'num_input_tokens_seen': 6577152, 'step': 79, 'step_time_sec': 11.46, 'avg_step_time_sec': 8.03, 'time_to_completion_sec': 835.56, 'estimated_total_time_sec': 1470.26, 'step_peak_memory_allocated_MB': 62354.05, 'step_peak_memory_reserved_MB': 79474.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10012.02, 'avg_tokens_per_second': 10374.53}\n",
    "{'loss': 1.1181, 'grad_norm': 3.030595302581787, 'learning_rate': 4.174544058958587e-06, 'epoch': 0.44, 'num_input_tokens_seen': 6652928, 'step': 80, 'step_time_sec': 5.48, 'avg_step_time_sec': 8.0, 'time_to_completion_sec': 824.2, 'estimated_total_time_sec': 1464.35, 'step_peak_memory_allocated_MB': 50872.95, 'step_peak_memory_reserved_MB': 68124.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13815.6, 'avg_tokens_per_second': 10404.39}\n",
    "{'loss': 1.0986, 'grad_norm': 2.5752651691436768, 'learning_rate': 4.121451215522306e-06, 'epoch': 0.44, 'num_input_tokens_seen': 6732800, 'step': 81, 'step_time_sec': 7.72, 'avg_step_time_sec': 8.0, 'time_to_completion_sec': 815.84, 'estimated_total_time_sec': 1463.72, 'step_peak_memory_allocated_MB': 52149.36, 'step_peak_memory_reserved_MB': 78614.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10340.89, 'avg_tokens_per_second': 10403.62}\n",
    "{'loss': 1.0982, 'grad_norm': 2.496309995651245, 'learning_rate': 4.06794686325967e-06, 'epoch': 0.45, 'num_input_tokens_seen': 6813696, 'step': 82, 'step_time_sec': 7.24, 'avg_step_time_sec': 7.99, 'time_to_completion_sec': 806.9, 'estimated_total_time_sec': 1462.01, 'step_peak_memory_allocated_MB': 48322.5, 'step_peak_memory_reserved_MB': 68730.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11168.36, 'avg_tokens_per_second': 10412.18}\n",
    "{'loss': 1.1902, 'grad_norm': 2.438497543334961, 'learning_rate': 4.014050635225508e-06, 'epoch': 0.45, 'num_input_tokens_seen': 6905856, 'step': 83, 'step_time_sec': 7.81, 'avg_step_time_sec': 7.99, 'time_to_completion_sec': 798.69, 'estimated_total_time_sec': 1461.6, 'step_peak_memory_allocated_MB': 53424.51, 'step_peak_memory_reserved_MB': 78716.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11803.67, 'avg_tokens_per_second': 10428.77}\n",
    "{'loss': 1.1746, 'grad_norm': 2.5531554222106934, 'learning_rate': 3.9597823082707765e-06, 'epoch': 0.46, 'num_input_tokens_seen': 6983680, 'step': 84, 'step_time_sec': 7.6, 'avg_step_time_sec': 7.98, 'time_to_completion_sec': 790.24, 'estimated_total_time_sec': 1460.76, 'step_peak_memory_allocated_MB': 59802.48, 'step_peak_memory_reserved_MB': 79274.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10237.49, 'avg_tokens_per_second': 10426.58}\n",
    "{'loss': 1.1274, 'grad_norm': 2.5228047370910645, 'learning_rate': 3.905161795785577e-06, 'epoch': 0.46, 'num_input_tokens_seen': 7054336, 'step': 85, 'step_time_sec': 5.5, 'avg_step_time_sec': 7.95, 'time_to_completion_sec': 779.37, 'estimated_total_time_sec': 1455.35, 'step_peak_memory_allocated_MB': 48322.5, 'step_peak_memory_reserved_MB': 71108.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 12840.6, 'avg_tokens_per_second': 10446.46}\n",
    "{'loss': 1.1063, 'grad_norm': 2.643988847732544, 'learning_rate': 3.850209140392072e-06, 'epoch': 0.47, 'num_input_tokens_seen': 7126016, 'step': 86, 'step_time_sec': 8.75, 'avg_step_time_sec': 7.96, 'time_to_completion_sec': 772.33, 'estimated_total_time_sec': 1457.07, 'step_peak_memory_allocated_MB': 44497.3, 'step_peak_memory_reserved_MB': 71108.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8190.64, 'avg_tokens_per_second': 10417.29}\n",
    "{'loss': 1.094, 'grad_norm': 2.3685641288757324, 'learning_rate': 3.7949445065899857e-06, 'epoch': 0.48, 'num_input_tokens_seen': 7219200, 'step': 87, 'step_time_sec': 9.35, 'avg_step_time_sec': 7.98, 'time_to_completion_sec': 765.92, 'estimated_total_time_sec': 1460.03, 'step_peak_memory_allocated_MB': 59802.48, 'step_peak_memory_reserved_MB': 75254.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9965.4, 'avg_tokens_per_second': 10411.13}\n",
    "{'loss': 1.1792, 'grad_norm': 2.541347026824951, 'learning_rate': 3.739388173357378e-06, 'epoch': 0.48, 'num_input_tokens_seen': 7309312, 'step': 88, 'step_time_sec': 6.74, 'avg_step_time_sec': 7.96, 'time_to_completion_sec': 756.58, 'estimated_total_time_sec': 1457.42, 'step_peak_memory_allocated_MB': 55974.59, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13373.64, 'avg_tokens_per_second': 10439.94}\n",
    "{'loss': 1.1301, 'grad_norm': 2.639070510864258, 'learning_rate': 3.6835605267094133e-06, 'epoch': 0.49, 'num_input_tokens_seen': 7393280, 'step': 89, 'step_time_sec': 7.04, 'avg_step_time_sec': 7.95, 'time_to_completion_sec': 747.63, 'estimated_total_time_sec': 1455.49, 'step_peak_memory_allocated_MB': 41948.18, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11933.61, 'avg_tokens_per_second': 10454.96}\n",
    "{'loss': 1.1294, 'grad_norm': 2.4945743083953857, 'learning_rate': 3.6274820522178506e-06, 'epoch': 0.49, 'num_input_tokens_seen': 7482368, 'step': 90, 'step_time_sec': 9.9, 'avg_step_time_sec': 7.98, 'time_to_completion_sec': 741.71, 'estimated_total_time_sec': 1459.49, 'step_peak_memory_allocated_MB': 53424.51, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 9000.52, 'avg_tokens_per_second': 10434.68}\n",
    "{'loss': 1.134, 'grad_norm': 2.4122140407562256, 'learning_rate': 3.5711733274940054e-06, 'epoch': 0.5, 'num_input_tokens_seen': 7557120, 'step': 91, 'step_time_sec': 6.44, 'avg_step_time_sec': 7.96, 'time_to_completion_sec': 732.17, 'estimated_total_time_sec': 1456.38, 'step_peak_memory_allocated_MB': 52148.36, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11598.97, 'avg_tokens_per_second': 10445.15}\n",
    "{'loss': 1.1013, 'grad_norm': 2.677960157394409, 'learning_rate': 3.5146550146379353e-06, 'epoch': 0.5, 'num_input_tokens_seen': 7629824, 'step': 92, 'step_time_sec': 5.56, 'avg_step_time_sec': 7.93, 'time_to_completion_sec': 721.81, 'estimated_total_time_sec': 1451.56, 'step_peak_memory_allocated_MB': 50872.95, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13068.83, 'avg_tokens_per_second': 10465.37}\n",
    "{'loss': 1.1413, 'grad_norm': 2.4696204662323, 'learning_rate': 3.4579478526566237e-06, 'epoch': 0.51, 'num_input_tokens_seen': 7705600, 'step': 93, 'step_time_sec': 5.76, 'avg_step_time_sec': 7.91, 'time_to_completion_sec': 711.76, 'estimated_total_time_sec': 1447.24, 'step_peak_memory_allocated_MB': 47048.31, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13157.8, 'avg_tokens_per_second': 10486.68}\n",
    "{'loss': 1.1057, 'grad_norm': 2.391805410385132, 'learning_rate': 3.4010726498539453e-06, 'epoch': 0.51, 'num_input_tokens_seen': 7797760, 'step': 94, 'step_time_sec': 9.19, 'avg_step_time_sec': 7.92, 'time_to_completion_sec': 705.07, 'estimated_total_time_sec': 1449.76, 'step_peak_memory_allocated_MB': 50872.95, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10027.52, 'avg_tokens_per_second': 10480.96}\n",
    "{'loss': 1.0637, 'grad_norm': 2.459974527359009, 'learning_rate': 3.344050276195202e-06, 'epoch': 0.52, 'num_input_tokens_seen': 7875584, 'step': 95, 'step_time_sec': 6.6, 'avg_step_time_sec': 7.91, 'time_to_completion_sec': 695.92, 'estimated_total_time_sec': 1447.19, 'step_peak_memory_allocated_MB': 45772.31, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11787.85, 'avg_tokens_per_second': 10492.56}\n",
    "{'loss': 1.172, 'grad_norm': 2.5020899772644043, 'learning_rate': 3.286901655649027e-06, 'epoch': 0.52, 'num_input_tokens_seen': 7944192, 'step': 96, 'step_time_sec': 6.79, 'avg_step_time_sec': 7.9, 'time_to_completion_sec': 686.98, 'estimated_total_time_sec': 1445.03, 'step_peak_memory_allocated_MB': 47048.31, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 10108.82, 'avg_tokens_per_second': 10489.09}\n",
    "{'loss': 1.1714, 'grad_norm': 2.462374448776245, 'learning_rate': 3.229647758509488e-06, 'epoch': 0.53, 'num_input_tokens_seen': 8030208, 'step': 97, 'step_time_sec': 7.35, 'avg_step_time_sec': 7.89, 'time_to_completion_sec': 678.6, 'estimated_total_time_sec': 1444.0, 'step_peak_memory_allocated_MB': 58525.78, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11694.95, 'avg_tokens_per_second': 10500.8}\n",
    "{'loss': 1.0739, 'grad_norm': 2.4302234649658203, 'learning_rate': 3.1723095937011706e-06, 'epoch': 0.54, 'num_input_tokens_seen': 8100864, 'step': 98, 'step_time_sec': 4.99, 'avg_step_time_sec': 7.86, 'time_to_completion_sec': 668.17, 'estimated_total_time_sec': 1438.53, 'step_peak_memory_allocated_MB': 47048.31, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 14148.51, 'avg_tokens_per_second': 10524.69}\n",
    "{'loss': 1.1096, 'grad_norm': 2.443291425704956, 'learning_rate': 3.1149082010701064e-06, 'epoch': 0.54, 'num_input_tokens_seen': 8177664, 'step': 99, 'step_time_sec': 6.21, 'avg_step_time_sec': 7.84, 'time_to_completion_sec': 658.9, 'estimated_total_time_sec': 1435.46, 'step_peak_memory_allocated_MB': 45772.31, 'step_peak_memory_reserved_MB': 75756.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 12362.05, 'avg_tokens_per_second': 10539.54}\n",
    "{'loss': 1.1443, 'grad_norm': 2.4153530597686768, 'learning_rate': 3.0574646436633425e-06, 'epoch': 0.55, 'num_input_tokens_seen': 8264704, 'step': 100, 'step_time_sec': 9.95, 'avg_step_time_sec': 7.87, 'time_to_completion_sec': 652.82, 'estimated_total_time_sec': 1439.35, 'step_peak_memory_allocated_MB': 62354.05, 'step_peak_memory_reserved_MB': 78006.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8746.36, 'avg_tokens_per_second': 10516.62}\n",
    "{'loss': 1.0994, 'grad_norm': 3.123987913131714, 'learning_rate': 3e-06, 'epoch': 0.55, 'num_input_tokens_seen': 8342528, 'step': 101, 'step_time_sec': 6.84, 'avg_step_time_sec': 7.86, 'time_to_completion_sec': 644.11, 'estimated_total_time_sec': 1437.47, 'step_peak_memory_allocated_MB': 53424.51, 'step_peak_memory_reserved_MB': 77760.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11380.57, 'avg_tokens_per_second': 10524.14}\n",
    "{'loss': 1.2066, 'grad_norm': 2.5220799446105957, 'learning_rate': 2.9425353563366576e-06, 'epoch': 0.56, 'num_input_tokens_seen': 8413184, 'step': 102, 'step_time_sec': 5.47, 'avg_step_time_sec': 7.83, 'time_to_completion_sec': 634.35, 'estimated_total_time_sec': 1433.16, 'step_peak_memory_allocated_MB': 48322.5, 'step_peak_memory_reserved_MB': 77760.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 12908.92, 'avg_tokens_per_second': 10540.65}\n",
    "{'loss': 1.1081, 'grad_norm': 2.5078158378601074, 'learning_rate': 2.885091798929894e-06, 'epoch': 0.56, 'num_input_tokens_seen': 8501248, 'step': 103, 'step_time_sec': 9.98, 'avg_step_time_sec': 7.85, 'time_to_completion_sec': 628.2, 'estimated_total_time_sec': 1437.02, 'step_peak_memory_allocated_MB': 49598.38, 'step_peak_memory_reserved_MB': 77760.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 8821.55, 'avg_tokens_per_second': 10519.22}\n",
    "{'loss': 1.1277, 'grad_norm': 2.56307053565979, 'learning_rate': 2.8276904062988304e-06, 'epoch': 0.57, 'num_input_tokens_seen': 8571904, 'step': 104, 'step_time_sec': 6.19, 'avg_step_time_sec': 7.84, 'time_to_completion_sec': 619.08, 'estimated_total_time_sec': 1434.06, 'step_peak_memory_allocated_MB': 43222.36, 'step_peak_memory_reserved_MB': 77760.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 11411.97, 'avg_tokens_per_second': 10526.07}\n",
    "{'loss': 1.1272, 'grad_norm': 2.6101255416870117, 'learning_rate': 2.770352241490513e-06, 'epoch': 0.57, 'num_input_tokens_seen': 8640512, 'step': 105, 'step_time_sec': 5.23, 'avg_step_time_sec': 7.81, 'time_to_completion_sec': 609.28, 'estimated_total_time_sec': 1429.47, 'step_peak_memory_allocated_MB': 50872.95, 'step_peak_memory_reserved_MB': 77760.0, 'total_peak_memory_allocated_MB': 66180.87, 'total_peak_memory_reserved_MB': 79498.0, 'step_tokens_per_second': 13123.83, 'avg_tokens_per_second': 10542.78}\n",
    " 57%|███████████████████████████████████████████████████████████████████████████▏                                                       | 105/183 [13:56<08:48,  6.78s/it][rank2]: Traceback (most recent call last):\n",
    "[rank2]:   File \"/home/ubuntu/Liger-Kernel/examples/huggingface/training.py\", line 81, in <module>\n",
    "[rank2]:     train()\n",
    "[rank2]:   File \"/home/ubuntu/Liger-Kernel/examples/huggingface/training.py\", line 77, in train\n",
    "[rank2]:     trainer.train()\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py\", line 450, in train\n",
    "[rank2]:     output = super().train(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/transformers/trainer.py\", line 1938, in train\n",
    "[rank2]:     return inner_training_loop(\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/transformers/trainer.py\", line 2279, in _inner_training_loop\n",
    "[rank2]:     tr_loss_step = self.training_step(model, inputs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/transformers/trainer.py\", line 3318, in training_step\n",
    "[rank2]:     loss = self.compute_loss(model, inputs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/transformers/trainer.py\", line 3363, in compute_loss\n",
    "[rank2]:     outputs = model(**inputs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
    "[rank2]:     return self._call_impl(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
    "[rank2]:     return forward_call(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 819, in forward\n",
    "[rank2]:     return model_forward(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
    "[rank2]:     return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/amp/autocast_mode.py\", line 43, in decorate_autocast\n",
    "[rank2]:     return func(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py\", line 863, in forward\n",
    "[rank2]:     output = self._fsdp_wrapped_module(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
    "[rank2]:     return self._call_impl(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
    "[rank2]:     return forward_call(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 819, in forward\n",
    "[rank2]:     return model_forward(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/utils/operations.py\", line 807, in __call__\n",
    "[rank2]:     return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/amp/autocast_mode.py\", line 43, in decorate_autocast\n",
    "[rank2]:     return func(*args, **kwargs)\n",
    "[rank2]:   File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py\", line 1166, in forward\n",
    "[rank2]:     shift_logits = logits[..., :-1, :].contiguous()\n",
    "[rank2]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 15.63 GiB. GPU 2 has a total capacity of 79.15 GiB of which 13.88 GiB is free. Including non-PyTorch memory, this process has 65.26 GiB memory in use. Of the allocated memory 48.60 GiB is allocated by PyTorch, and 15.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
    "W0829 21:39:48.437000 140308402159616 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 10886 closing signal SIGTERM\n",
    "W0829 21:39:48.440000 140308402159616 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 10887 closing signal SIGTERM\n",
    "W0829 21:39:48.442000 140308402159616 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 10889 closing signal SIGTERM\n",
    "E0829 21:39:49.874000 140308402159616 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 2 (pid: 10888) of binary: /home/ubuntu/.virtualenvs/batch-size-memory-testing/bin/python\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/bin/torchrun\", line 8, in <module>\n",
    "    sys.exit(main())\n",
    "  File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
    "    return f(*args, **kwargs)\n",
    "  File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/distributed/run.py\", line 901, in main\n",
    "    run(args)\n",
    "  File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/distributed/run.py\", line 892, in run\n",
    "    elastic_launch(\n",
    "  File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 133, in __call__\n",
    "    return launch_agent(self._config, self._entrypoint, list(args))\n",
    "  File \"/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
    "    raise ChildFailedError(\n",
    "torch.distributed.elastic.multiprocessing.errors.ChildFailedError:\n",
    "============================================================\n",
    "training.py FAILED\n",
    "------------------------------------------------------------\n",
    "Failures:\n",
    "  <NO_OTHER_FAILURES>\n",
    "------------------------------------------------------------\n",
    "Root Cause (first observed failure):\n",
    "[0]:\n",
    "  time      : 2024-08-29_21:39:48\n",
    "  host      : 164-152-19-130\n",
    "  rank      : 2 (local_rank: 2)\n",
    "  exitcode  : 1 (pid: 10888)\n",
    "  error_file: <N/A>\n",
    "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
    "============================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ecb6dff-dcaf-41ab-8bec-2abba5c6b2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>num_input_tokens_seen</th>\n",
       "      <th>step</th>\n",
       "      <th>step_time_sec</th>\n",
       "      <th>avg_step_time_sec</th>\n",
       "      <th>time_to_completion_sec</th>\n",
       "      <th>estimated_total_time_sec</th>\n",
       "      <th>step_peak_memory_allocated_MB</th>\n",
       "      <th>step_peak_memory_reserved_MB</th>\n",
       "      <th>total_peak_memory_allocated_MB</th>\n",
       "      <th>total_peak_memory_reserved_MB</th>\n",
       "      <th>step_tokens_per_second</th>\n",
       "      <th>avg_tokens_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2993</td>\n",
       "      <td>9.791667</td>\n",
       "      <td>6.315789e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>167936</td>\n",
       "      <td>2</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.33</td>\n",
       "      <td>1869.28</td>\n",
       "      <td>1889.94</td>\n",
       "      <td>62354.05</td>\n",
       "      <td>79408.0</td>\n",
       "      <td>62354.05</td>\n",
       "      <td>79408.0</td>\n",
       "      <td>8923.72</td>\n",
       "      <td>8923.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4052</td>\n",
       "      <td>9.731947</td>\n",
       "      <td>9.473684e-07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>250880</td>\n",
       "      <td>3</td>\n",
       "      <td>9.15</td>\n",
       "      <td>9.74</td>\n",
       "      <td>1752.71</td>\n",
       "      <td>1781.92</td>\n",
       "      <td>41948.18</td>\n",
       "      <td>70586.0</td>\n",
       "      <td>62354.05</td>\n",
       "      <td>79408.0</td>\n",
       "      <td>9067.88</td>\n",
       "      <td>8991.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3677</td>\n",
       "      <td>9.187686</td>\n",
       "      <td>1.263158e-06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329728</td>\n",
       "      <td>4</td>\n",
       "      <td>7.11</td>\n",
       "      <td>8.86</td>\n",
       "      <td>1586.12</td>\n",
       "      <td>1621.57</td>\n",
       "      <td>55974.59</td>\n",
       "      <td>79410.0</td>\n",
       "      <td>62354.05</td>\n",
       "      <td>79410.0</td>\n",
       "      <td>11092.03</td>\n",
       "      <td>9553.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.4013</td>\n",
       "      <td>9.777603</td>\n",
       "      <td>1.578947e-06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>406528</td>\n",
       "      <td>5</td>\n",
       "      <td>6.52</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1473.21</td>\n",
       "      <td>1514.59</td>\n",
       "      <td>45772.31</td>\n",
       "      <td>67092.0</td>\n",
       "      <td>62354.05</td>\n",
       "      <td>79410.0</td>\n",
       "      <td>11774.07</td>\n",
       "      <td>9990.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3633</td>\n",
       "      <td>8.155755</td>\n",
       "      <td>1.894737e-06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>478208</td>\n",
       "      <td>6</td>\n",
       "      <td>6.07</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1386.98</td>\n",
       "      <td>1434.00</td>\n",
       "      <td>52149.36</td>\n",
       "      <td>77582.0</td>\n",
       "      <td>62354.05</td>\n",
       "      <td>79410.0</td>\n",
       "      <td>11800.20</td>\n",
       "      <td>10271.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0994</td>\n",
       "      <td>3.123988</td>\n",
       "      <td>3.000000e-06</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8342528</td>\n",
       "      <td>101</td>\n",
       "      <td>6.84</td>\n",
       "      <td>7.86</td>\n",
       "      <td>644.11</td>\n",
       "      <td>1437.47</td>\n",
       "      <td>53424.51</td>\n",
       "      <td>77760.0</td>\n",
       "      <td>66180.87</td>\n",
       "      <td>79498.0</td>\n",
       "      <td>11380.57</td>\n",
       "      <td>10524.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.2066</td>\n",
       "      <td>2.522080</td>\n",
       "      <td>2.942535e-06</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8413184</td>\n",
       "      <td>102</td>\n",
       "      <td>5.47</td>\n",
       "      <td>7.83</td>\n",
       "      <td>634.35</td>\n",
       "      <td>1433.16</td>\n",
       "      <td>48322.50</td>\n",
       "      <td>77760.0</td>\n",
       "      <td>66180.87</td>\n",
       "      <td>79498.0</td>\n",
       "      <td>12908.92</td>\n",
       "      <td>10540.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1.1081</td>\n",
       "      <td>2.507816</td>\n",
       "      <td>2.885092e-06</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8501248</td>\n",
       "      <td>103</td>\n",
       "      <td>9.98</td>\n",
       "      <td>7.85</td>\n",
       "      <td>628.20</td>\n",
       "      <td>1437.02</td>\n",
       "      <td>49598.38</td>\n",
       "      <td>77760.0</td>\n",
       "      <td>66180.87</td>\n",
       "      <td>79498.0</td>\n",
       "      <td>8821.55</td>\n",
       "      <td>10519.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.1277</td>\n",
       "      <td>2.563071</td>\n",
       "      <td>2.827690e-06</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8571904</td>\n",
       "      <td>104</td>\n",
       "      <td>6.19</td>\n",
       "      <td>7.84</td>\n",
       "      <td>619.08</td>\n",
       "      <td>1434.06</td>\n",
       "      <td>43222.36</td>\n",
       "      <td>77760.0</td>\n",
       "      <td>66180.87</td>\n",
       "      <td>79498.0</td>\n",
       "      <td>11411.97</td>\n",
       "      <td>10526.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.1272</td>\n",
       "      <td>2.610126</td>\n",
       "      <td>2.770352e-06</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8640512</td>\n",
       "      <td>105</td>\n",
       "      <td>5.23</td>\n",
       "      <td>7.81</td>\n",
       "      <td>609.28</td>\n",
       "      <td>1429.47</td>\n",
       "      <td>50872.95</td>\n",
       "      <td>77760.0</td>\n",
       "      <td>66180.87</td>\n",
       "      <td>79498.0</td>\n",
       "      <td>13123.83</td>\n",
       "      <td>10542.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  grad_norm  learning_rate  epoch  num_input_tokens_seen  step  \\\n",
       "0    1.2993   9.791667   6.315789e-07   0.01                 167936     2   \n",
       "1    1.4052   9.731947   9.473684e-07   0.02                 250880     3   \n",
       "2    1.3677   9.187686   1.263158e-06   0.02                 329728     4   \n",
       "3    1.4013   9.777603   1.578947e-06   0.03                 406528     5   \n",
       "4    1.3633   8.155755   1.894737e-06   0.03                 478208     6   \n",
       "..      ...        ...            ...    ...                    ...   ...   \n",
       "99   1.0994   3.123988   3.000000e-06   0.55                8342528   101   \n",
       "100  1.2066   2.522080   2.942535e-06   0.56                8413184   102   \n",
       "101  1.1081   2.507816   2.885092e-06   0.56                8501248   103   \n",
       "102  1.1277   2.563071   2.827690e-06   0.57                8571904   104   \n",
       "103  1.1272   2.610126   2.770352e-06   0.57                8640512   105   \n",
       "\n",
       "     step_time_sec  avg_step_time_sec  time_to_completion_sec  \\\n",
       "0            10.33              10.33                 1869.28   \n",
       "1             9.15               9.74                 1752.71   \n",
       "2             7.11               8.86                 1586.12   \n",
       "3             6.52               8.28                 1473.21   \n",
       "4             6.07               7.84                 1386.98   \n",
       "..             ...                ...                     ...   \n",
       "99            6.84               7.86                  644.11   \n",
       "100           5.47               7.83                  634.35   \n",
       "101           9.98               7.85                  628.20   \n",
       "102           6.19               7.84                  619.08   \n",
       "103           5.23               7.81                  609.28   \n",
       "\n",
       "     estimated_total_time_sec  step_peak_memory_allocated_MB  \\\n",
       "0                     1889.94                       62354.05   \n",
       "1                     1781.92                       41948.18   \n",
       "2                     1621.57                       55974.59   \n",
       "3                     1514.59                       45772.31   \n",
       "4                     1434.00                       52149.36   \n",
       "..                        ...                            ...   \n",
       "99                    1437.47                       53424.51   \n",
       "100                   1433.16                       48322.50   \n",
       "101                   1437.02                       49598.38   \n",
       "102                   1434.06                       43222.36   \n",
       "103                   1429.47                       50872.95   \n",
       "\n",
       "     step_peak_memory_reserved_MB  total_peak_memory_allocated_MB  \\\n",
       "0                         79408.0                        62354.05   \n",
       "1                         70586.0                        62354.05   \n",
       "2                         79410.0                        62354.05   \n",
       "3                         67092.0                        62354.05   \n",
       "4                         77582.0                        62354.05   \n",
       "..                            ...                             ...   \n",
       "99                        77760.0                        66180.87   \n",
       "100                       77760.0                        66180.87   \n",
       "101                       77760.0                        66180.87   \n",
       "102                       77760.0                        66180.87   \n",
       "103                       77760.0                        66180.87   \n",
       "\n",
       "     total_peak_memory_reserved_MB  step_tokens_per_second  \\\n",
       "0                          79408.0                 8923.72   \n",
       "1                          79408.0                 9067.88   \n",
       "2                          79410.0                11092.03   \n",
       "3                          79410.0                11774.07   \n",
       "4                          79410.0                11800.20   \n",
       "..                             ...                     ...   \n",
       "99                         79498.0                11380.57   \n",
       "100                        79498.0                12908.92   \n",
       "101                        79498.0                 8821.55   \n",
       "102                        79498.0                11411.97   \n",
       "103                        79498.0                13123.83   \n",
       "\n",
       "     avg_tokens_per_second  \n",
       "0                  8923.72  \n",
       "1                  8991.43  \n",
       "2                  9553.14  \n",
       "3                  9990.73  \n",
       "4                 10271.27  \n",
       "..                     ...  \n",
       "99                10524.14  \n",
       "100               10540.65  \n",
       "101               10519.22  \n",
       "102               10526.07  \n",
       "103               10542.78  \n",
       "\n",
       "[104 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = extract_dicts_from_log(v020_data)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "v020 = pd.DataFrame(dicts)\n",
    "\n",
    "# Display the DataFrame\n",
    "v020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f3b1193-ca36-4ac3-be75-742a88a06fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v021_data = \"\"\"\n",
    "(batch-size-memory-testing) ubuntu@164-152-31-252:~/Liger-Kernel/examples/huggingface$ chmod +x ./run_llama.sh\n",
    "./run_llama.sh\n",
    "W0830 00:38:47.072000 140325209432064 torch/distributed/run.py:779]\n",
    "W0830 00:38:47.072000 140325209432064 torch/distributed/run.py:779] *****************************************\n",
    "W0830 00:38:47.072000 140325209432064 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
    "W0830 00:38:47.072000 140325209432064 torch/distributed/run.py:779] *****************************************\n",
    "2024-08-30 00:38:49.752018: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "2024-08-30 00:38:49.769534: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "2024-08-30 00:38:49.775033: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "2024-08-30 00:38:49.789225: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-08-30 00:38:49.798923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "2024-08-30 00:38:49.804447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "2024-08-30 00:38:49.817574: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "2024-08-30 00:38:49.822397: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "2024-08-30 00:38:49.823215: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "2024-08-30 00:38:49.824481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
    "2024-08-30 00:38:49.827934: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "2024-08-30 00:38:49.837962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-08-30 00:38:49.842036: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
    "2024-08-30 00:38:49.842162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-08-30 00:38:49.847423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
    "2024-08-30 00:38:49.861152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
    "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2024-08-30 00:38:50.895758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "2024-08-30 00:38:50.940185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "2024-08-30 00:38:50.940452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "2024-08-30 00:38:50.979592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
    "tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 50.6k/50.6k [00:00<00:00, 2.46MB/s]\n",
    "tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.09M/9.09M [00:00<00:00, 17.7MB/s]\n",
    "special_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 73.0/73.0 [00:00<00:00, 465kB/s]\n",
    "Downloading readme: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.47k/7.47k [00:00<00:00, 110kB/s]\n",
    "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24.2M/24.2M [00:00<00:00, 80.3MB/s]\n",
    "Generating train split: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 52002/52002 [00:00<00:00, 260301.00 examples/s]\n",
    "config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 654/654 [00:00<00:00, 4.04MB/s]\n",
    "model.safetensors.index.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 23.9k/23.9k [00:00<00:00, 121MB/s]\n",
    "model-00001-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4.98G/4.98G [00:26<00:00, 191MB/s]\n",
    "model-00002-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 5.00G/5.00G [00:25<00:00, 198MB/s]\n",
    "model-00003-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4.92G/4.92G [00:25<00:00, 193MB/s]\n",
    "model-00004-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1.17G/1.17G [00:04<00:00, 238MB/s]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:22<00:00, 20.55s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:22<00:00, 20.56s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:22<00:00, 20.56s/it]\n",
    "Downloading shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [01:22<00:00, 20.57s/it]\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.57it/s]\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  3.59it/s]\n",
    "generation_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 177/177 [00:00<00:00, 1.61MB/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.99it/s]\n",
    "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.94it/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
    "\n",
    "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
    "  warnings.warn(message, FutureWarning)\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
    "  warnings.warn(\n",
    "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 11554.45 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 7137.28 examples/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 9753.36 examples/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:04<00:00, 9405.03 examples/s]\n",
    "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46801/46801 [00:05<00:00, 9289.18 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 5314.54 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 5604.23 examples/s]\n",
    "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5201/5201 [00:00<00:00, 5762.92 examples/s]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1558: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1558: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.\n",
    "  warnings.warn(\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/accelerate/accelerator.py:1564: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.\n",
    "  warnings.warn(\n",
    "  0%|                                                                                                                                             | 0/183 [00:00<?, ?it/s]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.311, 'grad_norm': 11.20170783996582, 'learning_rate': 3.157894736842105e-07, 'epoch': 0.01, 'num_input_tokens_seen': 73728}\n",
    "{'loss': 1.2891, 'grad_norm': 9.976593017578125, 'learning_rate': 6.31578947368421e-07, 'epoch': 0.01, 'num_input_tokens_seen': 153600, 'step': 2, 'step_time_sec': 5.65, 'avg_step_time_sec': 5.65, 'time_to_completion_sec': 1022.81, 'estimated_total_time_sec': 1034.11, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 58420.0, 'total_peak_memory_allocated_MB': 38307.94, 'total_peak_memory_reserved_MB': 58420.0, 'step_tokens_per_second': 14134.49, 'avg_tokens_per_second': 14134.49}\n",
    "{'loss': 1.4091, 'grad_norm': 9.613659858703613, 'learning_rate': 9.473684210526316e-07, 'epoch': 0.02, 'num_input_tokens_seen': 241664, 'step': 3, 'step_time_sec': 6.49, 'avg_step_time_sec': 6.07, 'time_to_completion_sec': 1092.46, 'estimated_total_time_sec': 1110.67, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 60884.0, 'total_peak_memory_allocated_MB': 38308.05, 'total_peak_memory_reserved_MB': 60884.0, 'step_tokens_per_second': 13574.21, 'avg_tokens_per_second': 13835.04}\n",
    "{'loss': 1.3436, 'grad_norm': 10.107481002807617, 'learning_rate': 1.263157894736842e-06, 'epoch': 0.02, 'num_input_tokens_seen': 332800, 'step': 4, 'step_time_sec': 7.43, 'avg_step_time_sec': 6.52, 'time_to_completion_sec': 1167.41, 'estimated_total_time_sec': 1193.5, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 60884.0, 'total_peak_memory_allocated_MB': 38308.05, 'total_peak_memory_reserved_MB': 60884.0, 'step_tokens_per_second': 12270.76, 'avg_tokens_per_second': 13241.24}\n",
    "{'loss': 1.3494, 'grad_norm': 9.736581802368164, 'learning_rate': 1.5789473684210526e-06, 'epoch': 0.03, 'num_input_tokens_seen': 395264, 'step': 5, 'step_time_sec': 4.66, 'avg_step_time_sec': 6.06, 'time_to_completion_sec': 1078.11, 'estimated_total_time_sec': 1108.39, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 60884.0, 'total_peak_memory_allocated_MB': 38308.05, 'total_peak_memory_reserved_MB': 60884.0, 'step_tokens_per_second': 13399.55, 'avg_tokens_per_second': 13271.7}\n",
    "{'loss': 1.3698, 'grad_norm': 7.8975043296813965, 'learning_rate': 1.8947368421052632e-06, 'epoch': 0.03, 'num_input_tokens_seen': 495616, 'step': 6, 'step_time_sec': 8.23, 'avg_step_time_sec': 6.49, 'time_to_completion_sec': 1148.88, 'estimated_total_time_sec': 1187.83, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12197.81, 'avg_tokens_per_second': 12999.47}\n",
    "{'loss': 1.3106, 'grad_norm': 8.579422950744629, 'learning_rate': 2.2105263157894738e-06, 'epoch': 0.04, 'num_input_tokens_seen': 573440, 'step': 7, 'step_time_sec': 5.22, 'avg_step_time_sec': 6.28, 'time_to_completion_sec': 1105.2, 'estimated_total_time_sec': 1149.16, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14900.19, 'avg_tokens_per_second': 13262.96}\n",
    "{'loss': 1.381, 'grad_norm': 7.3687825202941895, 'learning_rate': 2.526315789473684e-06, 'epoch': 0.04, 'num_input_tokens_seen': 683008, 'step': 8, 'step_time_sec': 8.29, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 1149.23, 'estimated_total_time_sec': 1201.76, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13214.07, 'avg_tokens_per_second': 13254.14}\n",
    "{'loss': 1.2926, 'grad_norm': 3.5316898822784424, 'learning_rate': 2.8421052631578946e-06, 'epoch': 0.05, 'num_input_tokens_seen': 757760, 'step': 9, 'step_time_sec': 5.42, 'avg_step_time_sec': 6.42, 'time_to_completion_sec': 1117.67, 'estimated_total_time_sec': 1175.48, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13796.58, 'avg_tokens_per_second': 13311.33}\n",
    "{'loss': 1.2868, 'grad_norm': 3.765230655670166, 'learning_rate': 3.157894736842105e-06, 'epoch': 0.05, 'num_input_tokens_seen': 845824, 'step': 10, 'step_time_sec': 7.3, 'avg_step_time_sec': 6.52, 'time_to_completion_sec': 1128.08, 'estimated_total_time_sec': 1193.29, 'step_peak_memory_allocated_MB': 38629.85, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12065.1, 'avg_tokens_per_second': 13156.33}\n",
    "{'loss': 1.3394, 'grad_norm': 3.4735705852508545, 'learning_rate': 3.473684210526316e-06, 'epoch': 0.06, 'num_input_tokens_seen': 953344, 'step': 11, 'step_time_sec': 8.21, 'avg_step_time_sec': 6.69, 'time_to_completion_sec': 1150.54, 'estimated_total_time_sec': 1224.12, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13103.36, 'avg_tokens_per_second': 13149.84}\n",
    "{'loss': 1.2883, 'grad_norm': 5.749035835266113, 'learning_rate': 3.7894736842105264e-06, 'epoch': 0.07, 'num_input_tokens_seen': 1046528, 'step': 12, 'step_time_sec': 6.79, 'avg_step_time_sec': 6.7, 'time_to_completion_sec': 1145.49, 'estimated_total_time_sec': 1225.87, 'step_peak_memory_allocated_MB': 38629.85, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13714.72, 'avg_tokens_per_second': 13201.92}\n",
    "{'loss': 1.164, 'grad_norm': 4.168029308319092, 'learning_rate': 4.105263157894737e-06, 'epoch': 0.07, 'num_input_tokens_seen': 1127424, 'step': 13, 'step_time_sec': 5.79, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 1125.86, 'estimated_total_time_sec': 1211.95, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13981.48, 'avg_tokens_per_second': 13258.68}\n",
    "{'loss': 1.2401, 'grad_norm': 6.774705410003662, 'learning_rate': 4.4210526315789476e-06, 'epoch': 0.08, 'num_input_tokens_seen': 1208320, 'step': 14, 'step_time_sec': 6.5, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 1117.64, 'estimated_total_time_sec': 1210.23, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12445.31, 'avg_tokens_per_second': 13197.18}\n",
    "{'loss': 1.2363, 'grad_norm': 3.555173873901367, 'learning_rate': 4.736842105263158e-06, 'epoch': 0.08, 'num_input_tokens_seen': 1296384, 'step': 15, 'step_time_sec': 6.8, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 1113.31, 'estimated_total_time_sec': 1212.72, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12943.34, 'avg_tokens_per_second': 13178.57}\n",
    "{'loss': 1.2218, 'grad_norm': 3.3054089546203613, 'learning_rate': 5.052631578947368e-06, 'epoch': 0.09, 'num_input_tokens_seen': 1369088, 'step': 16, 'step_time_sec': 6.16, 'avg_step_time_sec': 6.6, 'time_to_completion_sec': 1101.5, 'estimated_total_time_sec': 1207.03, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11800.52, 'avg_tokens_per_second': 13092.75}\n",
    "{'loss': 1.242, 'grad_norm': 2.8901445865631104, 'learning_rate': 5.368421052631579e-06, 'epoch': 0.09, 'num_input_tokens_seen': 1448960, 'step': 17, 'step_time_sec': 7.03, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 1099.44, 'estimated_total_time_sec': 1212.03, 'step_peak_memory_allocated_MB': 38307.84, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11356.83, 'avg_tokens_per_second': 12977.54}\n",
    "{'loss': 1.2133, 'grad_norm': 3.233943223953247, 'learning_rate': 5.684210526315789e-06, 'epoch': 0.1, 'num_input_tokens_seen': 1536000, 'step': 18, 'step_time_sec': 6.12, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 1087.96, 'estimated_total_time_sec': 1206.64, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14216.88, 'avg_tokens_per_second': 13045.23}\n",
    "{'loss': 1.1388, 'grad_norm': 3.4579644203186035, 'learning_rate': 6e-06, 'epoch': 0.1, 'num_input_tokens_seen': 1620992, 'step': 19, 'step_time_sec': 7.51, 'avg_step_time_sec': 6.64, 'time_to_completion_sec': 1089.73, 'estimated_total_time_sec': 1215.98, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11313.25, 'avg_tokens_per_second': 12936.45}\n",
    "{'loss': 1.2576, 'grad_norm': 3.0374457836151123, 'learning_rate': 5.9994495852953836e-06, 'epoch': 0.11, 'num_input_tokens_seen': 1693696, 'step': 20, 'step_time_sec': 5.47, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 1073.03, 'estimated_total_time_sec': 1204.69, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13285.16, 'avg_tokens_per_second': 12951.7}\n",
    "{'loss': 1.1991, 'grad_norm': 3.061511516571045, 'learning_rate': 5.997798543152429e-06, 'epoch': 0.11, 'num_input_tokens_seen': 1771520, 'step': 21, 'step_time_sec': 7.28, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 1072.06, 'estimated_total_time_sec': 1211.03, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10697.12, 'avg_tokens_per_second': 12827.77}\n",
    "{'loss': 1.2089, 'grad_norm': 2.6074204444885254, 'learning_rate': 5.9950474794097236e-06, 'epoch': 0.12, 'num_input_tokens_seen': 1872896, 'step': 22, 'step_time_sec': 7.35, 'avg_step_time_sec': 6.65, 'time_to_completion_sec': 1071.06, 'estimated_total_time_sec': 1217.42, 'step_peak_memory_allocated_MB': 39248.95, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13790.75, 'avg_tokens_per_second': 12878.44}\n",
    "{'loss': 1.2516, 'grad_norm': 2.7089760303497314, 'learning_rate': 5.9911974035512214e-06, 'epoch': 0.13, 'num_input_tokens_seen': 1968128, 'step': 23, 'step_time_sec': 7.05, 'avg_step_time_sec': 6.67, 'time_to_completion_sec': 1067.29, 'estimated_total_time_sec': 1220.71, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13511.64, 'avg_tokens_per_second': 12908.85}\n",
    "{'loss': 1.1979, 'grad_norm': 3.071645975112915, 'learning_rate': 5.9862497283358345e-06, 'epoch': 0.13, 'num_input_tokens_seen': 2033664, 'step': 24, 'step_time_sec': 5.78, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 1054.48, 'estimated_total_time_sec': 1213.64, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11333.76, 'avg_tokens_per_second': 12849.14}\n",
    "{'loss': 1.2946, 'grad_norm': 2.830185651779175, 'learning_rate': 5.980206269279025e-06, 'epoch': 0.14, 'num_input_tokens_seen': 2104320, 'step': 25, 'step_time_sec': 4.94, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 1036.73, 'estimated_total_time_sec': 1200.77, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14292.97, 'avg_tokens_per_second': 12894.47}\n",
    "{'loss': 1.1642, 'grad_norm': 2.7993905544281006, 'learning_rate': 5.973069243986614e-06, 'epoch': 0.14, 'num_input_tokens_seen': 2174976, 'step': 26, 'step_time_sec': 5.16, 'avg_step_time_sec': 6.51, 'time_to_completion_sec': 1021.36, 'estimated_total_time_sec': 1190.51, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13693.81, 'avg_tokens_per_second': 12919.83}\n",
    "{'loss': 1.2362, 'grad_norm': 2.7283363342285156, 'learning_rate': 5.964841271341046e-06, 'epoch': 0.15, 'num_input_tokens_seen': 2258944, 'step': 27, 'step_time_sec': 6.96, 'avg_step_time_sec': 6.52, 'time_to_completion_sec': 1017.61, 'estimated_total_time_sec': 1193.73, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12057.27, 'avg_tokens_per_second': 12884.41}\n",
    "{'loss': 1.1748, 'grad_norm': 2.6129350662231445, 'learning_rate': 5.95552537054041e-06, 'epoch': 0.15, 'num_input_tokens_seen': 2344960, 'step': 28, 'step_time_sec': 8.33, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 1021.46, 'estimated_total_time_sec': 1205.98, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10326.67, 'avg_tokens_per_second': 12764.67}\n",
    "{'loss': 1.1453, 'grad_norm': 2.6744749546051025, 'learning_rate': 5.945124959990565e-06, 'epoch': 0.16, 'num_input_tokens_seen': 2419712, 'step': 29, 'step_time_sec': 5.95, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 1011.32, 'estimated_total_time_sec': 1201.76, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12573.9, 'avg_tokens_per_second': 12758.51}\n",
    "{'loss': 1.2519, 'grad_norm': 3.0947582721710205, 'learning_rate': 5.933643856050778e-06, 'epoch': 0.16, 'num_input_tokens_seen': 2488320, 'step': 30, 'step_time_sec': 4.98, 'avg_step_time_sec': 6.51, 'time_to_completion_sec': 996.4, 'estimated_total_time_sec': 1191.78, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13763.76, 'avg_tokens_per_second': 12785.04}\n",
    "{'loss': 1.2369, 'grad_norm': 2.740720272064209, 'learning_rate': 5.921086271633337e-06, 'epoch': 0.17, 'num_input_tokens_seen': 2577408, 'step': 31, 'step_time_sec': 6.2, 'avg_step_time_sec': 6.5, 'time_to_completion_sec': 988.29, 'estimated_total_time_sec': 1189.84, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14379.19, 'avg_tokens_per_second': 12835.67}\n",
    "{'loss': 1.1516, 'grad_norm': 2.7670297622680664, 'learning_rate': 5.907456814657656e-06, 'epoch': 0.17, 'num_input_tokens_seen': 2652160, 'step': 32, 'step_time_sec': 6.04, 'avg_step_time_sec': 6.49, 'time_to_completion_sec': 979.55, 'estimated_total_time_sec': 1187.14, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12369.28, 'avg_tokens_per_second': 12821.66}\n",
    "{'loss': 1.2276, 'grad_norm': 2.8464841842651367, 'learning_rate': 5.892760486359423e-06, 'epoch': 0.18, 'num_input_tokens_seen': 2728960, 'step': 33, 'step_time_sec': 6.03, 'avg_step_time_sec': 6.47, 'time_to_completion_sec': 970.9, 'estimated_total_time_sec': 1184.49, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12746.84, 'avg_tokens_per_second': 12819.48}\n",
    "{'loss': 1.2345, 'grad_norm': 3.011551856994629, 'learning_rate': 5.877002679455439e-06, 'epoch': 0.19, 'num_input_tokens_seen': 2804736, 'step': 34, 'step_time_sec': 6.6, 'avg_step_time_sec': 6.48, 'time_to_completion_sec': 964.99, 'estimated_total_time_sec': 1185.19, 'step_peak_memory_allocated_MB': 38307.84, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11486.11, 'avg_tokens_per_second': 12778.32}\n",
    "{'loss': 1.2288, 'grad_norm': 2.7519891262054443, 'learning_rate': 5.860189176164791e-06, 'epoch': 0.19, 'num_input_tokens_seen': 2878464, 'step': 35, 'step_time_sec': 5.22, 'avg_step_time_sec': 6.44, 'time_to_completion_sec': 953.05, 'estimated_total_time_sec': 1178.43, 'step_peak_memory_allocated_MB': 38307.98, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14120.27, 'avg_tokens_per_second': 12810.33}\n",
    "{'loss': 1.1727, 'grad_norm': 2.354231357574463, 'learning_rate': 5.842326146087113e-06, 'epoch': 0.2, 'num_input_tokens_seen': 2982912, 'step': 36, 'step_time_sec': 8.25, 'avg_step_time_sec': 6.49, 'time_to_completion_sec': 954.23, 'estimated_total_time_sec': 1187.91, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12655.64, 'avg_tokens_per_second': 12804.71}\n",
    "{'loss': 1.1638, 'grad_norm': 2.595043182373047, 'learning_rate': 5.823420143938684e-06, 'epoch': 0.2, 'num_input_tokens_seen': 3081216, 'step': 37, 'step_time_sec': 7.69, 'avg_step_time_sec': 6.52, 'time_to_completion_sec': 952.58, 'estimated_total_time_sec': 1193.98, 'step_peak_memory_allocated_MB': 40100.53, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12790.42, 'avg_tokens_per_second': 12804.24}\n",
    "{'loss': 1.2124, 'grad_norm': 2.781266689300537, 'learning_rate': 5.803478107147233e-06, 'epoch': 0.21, 'num_input_tokens_seen': 3153920, 'step': 38, 'step_time_sec': 6.03, 'avg_step_time_sec': 6.51, 'time_to_completion_sec': 944.13, 'estimated_total_time_sec': 1191.56, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12050.43, 'avg_tokens_per_second': 12785.36}\n",
    "{'loss': 1.2039, 'grad_norm': 2.731630325317383, 'learning_rate': 5.7825073533062846e-06, 'epoch': 0.21, 'num_input_tokens_seen': 3229696, 'step': 39, 'step_time_sec': 5.81, 'avg_step_time_sec': 6.49, 'time_to_completion_sec': 934.97, 'estimated_total_time_sec': 1188.19, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13035.27, 'avg_tokens_per_second': 12791.25}\n",
    "{'loss': 1.1506, 'grad_norm': 2.472780704498291, 'learning_rate': 5.760515577490025e-06, 'epoch': 0.22, 'num_input_tokens_seen': 3329024, 'step': 40, 'step_time_sec': 8.23, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 934.86, 'estimated_total_time_sec': 1196.36, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12064.36, 'avg_tokens_per_second': 12767.78}\n",
    "{'loss': 1.231, 'grad_norm': 2.819692611694336, 'learning_rate': 5.737510849429649e-06, 'epoch': 0.22, 'num_input_tokens_seen': 3411968, 'step': 41, 'step_time_sec': 7.32, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 931.1, 'estimated_total_time_sec': 1199.93, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11333.5, 'avg_tokens_per_second': 12727.76}\n",
    "{'loss': 1.1303, 'grad_norm': 2.573542594909668, 'learning_rate': 5.713501610552225e-06, 'epoch': 0.23, 'num_input_tokens_seen': 3497984, 'step': 42, 'step_time_sec': 6.81, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 925.41, 'estimated_total_time_sec': 1201.07, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12627.46, 'avg_tokens_per_second': 12725.22}\n",
    "{'loss': 1.2547, 'grad_norm': 2.732426166534424, 'learning_rate': 5.688496670883167e-06, 'epoch': 0.23, 'num_input_tokens_seen': 3576832, 'step': 43, 'step_time_sec': 6.04, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 917.09, 'estimated_total_time_sec': 1198.77, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13064.46, 'avg_tokens_per_second': 12732.66}\n",
    "{'loss': 1.1456, 'grad_norm': 2.6420061588287354, 'learning_rate': 5.662505205813464e-06, 'epoch': 0.24, 'num_input_tokens_seen': 3678208, 'step': 44, 'step_time_sec': 8.66, 'avg_step_time_sec': 6.6, 'time_to_completion_sec': 917.35, 'estimated_total_time_sec': 1207.73, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11712.19, 'avg_tokens_per_second': 12701.53}\n",
    "{'loss': 1.1715, 'grad_norm': 2.4896328449249268, 'learning_rate': 5.6355367527328275e-06, 'epoch': 0.25, 'num_input_tokens_seen': 3786752, 'step': 45, 'step_time_sec': 8.26, 'avg_step_time_sec': 6.64, 'time_to_completion_sec': 915.94, 'estimated_total_time_sec': 1214.61, 'step_peak_memory_allocated_MB': 38307.98, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13148.38, 'avg_tokens_per_second': 12714.16}\n",
    "{'loss': 1.1423, 'grad_norm': 2.729017734527588, 'learning_rate': 5.607601207530016e-06, 'epoch': 0.25, 'num_input_tokens_seen': 3846144, 'step': 46, 'step_time_sec': 4.48, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 902.73, 'estimated_total_time_sec': 1205.84, 'step_peak_memory_allocated_MB': 38307.84, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13259.78, 'avg_tokens_per_second': 12722.41}\n",
    "{'loss': 1.124, 'grad_norm': 2.7622640132904053, 'learning_rate': 5.578708820961603e-06, 'epoch': 0.26, 'num_input_tokens_seen': 3921920, 'step': 47, 'step_time_sec': 6.81, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 896.79, 'estimated_total_time_sec': 1206.71, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11130.82, 'avg_tokens_per_second': 12686.69}\n",
    "{'loss': 1.2133, 'grad_norm': 2.7125561237335205, 'learning_rate': 5.548870194890537e-06, 'epoch': 0.26, 'num_input_tokens_seen': 3999744, 'step': 48, 'step_time_sec': 6.03, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 888.58, 'estimated_total_time_sec': 1204.51, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12904.22, 'avg_tokens_per_second': 12690.93}\n",
    "{'loss': 1.1556, 'grad_norm': 2.649566411972046, 'learning_rate': 5.518096278395851e-06, 'epoch': 0.27, 'num_input_tokens_seen': 4064256, 'step': 49, 'step_time_sec': 5.2, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 878.13, 'estimated_total_time_sec': 1199.23, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12413.52, 'avg_tokens_per_second': 12686.34}\n",
    "{'loss': 1.1575, 'grad_norm': 2.6224870681762695, 'learning_rate': 5.486398363754984e-06, 'epoch': 0.27, 'num_input_tokens_seen': 4140032, 'step': 50, 'step_time_sec': 5.21, 'avg_step_time_sec': 6.53, 'time_to_completion_sec': 867.92, 'estimated_total_time_sec': 1194.21, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14549.43, 'avg_tokens_per_second': 12716.69}\n",
    "{'loss': 1.1683, 'grad_norm': 2.5452866554260254, 'learning_rate': 5.453788082300154e-06, 'epoch': 0.28, 'num_input_tokens_seen': 4224000, 'step': 51, 'step_time_sec': 6.82, 'avg_step_time_sec': 6.53, 'time_to_completion_sec': 862.19, 'estimated_total_time_sec': 1195.3, 'step_peak_memory_allocated_MB': 38629.85, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12304.64, 'avg_tokens_per_second': 12708.08}\n",
    "{'loss': 1.2843, 'grad_norm': 2.5905120372772217, 'learning_rate': 5.420277400150314e-06, 'epoch': 0.28, 'num_input_tokens_seen': 4314112, 'step': 52, 'step_time_sec': 7.26, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 857.53, 'estimated_total_time_sec': 1197.93, 'step_peak_memory_allocated_MB': 38307.98, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12406.14, 'avg_tokens_per_second': 12701.51}\n",
    "{'loss': 1.2525, 'grad_norm': 2.5538370609283447, 'learning_rate': 5.38587861382028e-06, 'epoch': 0.29, 'num_input_tokens_seen': 4399104, 'step': 53, 'step_time_sec': 6.91, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 851.89, 'estimated_total_time_sec': 1199.2, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12306.36, 'avg_tokens_per_second': 12693.5}\n",
    "{'loss': 1.1214, 'grad_norm': 2.652890205383301, 'learning_rate': 5.350604345708593e-06, 'epoch': 0.3, 'num_input_tokens_seen': 4462592, 'step': 54, 'step_time_sec': 5.04, 'avg_step_time_sec': 6.52, 'time_to_completion_sec': 841.66, 'estimated_total_time_sec': 1193.98, 'step_peak_memory_allocated_MB': 38307.98, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12587.91, 'avg_tokens_per_second': 12691.96}\n",
    "{'loss': 1.1352, 'grad_norm': 2.6701152324676514, 'learning_rate': 5.314467539465829e-06, 'epoch': 0.3, 'num_input_tokens_seen': 4536320, 'step': 55, 'step_time_sec': 5.69, 'avg_step_time_sec': 6.51, 'time_to_completion_sec': 833.15, 'estimated_total_time_sec': 1191.14, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12967.82, 'avg_tokens_per_second': 12696.42}\n",
    "{'loss': 1.1285, 'grad_norm': 2.781999349594116, 'learning_rate': 5.277481455245011e-06, 'epoch': 0.31, 'num_input_tokens_seen': 4609024, 'step': 56, 'step_time_sec': 5.17, 'avg_step_time_sec': 6.48, 'time_to_completion_sec': 823.55, 'estimated_total_time_sec': 1186.7, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14054.73, 'avg_tokens_per_second': 12716.12}\n",
    "{'loss': 1.1528, 'grad_norm': 2.5106871128082275, 'learning_rate': 5.239659664835888e-06, 'epoch': 0.31, 'num_input_tokens_seen': 4676608, 'step': 57, 'step_time_sec': 4.95, 'avg_step_time_sec': 6.46, 'time_to_completion_sec': 813.61, 'estimated_total_time_sec': 1181.67, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13664.62, 'avg_tokens_per_second': 12729.1}\n",
    "{'loss': 1.1513, 'grad_norm': 2.6652567386627197, 'learning_rate': 5.201016046684856e-06, 'epoch': 0.32, 'num_input_tokens_seen': 4752384, 'step': 58, 'step_time_sec': 6.88, 'avg_step_time_sec': 6.46, 'time_to_completion_sec': 808.08, 'estimated_total_time_sec': 1183.03, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11009.78, 'avg_tokens_per_second': 12696.98}\n",
    "{'loss': 1.1608, 'grad_norm': 2.848008394241333, 'learning_rate': 5.161564780802361e-06, 'epoch': 0.32, 'num_input_tokens_seen': 4832256, 'step': 59, 'step_time_sec': 7.79, 'avg_step_time_sec': 6.49, 'time_to_completion_sec': 804.45, 'estimated_total_time_sec': 1187.21, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10255.79, 'avg_tokens_per_second': 12646.46}\n",
    "{'loss': 1.2177, 'grad_norm': 2.7881691455841064, 'learning_rate': 5.1213203435596425e-06, 'epoch': 0.33, 'num_input_tokens_seen': 4907008, 'step': 60, 'step_time_sec': 5.66, 'avg_step_time_sec': 6.47, 'time_to_completion_sec': 796.24, 'estimated_total_time_sec': 1184.65, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13202.08, 'avg_tokens_per_second': 12654.69}\n",
    "{'loss': 1.1885, 'grad_norm': 2.77225661277771, 'learning_rate': 5.0802975023767254e-06, 'epoch': 0.33, 'num_input_tokens_seen': 4974592, 'step': 61, 'step_time_sec': 4.82, 'avg_step_time_sec': 6.45, 'time_to_completion_sec': 786.39, 'estimated_total_time_sec': 1179.59, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14035.44, 'avg_tokens_per_second': 12671.88}\n",
    "{'loss': 1.2245, 'grad_norm': 2.428131580352783, 'learning_rate': 5.038511310303617e-06, 'epoch': 0.34, 'num_input_tokens_seen': 5081088, 'step': 62, 'step_time_sec': 8.37, 'avg_step_time_sec': 6.48, 'time_to_completion_sec': 783.77, 'estimated_total_time_sec': 1185.38, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12716.85, 'avg_tokens_per_second': 12672.84}\n",
    "{'loss': 1.1688, 'grad_norm': 2.4794726371765137, 'learning_rate': 4.9959771004966955e-06, 'epoch': 0.34, 'num_input_tokens_seen': 5155840, 'step': 63, 'step_time_sec': 5.42, 'avg_step_time_sec': 6.46, 'time_to_completion_sec': 775.26, 'estimated_total_time_sec': 1182.27, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13779.47, 'avg_tokens_per_second': 12687.82}\n",
    "{'loss': 1.1114, 'grad_norm': 2.53656268119812, 'learning_rate': 4.952710480592314e-06, 'epoch': 0.35, 'num_input_tokens_seen': 5237760, 'step': 64, 'step_time_sec': 6.74, 'avg_step_time_sec': 6.46, 'time_to_completion_sec': 769.32, 'estimated_total_time_sec': 1183.08, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12158.07, 'avg_tokens_per_second': 12679.06}\n",
    "{'loss': 1.2041, 'grad_norm': 2.531165599822998, 'learning_rate': 4.9087273269796795e-06, 'epoch': 0.36, 'num_input_tokens_seen': 5309440, 'step': 65, 'step_time_sec': 5.29, 'avg_step_time_sec': 6.45, 'time_to_completion_sec': 760.68, 'estimated_total_time_sec': 1179.71, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13558.84, 'avg_tokens_per_second': 12690.33}\n",
    "{'loss': 1.1135, 'grad_norm': 2.458299398422241, 'learning_rate': 4.8640437789751294e-06, 'epoch': 0.36, 'num_input_tokens_seen': 5389312, 'step': 66, 'step_time_sec': 5.72, 'avg_step_time_sec': 6.44, 'time_to_completion_sec': 752.94, 'estimated_total_time_sec': 1177.67, 'step_peak_memory_allocated_MB': 38307.98, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13952.18, 'avg_tokens_per_second': 12707.6}\n",
    "{'loss': 1.1171, 'grad_norm': 2.6074368953704834, 'learning_rate': 4.818676232899914e-06, 'epoch': 0.37, 'num_input_tokens_seen': 5480448, 'step': 67, 'step_time_sec': 6.89, 'avg_step_time_sec': 6.44, 'time_to_completion_sec': 747.31, 'estimated_total_time_sec': 1178.94, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13224.17, 'avg_tokens_per_second': 12715.98}\n",
    "{'loss': 1.1305, 'grad_norm': 2.4341163635253906, 'learning_rate': 4.772641336063682e-06, 'epoch': 0.37, 'num_input_tokens_seen': 5582848, 'step': 68, 'step_time_sec': 8.37, 'avg_step_time_sec': 6.47, 'time_to_completion_sec': 744.17, 'estimated_total_time_sec': 1184.2, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12237.8, 'avg_tokens_per_second': 12706.75}\n",
    "{'loss': 1.1436, 'grad_norm': 2.4234328269958496, 'learning_rate': 4.725955980655862e-06, 'epoch': 0.38, 'num_input_tokens_seen': 5681152, 'step': 69, 'step_time_sec': 7.55, 'avg_step_time_sec': 6.49, 'time_to_completion_sec': 739.51, 'estimated_total_time_sec': 1187.1, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13018.04, 'avg_tokens_per_second': 12712.08}\n",
    "{'loss': 1.1842, 'grad_norm': 2.7257091999053955, 'learning_rate': 4.678637297547192e-06, 'epoch': 0.38, 'num_input_tokens_seen': 5748736, 'step': 70, 'step_time_sec': 5.94, 'avg_step_time_sec': 6.48, 'time_to_completion_sec': 732.12, 'estimated_total_time_sec': 1185.65, 'step_peak_memory_allocated_MB': 38307.84, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11382.35, 'avg_tokens_per_second': 12694.41}\n",
    "{'loss': 1.1862, 'grad_norm': 2.6627514362335205, 'learning_rate': 4.630702650003664e-06, 'epoch': 0.39, 'num_input_tokens_seen': 5824512, 'step': 71, 'step_time_sec': 6.58, 'avg_step_time_sec': 6.48, 'time_to_completion_sec': 725.81, 'estimated_total_time_sec': 1185.92, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11510.55, 'avg_tokens_per_second': 12677.23}\n",
    "{'loss': 1.1188, 'grad_norm': 2.5618109703063965, 'learning_rate': 4.582169627315188e-06, 'epoch': 0.39, 'num_input_tokens_seen': 5913600, 'step': 72, 'step_time_sec': 8.24, 'avg_step_time_sec': 6.51, 'time_to_completion_sec': 722.08, 'estimated_total_time_sec': 1190.45, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10813.48, 'avg_tokens_per_second': 12643.99}\n",
    "{'loss': 1.1753, 'grad_norm': 2.44663667678833, 'learning_rate': 4.533056038341331e-06, 'epoch': 0.4, 'num_input_tokens_seen': 5991424, 'step': 73, 'step_time_sec': 5.69, 'avg_step_time_sec': 6.49, 'time_to_completion_sec': 714.33, 'estimated_total_time_sec': 1188.38, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13677.61, 'avg_tokens_per_second': 12656.57}\n",
    "{'loss': 1.0808, 'grad_norm': 2.558300495147705, 'learning_rate': 4.483379904976471e-06, 'epoch': 0.4, 'num_input_tokens_seen': 6084608, 'step': 74, 'step_time_sec': 8.25, 'avg_step_time_sec': 6.52, 'time_to_completion_sec': 710.46, 'estimated_total_time_sec': 1192.79, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11293.36, 'avg_tokens_per_second': 12632.93}\n",
    "{'loss': 1.1228, 'grad_norm': 2.667332887649536, 'learning_rate': 4.433159455536789e-06, 'epoch': 0.41, 'num_input_tokens_seen': 6175744, 'step': 75, 'step_time_sec': 7.61, 'avg_step_time_sec': 6.53, 'time_to_completion_sec': 705.54, 'estimated_total_time_sec': 1195.5, 'step_peak_memory_allocated_MB': 39675.71, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11969.71, 'avg_tokens_per_second': 12622.48}\n",
    "{'loss': 1.141, 'grad_norm': 2.3996784687042236, 'learning_rate': 4.382413118071515e-06, 'epoch': 0.42, 'num_input_tokens_seen': 6288384, 'step': 76, 'step_time_sec': 8.37, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 701.63, 'estimated_total_time_sec': 1199.99, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13450.54, 'avg_tokens_per_second': 12636.58}\n",
    "{'loss': 1.12, 'grad_norm': 2.7005488872528076, 'learning_rate': 4.331159513600879e-06, 'epoch': 0.42, 'num_input_tokens_seen': 6359040, 'step': 77, 'step_time_sec': 5.19, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 693.17, 'estimated_total_time_sec': 1196.7, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13613.72, 'avg_tokens_per_second': 12646.79}\n",
    "{'loss': 1.1277, 'grad_norm': 2.7184033393859863, 'learning_rate': 4.27941744928326e-06, 'epoch': 0.43, 'num_input_tokens_seen': 6427648, 'step': 78, 'step_time_sec': 5.89, 'avg_step_time_sec': 6.53, 'time_to_completion_sec': 685.74, 'estimated_total_time_sec': 1195.15, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11653.13, 'avg_tokens_per_second': 12635.15}\n",
    "{'loss': 1.1059, 'grad_norm': 2.5520217418670654, 'learning_rate': 4.22720591151402e-06, 'epoch': 0.43, 'num_input_tokens_seen': 6520832, 'step': 79, 'step_time_sec': 8.38, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 681.67, 'estimated_total_time_sec': 1199.48, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11122.32, 'avg_tokens_per_second': 12610.36}\n",
    "{'loss': 1.1318, 'grad_norm': 2.5840554237365723, 'learning_rate': 4.174544058958587e-06, 'epoch': 0.44, 'num_input_tokens_seen': 6603776, 'step': 80, 'step_time_sec': 6.89, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 675.55, 'estimated_total_time_sec': 1200.26, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12040.17, 'avg_tokens_per_second': 12602.78}\n",
    "{'loss': 1.1695, 'grad_norm': 2.741536855697632, 'learning_rate': 4.121451215522306e-06, 'epoch': 0.44, 'num_input_tokens_seen': 6668288, 'step': 81, 'step_time_sec': 4.51, 'avg_step_time_sec': 6.53, 'time_to_completion_sec': 666.38, 'estimated_total_time_sec': 1195.56, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14313.2, 'avg_tokens_per_second': 12617.53}\n",
    "{'loss': 1.1154, 'grad_norm': 2.63997220993042, 'learning_rate': 4.06794686325967e-06, 'epoch': 0.45, 'num_input_tokens_seen': 6754304, 'step': 82, 'step_time_sec': 7.77, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 661.38, 'estimated_total_time_sec': 1198.35, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11076.89, 'avg_tokens_per_second': 12594.98}\n",
    "{'loss': 1.1844, 'grad_norm': 2.3627078533172607, 'learning_rate': 4.014050635225508e-06, 'epoch': 0.45, 'num_input_tokens_seen': 6862848, 'step': 83, 'step_time_sec': 8.36, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 657.05, 'estimated_total_time_sec': 1202.39, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12981.11, 'avg_tokens_per_second': 12600.97}\n",
    "{'loss': 1.1052, 'grad_norm': 2.4519941806793213, 'learning_rate': 3.9597823082707765e-06, 'epoch': 0.46, 'num_input_tokens_seen': 6939648, 'step': 84, 'step_time_sec': 6.58, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 650.48, 'estimated_total_time_sec': 1202.41, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11674.71, 'avg_tokens_per_second': 12589.8}\n",
    "{'loss': 1.0939, 'grad_norm': 2.5853402614593506, 'learning_rate': 3.905161795785577e-06, 'epoch': 0.46, 'num_input_tokens_seen': 7016448, 'step': 85, 'step_time_sec': 6.66, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 644.02, 'estimated_total_time_sec': 1202.6, 'step_peak_memory_allocated_MB': 38629.85, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11534.53, 'avg_tokens_per_second': 12577.07}\n",
    "{'loss': 1.169, 'grad_norm': 2.578096866607666, 'learning_rate': 3.850209140392072e-06, 'epoch': 0.47, 'num_input_tokens_seen': 7087104, 'step': 86, 'step_time_sec': 5.28, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 635.97, 'estimated_total_time_sec': 1199.82, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13381.28, 'avg_tokens_per_second': 12584.69}\n",
    "{'loss': 1.1836, 'grad_norm': 2.5823841094970703, 'learning_rate': 3.7949445065899857e-06, 'epoch': 0.48, 'num_input_tokens_seen': 7172096, 'step': 87, 'step_time_sec': 6.05, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 628.86, 'estimated_total_time_sec': 1198.76, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14036.82, 'avg_tokens_per_second': 12600.29}\n",
    "{'loss': 1.1734, 'grad_norm': 2.5420873165130615, 'learning_rate': 3.739388173357378e-06, 'epoch': 0.48, 'num_input_tokens_seen': 7248896, 'step': 88, 'step_time_sec': 7.57, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 623.42, 'estimated_total_time_sec': 1200.89, 'step_peak_memory_allocated_MB': 38307.82, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10148.38, 'avg_tokens_per_second': 12567.79}\n",
    "{'loss': 1.0736, 'grad_norm': 2.4663279056549072, 'learning_rate': 3.6835605267094133e-06, 'epoch': 0.49, 'num_input_tokens_seen': 7323648, 'step': 89, 'step_time_sec': 6.87, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 617.18, 'estimated_total_time_sec': 1201.53, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10887.86, 'avg_tokens_per_second': 12547.83}\n",
    "{'loss': 1.1564, 'grad_norm': 2.658759355545044, 'learning_rate': 3.6274820522178506e-06, 'epoch': 0.49, 'num_input_tokens_seen': 7400448, 'step': 90, 'step_time_sec': 5.71, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 609.72, 'estimated_total_time_sec': 1199.77, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13448.87, 'avg_tokens_per_second': 12556.65}\n",
    "{'loss': 1.1336, 'grad_norm': 2.375141143798828, 'learning_rate': 3.5711733274940054e-06, 'epoch': 0.5, 'num_input_tokens_seen': 7472128, 'step': 91, 'step_time_sec': 5.43, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 602.01, 'estimated_total_time_sec': 1197.48, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13201.32, 'avg_tokens_per_second': 12562.59}\n",
    "{'loss': 1.1605, 'grad_norm': 2.378243923187256, 'learning_rate': 3.5146550146379353e-06, 'epoch': 0.5, 'num_input_tokens_seen': 7558144, 'step': 92, 'step_time_sec': 7.11, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 596.03, 'estimated_total_time_sec': 1198.61, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12105.63, 'avg_tokens_per_second': 12557.15}\n",
    "{'loss': 1.0543, 'grad_norm': 2.6844048500061035, 'learning_rate': 3.4579478526566237e-06, 'epoch': 0.51, 'num_input_tokens_seen': 7643136, 'step': 93, 'step_time_sec': 6.25, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 589.18, 'estimated_total_time_sec': 1198.0, 'step_peak_memory_allocated_MB': 38436.28, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13606.35, 'avg_tokens_per_second': 12568.03}\n",
    "{'loss': 1.0862, 'grad_norm': 2.3707942962646484, 'learning_rate': 3.4010726498539453e-06, 'epoch': 0.51, 'num_input_tokens_seen': 7749632, 'step': 94, 'step_time_sec': 8.26, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 584.27, 'estimated_total_time_sec': 1201.37, 'step_peak_memory_allocated_MB': 40100.53, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12895.88, 'avg_tokens_per_second': 12572.46}\n",
    "{'loss': 1.1057, 'grad_norm': 2.468660354614258, 'learning_rate': 3.344050276195202e-06, 'epoch': 0.52, 'num_input_tokens_seen': 7815168, 'step': 95, 'step_time_sec': 4.98, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 576.22, 'estimated_total_time_sec': 1198.28, 'step_peak_memory_allocated_MB': 38307.84, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13170.61, 'avg_tokens_per_second': 12577.3}\n",
    "{'loss': 1.1001, 'grad_norm': 2.540684461593628, 'learning_rate': 3.286901655649027e-06, 'epoch': 0.52, 'num_input_tokens_seen': 7877632, 'step': 96, 'step_time_sec': 4.83, 'avg_step_time_sec': 6.53, 'time_to_completion_sec': 568.1, 'estimated_total_time_sec': 1194.96, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12943.44, 'avg_tokens_per_second': 12580.15}\n",
    "{'loss': 1.0612, 'grad_norm': 2.438426971435547, 'learning_rate': 3.229647758509488e-06, 'epoch': 0.53, 'num_input_tokens_seen': 7970816, 'step': 97, 'step_time_sec': 7.91, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 562.8, 'estimated_total_time_sec': 1197.59, 'step_peak_memory_allocated_MB': 40526.41, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11780.58, 'avg_tokens_per_second': 12570.08}\n",
    "{'loss': 1.1338, 'grad_norm': 2.5424418449401855, 'learning_rate': 3.1723095937011706e-06, 'epoch': 0.54, 'num_input_tokens_seen': 8062976, 'step': 98, 'step_time_sec': 7.41, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 557.02, 'estimated_total_time_sec': 1199.22, 'step_peak_memory_allocated_MB': 39675.71, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12440.8, 'avg_tokens_per_second': 12568.57}\n",
    "{'loss': 1.1244, 'grad_norm': 2.5095560550689697, 'learning_rate': 3.1149082010701064e-06, 'epoch': 0.54, 'num_input_tokens_seen': 8145920, 'step': 99, 'step_time_sec': 7.02, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 550.87, 'estimated_total_time_sec': 1200.1, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11807.49, 'avg_tokens_per_second': 12560.25}\n",
    "{'loss': 1.0911, 'grad_norm': 2.5134990215301514, 'learning_rate': 3.0574646436633425e-06, 'epoch': 0.55, 'num_input_tokens_seen': 8232960, 'step': 100, 'step_time_sec': 6.78, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 544.5, 'estimated_total_time_sec': 1200.52, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12829.13, 'avg_tokens_per_second': 12563.06}\n",
    "{'loss': 1.1368, 'grad_norm': 2.4135184288024902, 'learning_rate': 3e-06, 'epoch': 0.55, 'num_input_tokens_seen': 8314880, 'step': 101, 'step_time_sec': 7.26, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 538.51, 'estimated_total_time_sec': 1201.8, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11285.1, 'avg_tokens_per_second': 12548.94}\n",
    "{'loss': 1.2112, 'grad_norm': 2.576052665710449, 'learning_rate': 2.9425353563366576e-06, 'epoch': 0.56, 'num_input_tokens_seen': 8395776, 'step': 102, 'step_time_sec': 7.03, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 532.31, 'estimated_total_time_sec': 1202.63, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11513.13, 'avg_tokens_per_second': 12537.97}\n",
    "{'loss': 1.05, 'grad_norm': 2.3906030654907227, 'learning_rate': 2.885091798929894e-06, 'epoch': 0.56, 'num_input_tokens_seen': 8479744, 'step': 103, 'step_time_sec': 7.43, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 526.41, 'estimated_total_time_sec': 1204.17, 'step_peak_memory_allocated_MB': 39675.71, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11300.5, 'avg_tokens_per_second': 12524.27}\n",
    "{'loss': 1.1087, 'grad_norm': 2.34201717376709, 'learning_rate': 2.8276904062988304e-06, 'epoch': 0.57, 'num_input_tokens_seen': 8593408, 'step': 104, 'step_time_sec': 8.38, 'avg_step_time_sec': 6.6, 'time_to_completion_sec': 521.21, 'estimated_total_time_sec': 1207.36, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13571.11, 'avg_tokens_per_second': 12537.17}\n",
    "{'loss': 1.0942, 'grad_norm': 2.607990026473999, 'learning_rate': 2.770352241490513e-06, 'epoch': 0.57, 'num_input_tokens_seen': 8674304, 'step': 105, 'step_time_sec': 7.25, 'avg_step_time_sec': 6.6, 'time_to_completion_sec': 515.1, 'estimated_total_time_sec': 1208.51, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11159.33, 'avg_tokens_per_second': 12522.63}\n",
    "{'loss': 1.1046, 'grad_norm': 2.4252984523773193, 'learning_rate': 2.7130983443509734e-06, 'epoch': 0.58, 'num_input_tokens_seen': 8766464, 'step': 106, 'step_time_sec': 7.31, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 509.02, 'estimated_total_time_sec': 1209.75, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12599.5, 'avg_tokens_per_second': 12523.44}\n",
    "{'loss': 1.1165, 'grad_norm': 2.59588623046875, 'learning_rate': 2.655949723804799e-06, 'epoch': 0.58, 'num_input_tokens_seen': 8850432, 'step': 107, 'step_time_sec': 7.02, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 502.7, 'estimated_total_time_sec': 1210.46, 'step_peak_memory_allocated_MB': 38436.28, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11959.06, 'avg_tokens_per_second': 12517.79}\n",
    "{'loss': 1.102, 'grad_norm': 2.5791361331939697, 'learning_rate': 2.5989273501460544e-06, 'epoch': 0.59, 'num_input_tokens_seen': 8924160, 'step': 108, 'step_time_sec': 5.72, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 495.46, 'estimated_total_time_sec': 1208.93, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12884.96, 'avg_tokens_per_second': 12520.76}\n",
    "{'loss': 1.1161, 'grad_norm': 2.4544708728790283, 'learning_rate': 2.5420521473433765e-06, 'epoch': 0.6, 'num_input_tokens_seen': 9015296, 'step': 109, 'step_time_sec': 7.15, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 489.23, 'estimated_total_time_sec': 1209.85, 'step_peak_memory_allocated_MB': 39248.95, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12749.69, 'avg_tokens_per_second': 12523.05}\n",
    " 60%|██████████████████████████████████████████████████████████████████████████████                                                     | 109/183 [12:17<08:40,  7.04s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/trl/trainer/utils.py:155: UserWarning: Could not find response key `[14711, 6075, 512]` in the following instance: <|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Come up with an appropriate title for the following document.\n",
    "\n",
    "### Input:\n",
    "WASHINGTON (CNN) -- A wide-open presidential race and a willingness by candidates, interest groups, unions and corporations to buy TV time will lead to historic spending for political and issue-advocacy advertising in the 2008 election cycle, an analysis shows. Former Massachusetts Gov. Mitt Romney has spent the most on TV advertising so far among presidential contenders. The cost to try to influence the 2008 election could exceed $3 billion, according to TNS Media Intelligence/Campaign Media Analysis Group, CNN's consultant on political television advertising. This is nearly twice as much than what was spent in 2004 when political and issue-advocacy television advertising rang in at $1.7 billion. In 2006, $2.3 billion was spent on political and issue-advocacy TV commercials. Just about every candidate running for an office from dogcatcher to president is spending the money, said Evan Tracey, CMAG's chief operating officer. The costs to produce a TV commercial are no longer prohibitive for local and state candidates, who are turning more and more to the airwaves to reach voters. See how spending breaks down for this year ». And interest groups have spent $6.2 million on TV ads so far this year for state and local ballot measures. On the national level, the cost of issue-advocacy television ad spending was $270 million in the first nine months of this year. Subjects ranged from the Iraq war to telecommunications reform. Television ads on health care alone total $60 million. CMAG estimates more than $3 million of the $270 million spent to air issue-advocacy ads this year has gone for commercials in states and districts that are likely to have competitive House and Senate races in 2008. Tracey said he thinks this is just the beginning of interest groups \"pivoting from legislative advocacy mode to political mode.\" \"What we expect to see between now and the end of the primaries, and through the general election, is groups will take a more aggressive stance on their advertising and actually target candidates,\" he said. With 17 Democratic and Republican candidates running for president, CMAG predicts that more than $800 million will be spent on TV ads in the battle for the White House. Up to now, the political commercials have been largely This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
    "  warnings.warn(\n",
    "{'loss': 1.0567, 'grad_norm': 2.6201181411743164, 'learning_rate': 2.485344985362065e-06, 'epoch': 0.6, 'num_input_tokens_seen': 9095168, 'step': 110, 'step_time_sec': 6.51, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 482.55, 'estimated_total_time_sec': 1209.69, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12260.39, 'avg_tokens_per_second': 12520.68}\n",
    " 60%|██████████████████████████████████████████████████████████████████████████████▋                                                    | 110/183 [12:23<08:25,  6.92s/it]/home/ubuntu/.virtualenvs/batch-size-memory-testing/lib/python3.10/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
    "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
    "{'loss': 1.2061, 'grad_norm': 2.7824528217315674, 'learning_rate': 2.4288266725059947e-06, 'epoch': 0.61, 'num_input_tokens_seen': 9187328, 'step': 111, 'step_time_sec': 8.57, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 477.23, 'estimated_total_time_sec': 1212.95, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10747.71, 'avg_tokens_per_second': 12499.83}\n",
    "{'loss': 1.1292, 'grad_norm': 2.491321563720703, 'learning_rate': 2.372517947782151e-06, 'epoch': 0.61, 'num_input_tokens_seen': 9263104, 'step': 112, 'step_time_sec': 5.73, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 470.03, 'estimated_total_time_sec': 1211.48, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13217.75, 'avg_tokens_per_second': 12505.43}\n",
    "{'loss': 1.1393, 'grad_norm': 2.608376979827881, 'learning_rate': 2.316439473290588e-06, 'epoch': 0.62, 'num_input_tokens_seen': 9331712, 'step': 113, 'step_time_sec': 5.06, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 462.43, 'estimated_total_time_sec': 1208.94, 'step_peak_memory_allocated_MB': 38307.98, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13546.99, 'avg_tokens_per_second': 12512.56}\n",
    "{'loss': 1.0823, 'grad_norm': 2.5483405590057373, 'learning_rate': 2.260611826642623e-06, 'epoch': 0.62, 'num_input_tokens_seen': 9399296, 'step': 114, 'step_time_sec': 4.75, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 454.7, 'estimated_total_time_sec': 1205.94, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14215.51, 'avg_tokens_per_second': 12523.43}\n",
    "{'loss': 1.1527, 'grad_norm': 2.467620372772217, 'learning_rate': 2.2050554934100157e-06, 'epoch': 0.63, 'num_input_tokens_seen': 9477120, 'step': 115, 'step_time_sec': 5.87, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 447.68, 'estimated_total_time_sec': 1204.79, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13250.5, 'avg_tokens_per_second': 12529.12}\n",
    "{'loss': 1.0532, 'grad_norm': 2.778763771057129, 'learning_rate': 2.149790859607929e-06, 'epoch': 0.63, 'num_input_tokens_seen': 9560064, 'step': 116, 'step_time_sec': 6.88, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 441.27, 'estimated_total_time_sec': 1205.25, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12063.15, 'avg_tokens_per_second': 12524.89}\n",
    "{'loss': 1.0873, 'grad_norm': 2.469125747680664, 'learning_rate': 2.0948382042144234e-06, 'epoch': 0.64, 'num_input_tokens_seen': 9646080, 'step': 117, 'step_time_sec': 7.3, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 435.09, 'estimated_total_time_sec': 1206.38, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11784.05, 'avg_tokens_per_second': 12517.82}\n",
    "{'loss': 1.1066, 'grad_norm': 2.4681687355041504, 'learning_rate': 2.0402176917292237e-06, 'epoch': 0.64, 'num_input_tokens_seen': 9724928, 'step': 118, 'step_time_sec': 6.15, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 428.25, 'estimated_total_time_sec': 1205.69, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12816.61, 'avg_tokens_per_second': 12520.2}\n",
    "{'loss': 1.1306, 'grad_norm': 2.5295934677124023, 'learning_rate': 1.9859493647744925e-06, 'epoch': 0.65, 'num_input_tokens_seen': 9802752, 'step': 119, 'step_time_sec': 6.12, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 421.41, 'estimated_total_time_sec': 1204.96, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12712.69, 'avg_tokens_per_second': 12521.72}\n",
    "{'loss': 1.0632, 'grad_norm': 2.5487372875213623, 'learning_rate': 1.9320531367403304e-06, 'epoch': 0.66, 'num_input_tokens_seen': 9888768, 'step': 120, 'step_time_sec': 6.97, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 415.03, 'estimated_total_time_sec': 1205.56, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12336.98, 'avg_tokens_per_second': 12520.08}\n",
    "{'loss': 1.0879, 'grad_norm': 2.3866958618164062, 'learning_rate': 1.8785487844776938e-06, 'epoch': 0.66, 'num_input_tokens_seen': 9969664, 'step': 121, 'step_time_sec': 6.8, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 408.55, 'estimated_total_time_sec': 1205.88, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11896.31, 'avg_tokens_per_second': 12514.71}\n",
    "{'loss': 1.0863, 'grad_norm': 2.6043450832366943, 'learning_rate': 1.8254559410414134e-06, 'epoch': 0.67, 'num_input_tokens_seen': 10056704, 'step': 122, 'step_time_sec': 6.52, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 401.92, 'estimated_total_time_sec': 1205.77, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13356.3, 'avg_tokens_per_second': 12521.59}\n",
    "{'loss': 1.1638, 'grad_norm': 2.4173662662506104, 'learning_rate': 1.7727940884859804e-06, 'epoch': 0.67, 'num_input_tokens_seen': 10148864, 'step': 123, 'step_time_sec': 8.25, 'avg_step_time_sec': 6.6, 'time_to_completion_sec': 396.15, 'estimated_total_time_sec': 1208.27, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11165.97, 'avg_tokens_per_second': 12507.7}\n",
    "{'loss': 1.0671, 'grad_norm': 2.364880323410034, 'learning_rate': 1.7205825507167408e-06, 'epoch': 0.68, 'num_input_tokens_seen': 10237952, 'step': 124, 'step_time_sec': 7.03, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 389.76, 'estimated_total_time_sec': 1208.91, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12672.43, 'avg_tokens_per_second': 12509.13}\n",
    "{'loss': 1.1163, 'grad_norm': 2.760326385498047, 'learning_rate': 1.6688404863991208e-06, 'epoch': 0.68, 'num_input_tokens_seen': 10328064, 'step': 125, 'step_time_sec': 7.43, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 383.54, 'estimated_total_time_sec': 1210.12, 'step_peak_memory_allocated_MB': 39675.71, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12131.89, 'avg_tokens_per_second': 12505.71}\n",
    "{'loss': 1.0584, 'grad_norm': 2.5053317546844482, 'learning_rate': 1.6175868819284853e-06, 'epoch': 0.69, 'num_input_tokens_seen': 10404864, 'step': 126, 'step_time_sec': 5.56, 'avg_step_time_sec': 6.6, 'time_to_completion_sec': 376.44, 'estimated_total_time_sec': 1208.58, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13814.93, 'avg_tokens_per_second': 12514.52}\n",
    "{'loss': 1.0221, 'grad_norm': 2.603980779647827, 'learning_rate': 1.5668405444632109e-06, 'epoch': 0.69, 'num_input_tokens_seen': 10493952, 'step': 127, 'step_time_sec': 6.07, 'avg_step_time_sec': 6.6, 'time_to_completion_sec': 369.6, 'estimated_total_time_sec': 1207.8, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14678.95, 'avg_tokens_per_second': 12530.32}\n",
    "{'loss': 1.0533, 'grad_norm': 2.417914628982544, 'learning_rate': 1.5166200950235286e-06, 'epoch': 0.7, 'num_input_tokens_seen': 10598400, 'step': 128, 'step_time_sec': 7.56, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 363.41, 'estimated_total_time_sec': 1209.18, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13823.89, 'avg_tokens_per_second': 12541.97}\n",
    "{'loss': 1.0979, 'grad_norm': 2.49830961227417, 'learning_rate': 1.4669439616586685e-06, 'epoch': 0.7, 'num_input_tokens_seen': 10695680, 'step': 129, 'step_time_sec': 8.34, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 357.54, 'estimated_total_time_sec': 1211.66, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11660.33, 'avg_tokens_per_second': 12533.29}\n",
    "{'loss': 1.041, 'grad_norm': 2.348635673522949, 'learning_rate': 1.4178303726848122e-06, 'epoch': 0.71, 'num_input_tokens_seen': 10779648, 'step': 130, 'step_time_sec': 6.21, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 350.75, 'estimated_total_time_sec': 1211.07, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13528.62, 'avg_tokens_per_second': 12540.53}\n",
    "{'loss': 1.0287, 'grad_norm': 2.4323790073394775, 'learning_rate': 1.3692973499963369e-06, 'epoch': 0.72, 'num_input_tokens_seen': 10868736, 'step': 131, 'step_time_sec': 6.15, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 343.94, 'estimated_total_time_sec': 1210.41, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14493.39, 'avg_tokens_per_second': 12554.49}\n",
    "{'loss': 1.0685, 'grad_norm': 2.370760202407837, 'learning_rate': 1.321362702452808e-06, 'epoch': 0.72, 'num_input_tokens_seen': 10950656, 'step': 132, 'step_time_sec': 8.24, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 337.96, 'estimated_total_time_sec': 1212.69, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 9936.22, 'avg_tokens_per_second': 12529.62}\n",
    "{'loss': 1.0702, 'grad_norm': 2.601104974746704, 'learning_rate': 1.2740440193441384e-06, 'epoch': 0.73, 'num_input_tokens_seen': 11023360, 'step': 133, 'step_time_sec': 5.9, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 331.06, 'estimated_total_time_sec': 1211.68, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12314.73, 'avg_tokens_per_second': 12528.17}\n",
    "{'loss': 1.136, 'grad_norm': 2.4361798763275146, 'learning_rate': 1.2273586639363195e-06, 'epoch': 0.73, 'num_input_tokens_seen': 11137024, 'step': 134, 'step_time_sec': 8.27, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 325.05, 'estimated_total_time_sec': 1213.95, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13744.68, 'avg_tokens_per_second': 12539.57}\n",
    "{'loss': 1.0075, 'grad_norm': 2.7673609256744385, 'learning_rate': 1.1813237671000868e-06, 'epoch': 0.74, 'num_input_tokens_seen': 11208704, 'step': 135, 'step_time_sec': 5.68, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 318.07, 'estimated_total_time_sec': 1212.65, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12611.45, 'avg_tokens_per_second': 12540.03}\n",
    "{'loss': 1.032, 'grad_norm': 2.469632625579834, 'learning_rate': 1.1359562210248713e-06, 'epoch': 0.74, 'num_input_tokens_seen': 11286528, 'step': 136, 'step_time_sec': 5.83, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 311.17, 'estimated_total_time_sec': 1211.57, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13355.8, 'avg_tokens_per_second': 12545.35}\n",
    "{'loss': 1.1472, 'grad_norm': 2.507446527481079, 'learning_rate': 1.0912726730203213e-06, 'epoch': 0.75, 'num_input_tokens_seen': 11370496, 'step': 137, 'step_time_sec': 6.58, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 304.53, 'estimated_total_time_sec': 1211.52, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12760.98, 'avg_tokens_per_second': 12546.92}\n",
    "{'loss': 1.0155, 'grad_norm': 2.5884740352630615, 'learning_rate': 1.0472895194076868e-06, 'epoch': 0.75, 'num_input_tokens_seen': 11442176, 'step': 138, 'step_time_sec': 4.99, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 297.38, 'estimated_total_time_sec': 1209.34, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14369.81, 'avg_tokens_per_second': 12556.97}\n",
    "{'loss': 1.1064, 'grad_norm': 2.613290548324585, 'learning_rate': 1.0040228995033042e-06, 'epoch': 0.76, 'num_input_tokens_seen': 11527168, 'step': 139, 'step_time_sec': 8.17, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 291.27, 'estimated_total_time_sec': 1211.4, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10406.3, 'avg_tokens_per_second': 12537.74}\n",
    "{'loss': 1.0715, 'grad_norm': 2.467012643814087, 'learning_rate': 9.614886896963835e-07, 'epoch': 0.77, 'num_input_tokens_seen': 11604992, 'step': 140, 'step_time_sec': 6.07, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 284.48, 'estimated_total_time_sec': 1210.69, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12811.4, 'avg_tokens_per_second': 12539.55}\n",
    "{'loss': 1.0759, 'grad_norm': 2.3385117053985596, 'learning_rate': 9.197024976232752e-07, 'epoch': 0.77, 'num_input_tokens_seen': 11701248, 'step': 141, 'step_time_sec': 8.25, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 278.35, 'estimated_total_time_sec': 1212.82, 'step_peak_memory_allocated_MB': 39248.95, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11670.49, 'avg_tokens_per_second': 12531.82}\n",
    "{'loss': 1.0554, 'grad_norm': 2.4481923580169678, 'learning_rate': 8.786796564403577e-07, 'epoch': 0.78, 'num_input_tokens_seen': 11786240, 'step': 142, 'step_time_sec': 6.58, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 271.71, 'estimated_total_time_sec': 1212.76, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12919.67, 'avg_tokens_per_second': 12534.55}\n",
    "{'loss': 1.0658, 'grad_norm': 2.5201611518859863, 'learning_rate': 8.384352191976392e-07, 'epoch': 0.78, 'num_input_tokens_seen': 11863040, 'step': 143, 'step_time_sec': 6.78, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 265.13, 'estimated_total_time_sec': 1212.95, 'step_peak_memory_allocated_MB': 38307.8, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11324.22, 'avg_tokens_per_second': 12525.83}\n",
    "{'loss': 1.0606, 'grad_norm': 2.6058623790740967, 'learning_rate': 7.989839533151444e-07, 'epoch': 0.79, 'num_input_tokens_seen': 11942912, 'step': 144, 'step_time_sec': 6.88, 'avg_step_time_sec': 6.63, 'time_to_completion_sec': 258.57, 'estimated_total_time_sec': 1213.28, 'step_peak_memory_allocated_MB': 38823.48, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11610.27, 'avg_tokens_per_second': 12519.19}\n",
    "{'loss': 1.0347, 'grad_norm': 2.503452777862549, 'learning_rate': 7.603403351641119e-07, 'epoch': 0.79, 'num_input_tokens_seen': 12016640, 'step': 145, 'step_time_sec': 5.72, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 251.7, 'estimated_total_time_sec': 1212.12, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12886.44, 'avg_tokens_per_second': 12521.39}\n",
    "{'loss': 1.0733, 'grad_norm': 2.389481782913208, 'learning_rate': 7.225185447549883e-07, 'epoch': 0.8, 'num_input_tokens_seen': 12093440, 'step': 146, 'step_time_sec': 5.56, 'avg_step_time_sec': 6.62, 'time_to_completion_sec': 244.8, 'estimated_total_time_sec': 1210.78, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13803.41, 'avg_tokens_per_second': 12528.83}\n",
    "{'loss': 1.1022, 'grad_norm': 2.6675384044647217, 'learning_rate': 6.855324605341711e-07, 'epoch': 0.8, 'num_input_tokens_seen': 12161024, 'step': 147, 'step_time_sec': 5.01, 'avg_step_time_sec': 6.61, 'time_to_completion_sec': 237.79, 'estimated_total_time_sec': 1208.77, 'step_peak_memory_allocated_MB': 38307.84, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13501.07, 'avg_tokens_per_second': 12533.87}\n",
    "{'loss': 1.0653, 'grad_norm': 2.5652620792388916, 'learning_rate': 6.493956542914075e-07, 'epoch': 0.81, 'num_input_tokens_seen': 12220416, 'step': 148, 'step_time_sec': 4.48, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 230.68, 'estimated_total_time_sec': 1206.13, 'step_peak_memory_allocated_MB': 38307.84, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13244.26, 'avg_tokens_per_second': 12537.16}\n",
    "{'loss': 1.0454, 'grad_norm': 2.5035910606384277, 'learning_rate': 6.141213861797204e-07, 'epoch': 0.81, 'num_input_tokens_seen': 12291072, 'step': 149, 'step_time_sec': 5.54, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 223.85, 'estimated_total_time_sec': 1204.82, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12760.36, 'avg_tokens_per_second': 12538.43}\n",
    "{'loss': 1.0549, 'grad_norm': 2.4987902641296387, 'learning_rate': 5.797225998496851e-07, 'epoch': 0.82, 'num_input_tokens_seen': 12390400, 'step': 150, 'step_time_sec': 8.17, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 217.61, 'estimated_total_time_sec': 1206.77, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12160.01, 'avg_tokens_per_second': 12535.28}\n",
    "{'loss': 1.0903, 'grad_norm': 2.5121428966522217, 'learning_rate': 5.462119176998471e-07, 'epoch': 0.83, 'num_input_tokens_seen': 12460032, 'step': 151, 'step_time_sec': 5.95, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 210.88, 'estimated_total_time_sec': 1205.99, 'step_peak_memory_allocated_MB': 38307.87, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11698.81, 'avg_tokens_per_second': 12530.25}\n",
    "{'loss': 1.0734, 'grad_norm': 2.7282514572143555, 'learning_rate': 5.136016362450165e-07, 'epoch': 0.83, 'num_input_tokens_seen': 12535808, 'step': 152, 'step_time_sec': 6.03, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 204.18, 'estimated_total_time_sec': 1205.31, 'step_peak_memory_allocated_MB': 38308.08, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12567.48, 'avg_tokens_per_second': 12530.47}\n",
    "{'loss': 1.0174, 'grad_norm': 2.896052598953247, 'learning_rate': 4.819037216041501e-07, 'epoch': 0.84, 'num_input_tokens_seen': 12623872, 'step': 153, 'step_time_sec': 7.8, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 197.83, 'estimated_total_time_sec': 1206.76, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11294.0, 'avg_tokens_per_second': 12520.85}\n",
    "{'loss': 1.0732, 'grad_norm': 2.5064637660980225, 'learning_rate': 4.511298051094641e-07, 'epoch': 0.84, 'num_input_tokens_seen': 12693504, 'step': 154, 'step_time_sec': 5.05, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 190.94, 'estimated_total_time_sec': 1204.92, 'step_peak_memory_allocated_MB': 38307.98, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13783.97, 'avg_tokens_per_second': 12527.19}\n",
    "{'loss': 1.096, 'grad_norm': 2.526785373687744, 'learning_rate': 4.212911790383971e-07, 'epoch': 0.85, 'num_input_tokens_seen': 12774400, 'step': 155, 'step_time_sec': 6.19, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 184.29, 'estimated_total_time_sec': 1204.45, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13064.41, 'avg_tokens_per_second': 12530.47}\n",
    "{'loss': 0.9801, 'grad_norm': 2.367748498916626, 'learning_rate': 3.9239879246998476e-07, 'epoch': 0.85, 'num_input_tokens_seen': 12857344, 'step': 156, 'step_time_sec': 7.53, 'avg_step_time_sec': 6.59, 'time_to_completion_sec': 177.87, 'estimated_total_time_sec': 1205.57, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11015.33, 'avg_tokens_per_second': 12519.3}\n",
    "{'loss': 1.0163, 'grad_norm': 2.5074172019958496, 'learning_rate': 3.644632472671734e-07, 'epoch': 0.86, 'num_input_tokens_seen': 12936192, 'step': 157, 'step_time_sec': 5.96, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 171.18, 'estimated_total_time_sec': 1204.84, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13225.33, 'avg_tokens_per_second': 12523.4}\n",
    "{'loss': 1.1275, 'grad_norm': 2.468357801437378, 'learning_rate': 3.3749479418653716e-07, 'epoch': 0.86, 'num_input_tokens_seen': 13015040, 'step': 158, 'step_time_sec': 5.95, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 164.49, 'estimated_total_time_sec': 1204.1, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13244.01, 'avg_tokens_per_second': 12527.55}\n",
    "{'loss': 1.0775, 'grad_norm': 2.3577749729156494, 'learning_rate': 3.1150332911683354e-07, 'epoch': 0.87, 'num_input_tokens_seen': 13089792, 'step': 159, 'step_time_sec': 5.68, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 157.78, 'estimated_total_time_sec': 1203.06, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13162.94, 'avg_tokens_per_second': 12531.02}\n",
    "{'loss': 1.0951, 'grad_norm': 2.4419283866882324, 'learning_rate': 2.864983894477752e-07, 'epoch': 0.87, 'num_input_tokens_seen': 13163520, 'step': 160, 'step_time_sec': 5.22, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 151.01, 'estimated_total_time_sec': 1201.5, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14115.6, 'avg_tokens_per_second': 12538.95}\n",
    "{'loss': 1.0282, 'grad_norm': 2.596604108810425, 'learning_rate': 2.6248915057035006e-07, 'epoch': 0.88, 'num_input_tokens_seen': 13236224, 'step': 161, 'step_time_sec': 5.55, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 144.3, 'estimated_total_time_sec': 1200.34, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13111.61, 'avg_tokens_per_second': 12541.98}\n",
    "{'loss': 1.1054, 'grad_norm': 2.4711930751800537, 'learning_rate': 2.394844225099747e-07, 'epoch': 0.89, 'num_input_tokens_seen': 13333504, 'step': 162, 'step_time_sec': 8.17, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 137.95, 'estimated_total_time_sec': 1202.17, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11901.32, 'avg_tokens_per_second': 12537.02}\n",
    "{'loss': 1.1097, 'grad_norm': 2.635345697402954, 'learning_rate': 2.1749264669371616e-07, 'epoch': 0.89, 'num_input_tokens_seen': 13414400, 'step': 163, 'step_time_sec': 6.57, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 131.38, 'estimated_total_time_sec': 1202.17, 'step_peak_memory_allocated_MB': 38308.01, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12316.59, 'avg_tokens_per_second': 12535.66}\n",
    "{'loss': 1.1126, 'grad_norm': 2.3947408199310303, 'learning_rate': 1.96521892852767e-07, 'epoch': 0.9, 'num_input_tokens_seen': 13498368, 'step': 164, 'step_time_sec': 8.05, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 124.99, 'estimated_total_time_sec': 1203.83, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10431.71, 'avg_tokens_per_second': 12519.87}\n",
    "{'loss': 1.0697, 'grad_norm': 2.6839816570281982, 'learning_rate': 1.7657985606131544e-07, 'epoch': 0.9, 'num_input_tokens_seen': 13564928, 'step': 165, 'step_time_sec': 5.78, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 118.32, 'estimated_total_time_sec': 1202.94, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11511.12, 'avg_tokens_per_second': 12514.46}\n",
    "{'loss': 1.1374, 'grad_norm': 2.5085816383361816, 'learning_rate': 1.5767385391288725e-07, 'epoch': 0.91, 'num_input_tokens_seen': 13655040, 'step': 166, 'step_time_sec': 8.24, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 111.92, 'estimated_total_time_sec': 1204.79, 'step_peak_memory_allocated_MB': 38307.94, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10936.74, 'avg_tokens_per_second': 12502.49}\n",
    "{'loss': 1.0829, 'grad_norm': 2.564040184020996, 'learning_rate': 1.3981082383520837e-07, 'epoch': 0.91, 'num_input_tokens_seen': 13730816, 'step': 167, 'step_time_sec': 5.8, 'avg_step_time_sec': 6.58, 'time_to_completion_sec': 105.26, 'estimated_total_time_sec': 1203.93, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13055.97, 'avg_tokens_per_second': 12505.43}\n",
    "{'loss': 1.0769, 'grad_norm': 2.527573585510254, 'learning_rate': 1.2299732054456092e-07, 'epoch': 0.92, 'num_input_tokens_seen': 13795328, 'step': 168, 'step_time_sec': 4.72, 'avg_step_time_sec': 6.57, 'time_to_completion_sec': 98.52, 'estimated_total_time_sec': 1201.9, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13666.3, 'avg_tokens_per_second': 12510.43}\n",
    "{'loss': 1.06, 'grad_norm': 2.6875393390655518, 'learning_rate': 1.0723951364057705e-07, 'epoch': 0.92, 'num_input_tokens_seen': 13864960, 'step': 169, 'step_time_sec': 4.72, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 91.79, 'estimated_total_time_sec': 1199.89, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14742.65, 'avg_tokens_per_second': 12520.0}\n",
    "{'loss': 1.0692, 'grad_norm': 2.526292085647583, 'learning_rate': 9.25431853423443e-08, 'epoch': 0.93, 'num_input_tokens_seen': 13934592, 'step': 170, 'step_time_sec': 5.54, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 85.16, 'estimated_total_time_sec': 1198.79, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12562.77, 'avg_tokens_per_second': 12520.22}\n",
    "{'loss': 1.1275, 'grad_norm': 2.339484453201294, 'learning_rate': 7.891372836666311e-08, 'epoch': 0.93, 'num_input_tokens_seen': 14019584, 'step': 171, 'step_time_sec': 6.26, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 78.59, 'estimated_total_time_sec': 1198.48, 'step_peak_memory_allocated_MB': 38436.28, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13578.63, 'avg_tokens_per_second': 12526.17}\n",
    "{'loss': 1.0131, 'grad_norm': 2.5209367275238037, 'learning_rate': 6.635614394922274e-08, 'epoch': 0.94, 'num_input_tokens_seen': 14125056, 'step': 172, 'step_time_sec': 8.35, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 72.16, 'estimated_total_time_sec': 1200.41, 'step_peak_memory_allocated_MB': 41378.36, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12626.84, 'avg_tokens_per_second': 12526.92}\n",
    "{'loss': 1.0388, 'grad_norm': 2.4875357151031494, 'learning_rate': 5.487504000943522e-08, 'epoch': 0.95, 'num_input_tokens_seen': 14209024, 'step': 173, 'step_time_sec': 6.76, 'avg_step_time_sec': 6.56, 'time_to_completion_sec': 65.61, 'estimated_total_time_sec': 1200.62, 'step_peak_memory_allocated_MB': 38436.28, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12422.83, 'avg_tokens_per_second': 12526.29}\n",
    "{'loss': 1.0955, 'grad_norm': 2.5076024532318115, 'learning_rate': 4.447462945959024e-08, 'epoch': 0.95, 'num_input_tokens_seen': 14269440, 'step': 174, 'step_time_sec': 5.19, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 58.98, 'estimated_total_time_sec': 1199.17, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11633.35, 'avg_tokens_per_second': 12522.2}\n",
    "{'loss': 1.0689, 'grad_norm': 2.4877614974975586, 'learning_rate': 3.515872865895475e-08, 'epoch': 0.96, 'num_input_tokens_seen': 14343168, 'step': 175, 'step_time_sec': 5.68, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 52.38, 'estimated_total_time_sec': 1198.26, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 12977.44, 'avg_tokens_per_second': 12524.47}\n",
    "{'loss': 1.1785, 'grad_norm': 2.593111991882324, 'learning_rate': 2.693075601338646e-08, 'epoch': 0.96, 'num_input_tokens_seen': 14413824, 'step': 176, 'step_time_sec': 4.99, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 45.77, 'estimated_total_time_sec': 1196.62, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14173.57, 'avg_tokens_per_second': 12531.66}\n",
    "{'loss': 1.0095, 'grad_norm': 2.4368386268615723, 'learning_rate': 1.9793730720974902e-08, 'epoch': 0.97, 'num_input_tokens_seen': 14498816, 'step': 177, 'step_time_sec': 8.19, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 39.29, 'estimated_total_time_sec': 1198.34, 'step_peak_memory_allocated_MB': 38307.84, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 10380.25, 'avg_tokens_per_second': 12516.37}\n",
    "{'loss': 1.0817, 'grad_norm': 2.4786536693573, 'learning_rate': 1.3750271664165315e-08, 'epoch': 0.97, 'num_input_tokens_seen': 14581760, 'step': 178, 'step_time_sec': 6.18, 'avg_step_time_sec': 6.55, 'time_to_completion_sec': 32.73, 'estimated_total_time_sec': 1197.96, 'step_peak_memory_allocated_MB': 38307.96, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13419.88, 'avg_tokens_per_second': 12521.19}\n",
    "{'loss': 1.0464, 'grad_norm': 2.5346462726593018, 'learning_rate': 8.802596448778677e-09, 'epoch': 0.98, 'num_input_tokens_seen': 14653440, 'step': 179, 'step_time_sec': 5.22, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 26.16, 'estimated_total_time_sec': 1196.59, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13728.16, 'avg_tokens_per_second': 12526.61}\n",
    "{'loss': 1.0731, 'grad_norm': 2.210472345352173, 'learning_rate': 4.952520590276621e-09, 'epoch': 0.98, 'num_input_tokens_seen': 14736384, 'step': 180, 'step_time_sec': 7.01, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 19.62, 'estimated_total_time_sec': 1197.08, 'step_peak_memory_allocated_MB': 38307.89, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11829.66, 'avg_tokens_per_second': 12522.43}\n",
    "{'loss': 1.051, 'grad_norm': 2.5272750854492188, 'learning_rate': 2.201456847570005e-09, 'epoch': 0.99, 'num_input_tokens_seen': 14816256, 'step': 181, 'step_time_sec': 6.81, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 13.09, 'estimated_total_time_sec': 1197.34, 'step_peak_memory_allocated_MB': 38307.91, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 11736.99, 'avg_tokens_per_second': 12517.89}\n",
    "{'loss': 1.0723, 'grad_norm': 2.576997995376587, 'learning_rate': 5.504147046169195e-10, 'epoch': 0.99, 'num_input_tokens_seen': 14897152, 'step': 182, 'step_time_sec': 6.2, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 6.54, 'estimated_total_time_sec': 1196.99, 'step_peak_memory_allocated_MB': 38308.03, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 13055.33, 'avg_tokens_per_second': 12520.71}\n",
    "{'loss': 1.0963, 'grad_norm': 2.5667755603790283, 'learning_rate': 0.0, 'epoch': 1.0, 'num_input_tokens_seen': 14979072, 'step': 183, 'step_time_sec': 5.82, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 0.0, 'estimated_total_time_sec': 1196.27, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14071.57, 'avg_tokens_per_second': 12528.3}\n",
    "{'train_runtime': 1222.224, 'train_samples_per_second': 38.292, 'train_steps_per_second': 0.15, 'train_loss': 1.139190784568995, 'epoch': 1.0, 'num_input_tokens_seen': 14979072, 'step': 183, 'step_time_sec': 5.82, 'avg_step_time_sec': 6.54, 'time_to_completion_sec': 0.0, 'estimated_total_time_sec': 1196.27, 'step_peak_memory_allocated_MB': 38308.05, 'step_peak_memory_reserved_MB': 67158.0, 'total_peak_memory_allocated_MB': 41378.36, 'total_peak_memory_reserved_MB': 67158.0, 'step_tokens_per_second': 14071.57, 'avg_tokens_per_second': 12528.3}\n",
    "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 183/183 [20:22<00:00,  6.68s/it]\n",
    "(batch-size-memory-testing) ubuntu@164-152-31-252:~/Liger-Kernel/examples/huggingface$\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ff9e9d-f4ab-427c-b0f7-1cd61683d23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>num_input_tokens_seen</th>\n",
       "      <th>step</th>\n",
       "      <th>step_time_sec</th>\n",
       "      <th>avg_step_time_sec</th>\n",
       "      <th>time_to_completion_sec</th>\n",
       "      <th>estimated_total_time_sec</th>\n",
       "      <th>step_peak_memory_allocated_MB</th>\n",
       "      <th>step_peak_memory_reserved_MB</th>\n",
       "      <th>total_peak_memory_allocated_MB</th>\n",
       "      <th>total_peak_memory_reserved_MB</th>\n",
       "      <th>step_tokens_per_second</th>\n",
       "      <th>avg_tokens_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2891</td>\n",
       "      <td>9.976593</td>\n",
       "      <td>6.315789e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>153600</td>\n",
       "      <td>2</td>\n",
       "      <td>5.65</td>\n",
       "      <td>5.65</td>\n",
       "      <td>1022.81</td>\n",
       "      <td>1034.11</td>\n",
       "      <td>38307.94</td>\n",
       "      <td>58420.0</td>\n",
       "      <td>38307.94</td>\n",
       "      <td>58420.0</td>\n",
       "      <td>14134.49</td>\n",
       "      <td>14134.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4091</td>\n",
       "      <td>9.613660</td>\n",
       "      <td>9.473684e-07</td>\n",
       "      <td>0.02</td>\n",
       "      <td>241664</td>\n",
       "      <td>3</td>\n",
       "      <td>6.49</td>\n",
       "      <td>6.07</td>\n",
       "      <td>1092.46</td>\n",
       "      <td>1110.67</td>\n",
       "      <td>38308.05</td>\n",
       "      <td>60884.0</td>\n",
       "      <td>38308.05</td>\n",
       "      <td>60884.0</td>\n",
       "      <td>13574.21</td>\n",
       "      <td>13835.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3436</td>\n",
       "      <td>10.107481</td>\n",
       "      <td>1.263158e-06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>332800</td>\n",
       "      <td>4</td>\n",
       "      <td>7.43</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1167.41</td>\n",
       "      <td>1193.50</td>\n",
       "      <td>38308.03</td>\n",
       "      <td>60884.0</td>\n",
       "      <td>38308.05</td>\n",
       "      <td>60884.0</td>\n",
       "      <td>12270.76</td>\n",
       "      <td>13241.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3494</td>\n",
       "      <td>9.736582</td>\n",
       "      <td>1.578947e-06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395264</td>\n",
       "      <td>5</td>\n",
       "      <td>4.66</td>\n",
       "      <td>6.06</td>\n",
       "      <td>1078.11</td>\n",
       "      <td>1108.39</td>\n",
       "      <td>38307.87</td>\n",
       "      <td>60884.0</td>\n",
       "      <td>38308.05</td>\n",
       "      <td>60884.0</td>\n",
       "      <td>13399.55</td>\n",
       "      <td>13271.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3698</td>\n",
       "      <td>7.897504</td>\n",
       "      <td>1.894737e-06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>495616</td>\n",
       "      <td>6</td>\n",
       "      <td>8.23</td>\n",
       "      <td>6.49</td>\n",
       "      <td>1148.88</td>\n",
       "      <td>1187.83</td>\n",
       "      <td>41378.36</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>41378.36</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>12197.81</td>\n",
       "      <td>12999.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.0731</td>\n",
       "      <td>2.210472</td>\n",
       "      <td>4.952521e-09</td>\n",
       "      <td>0.98</td>\n",
       "      <td>14736384</td>\n",
       "      <td>180</td>\n",
       "      <td>7.01</td>\n",
       "      <td>6.54</td>\n",
       "      <td>19.62</td>\n",
       "      <td>1197.08</td>\n",
       "      <td>38307.89</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>41378.36</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>11829.66</td>\n",
       "      <td>12522.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.0510</td>\n",
       "      <td>2.527275</td>\n",
       "      <td>2.201457e-09</td>\n",
       "      <td>0.99</td>\n",
       "      <td>14816256</td>\n",
       "      <td>181</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.54</td>\n",
       "      <td>13.09</td>\n",
       "      <td>1197.34</td>\n",
       "      <td>38307.91</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>41378.36</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>11736.99</td>\n",
       "      <td>12517.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.0723</td>\n",
       "      <td>2.576998</td>\n",
       "      <td>5.504147e-10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>14897152</td>\n",
       "      <td>182</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.54</td>\n",
       "      <td>6.54</td>\n",
       "      <td>1196.99</td>\n",
       "      <td>38308.03</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>41378.36</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>13055.33</td>\n",
       "      <td>12520.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.0963</td>\n",
       "      <td>2.566776</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14979072</td>\n",
       "      <td>183</td>\n",
       "      <td>5.82</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1196.27</td>\n",
       "      <td>38308.05</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>41378.36</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>14071.57</td>\n",
       "      <td>12528.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14979072</td>\n",
       "      <td>183</td>\n",
       "      <td>5.82</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1196.27</td>\n",
       "      <td>38308.05</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>41378.36</td>\n",
       "      <td>67158.0</td>\n",
       "      <td>14071.57</td>\n",
       "      <td>12528.30</td>\n",
       "      <td>1222.224</td>\n",
       "      <td>38.292</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.139191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  grad_norm  learning_rate  epoch  num_input_tokens_seen  step  \\\n",
       "0    1.2891   9.976593   6.315789e-07   0.01                 153600     2   \n",
       "1    1.4091   9.613660   9.473684e-07   0.02                 241664     3   \n",
       "2    1.3436  10.107481   1.263158e-06   0.02                 332800     4   \n",
       "3    1.3494   9.736582   1.578947e-06   0.03                 395264     5   \n",
       "4    1.3698   7.897504   1.894737e-06   0.03                 495616     6   \n",
       "..      ...        ...            ...    ...                    ...   ...   \n",
       "178  1.0731   2.210472   4.952521e-09   0.98               14736384   180   \n",
       "179  1.0510   2.527275   2.201457e-09   0.99               14816256   181   \n",
       "180  1.0723   2.576998   5.504147e-10   0.99               14897152   182   \n",
       "181  1.0963   2.566776   0.000000e+00   1.00               14979072   183   \n",
       "182     NaN        NaN            NaN   1.00               14979072   183   \n",
       "\n",
       "     step_time_sec  avg_step_time_sec  time_to_completion_sec  \\\n",
       "0             5.65               5.65                 1022.81   \n",
       "1             6.49               6.07                 1092.46   \n",
       "2             7.43               6.52                 1167.41   \n",
       "3             4.66               6.06                 1078.11   \n",
       "4             8.23               6.49                 1148.88   \n",
       "..             ...                ...                     ...   \n",
       "178           7.01               6.54                   19.62   \n",
       "179           6.81               6.54                   13.09   \n",
       "180           6.20               6.54                    6.54   \n",
       "181           5.82               6.54                    0.00   \n",
       "182           5.82               6.54                    0.00   \n",
       "\n",
       "     estimated_total_time_sec  step_peak_memory_allocated_MB  \\\n",
       "0                     1034.11                       38307.94   \n",
       "1                     1110.67                       38308.05   \n",
       "2                     1193.50                       38308.03   \n",
       "3                     1108.39                       38307.87   \n",
       "4                     1187.83                       41378.36   \n",
       "..                        ...                            ...   \n",
       "178                   1197.08                       38307.89   \n",
       "179                   1197.34                       38307.91   \n",
       "180                   1196.99                       38308.03   \n",
       "181                   1196.27                       38308.05   \n",
       "182                   1196.27                       38308.05   \n",
       "\n",
       "     step_peak_memory_reserved_MB  total_peak_memory_allocated_MB  \\\n",
       "0                         58420.0                        38307.94   \n",
       "1                         60884.0                        38308.05   \n",
       "2                         60884.0                        38308.05   \n",
       "3                         60884.0                        38308.05   \n",
       "4                         67158.0                        41378.36   \n",
       "..                            ...                             ...   \n",
       "178                       67158.0                        41378.36   \n",
       "179                       67158.0                        41378.36   \n",
       "180                       67158.0                        41378.36   \n",
       "181                       67158.0                        41378.36   \n",
       "182                       67158.0                        41378.36   \n",
       "\n",
       "     total_peak_memory_reserved_MB  step_tokens_per_second  \\\n",
       "0                          58420.0                14134.49   \n",
       "1                          60884.0                13574.21   \n",
       "2                          60884.0                12270.76   \n",
       "3                          60884.0                13399.55   \n",
       "4                          67158.0                12197.81   \n",
       "..                             ...                     ...   \n",
       "178                        67158.0                11829.66   \n",
       "179                        67158.0                11736.99   \n",
       "180                        67158.0                13055.33   \n",
       "181                        67158.0                14071.57   \n",
       "182                        67158.0                14071.57   \n",
       "\n",
       "     avg_tokens_per_second  train_runtime  train_samples_per_second  \\\n",
       "0                 14134.49            NaN                       NaN   \n",
       "1                 13835.04            NaN                       NaN   \n",
       "2                 13241.24            NaN                       NaN   \n",
       "3                 13271.70            NaN                       NaN   \n",
       "4                 12999.47            NaN                       NaN   \n",
       "..                     ...            ...                       ...   \n",
       "178               12522.43            NaN                       NaN   \n",
       "179               12517.89            NaN                       NaN   \n",
       "180               12520.71            NaN                       NaN   \n",
       "181               12528.30            NaN                       NaN   \n",
       "182               12528.30       1222.224                    38.292   \n",
       "\n",
       "     train_steps_per_second  train_loss  \n",
       "0                       NaN         NaN  \n",
       "1                       NaN         NaN  \n",
       "2                       NaN         NaN  \n",
       "3                       NaN         NaN  \n",
       "4                       NaN         NaN  \n",
       "..                      ...         ...  \n",
       "178                     NaN         NaN  \n",
       "179                     NaN         NaN  \n",
       "180                     NaN         NaN  \n",
       "181                     NaN         NaN  \n",
       "182                    0.15    1.139191  \n",
       "\n",
       "[183 rows x 20 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = extract_dicts_from_log(v021_data)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "v021 = pd.DataFrame(dicts)\n",
    "\n",
    "# Display the DataFrame\n",
    "v021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a85ada8f-4188-4a78-8d8a-4efec03ffb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xkcd()\n",
    "plt.rcParams['font.family'] = \"xkcd\"\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax1.plot(v011['step'], v011['total_peak_memory_allocated_MB'], label='v0.1.1', color='blue')\n",
    "ax1.plot(v020['step'], v020['total_peak_memory_allocated_MB'], label='v0.2.0', color='red')\n",
    "ax1.plot(v021['step'], v021['total_peak_memory_allocated_MB'], label='v0.2.1', color='green')\n",
    "ax1.set_xlabel('STEP')\n",
    "ax1.set_ylabel('MiB')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "plt.title('ALLOCATED MEMORY FOR HUGGING FACE EXAMPLE BY STEP')\n",
    "ax1.legend(loc='lower right', bbox_to_anchor=(0.95, 0.05))\n",
    "plt.savefig(\"/tmp/liger-v0.1.1-vs-0.2.0-vs-0.2.1.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c71f5-bcda-4b5f-94d0-5435e88153d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
